\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{baskervald}
\usepackage{bbold}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{faktor}
\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red]{hyperref}
\usepackage{imakeidx} % before hyperref
\usepackage{mathalfa}
\usepackage{mathtools}
\usepackage{mdframed}
\usepackage[bigdelims,vvarbb]{newtxmath}
\usepackage{rotating}
\usepackage{stmaryrd}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{xcolor}

\renewcommand*\oldstylenums[1]{\textosf{#1}}

\theoremstyle{definition}
\newmdtheoremenv[%
  backgroundcolor=white,
  linecolor=white!60!black,
  linewidth=3pt]{ex}{Exercise}

\DeclareMathOperator\kernel{kernel}
\DeclareMathOperator\image{image}
\DeclareMathOperator\sign{sign}
\DeclareMathOperator\Hom{Hom}
\DeclareMathOperator\Tr{Tr}

\title{Linear Algebra 2 -- Practicals}
\author{Lukas Prokop}
\date{summer term 2018}

\newcommand\dateref[1]{These practicals took place on #1.\par}
\newcommand\meta[3]{This #1 took place on #2 (#3).\par}
\newcommand\abs[1]{|\,#1\,|}
\newcommand\set[1]{\left\{#1\right\}}
\newcommand\setdef[2]{\left\{#1\,\middle|\,#2\right\}}
\newcommand\card[1]{\left|\,#1\,\right|}
\newcommand\divides[2]{#1\,\mid\,#2}
\newcommand\angel[1]{\langle#1\rangle}
\newcommand\mathspace{\hspace{20pt}}
\newcommand\fun[1]{\left\langle{#1}\right\rangle}
\newcommand\ip[2]{\langle{#1},{#2}\rangle}
\newcommand\norm[1]{\left\|{#1}\right\|}
\newcommand\vectwo[2]{\begin{pmatrix} #1 \\ #2 \end{pmatrix}}
\newcommand\Q{\mathbb{Q}}
\newcommand\nope{\lightning}
\newcommand\vecfour[4]{\begin{pmatrix} #1 \\ #2 \\ #3 \\ #4 \end{pmatrix}}
\newcommand{\textgreek}[1]{\begingroup\fontencoding{LGR}\selectfont#1\endgroup}

\DeclareMathOperator\rank{rank}

\parindent0pt
\parskip7pt
\setcounter{tocdepth}{1}

\begin{document}

\maketitle
\tableofcontents

\clearpage

Exercises, I did on the board: 

\section{Exercise 1}
\begin{ex}
  Determine the matrix representation of the linear map
  \[ f: \mathbb R_2[x] \to \mathbb R_3[x] \]
  \[ p(x) \mapsto x \cdot p(x) \]
  in terms of the bases $B = \set{1, x, x^2 - 1} \subseteq \mathbb R_2[x]$ and $C = \set{1, x, x^2 - 1, x^3 - 2x} \subseteq \mathbb R_3[x]$
\end{ex}

\subsection{Blackboard solution}

\[ \mathcal L(\set{\underbrace{1, x, x^2-1}_{b_1, b_2, b_3}}) \to \mathcal L(\set{\underbrace{1, x, x^2-1, x^3 - 2x}_{c_1, c_2, c_3, c_4}}) \]
\[ f: \alpha \mapsto x \cdot \alpha \]

\[ f(1) = x = 1 c_2 \]
\[ f(x) = x = x^2 = 1c_3 + 1 c_1 \]
\[ f(x^2-1) = x^3 - x = 1 c_4 + 1 c_2 \]

\[
  \begin{matrix}
        & b_1 & b_2 & b_3 \\
  \hline
    c_1 & 0 & 1 & 0 \\
    c_2 & 1 & 0 & 1 \\
    c_3 & 0 & 1 & 0 \\
    c_4 &   & 0 & 1
  \end{matrix}
\]

\subsection{My solution}

\begin{align*}
  B &= \set{1, x, x^2 - 1} \eqqcolon \set{b_1, b_2, b_3} \\
  C &= \set{1, x, x^2 - 1, x^3 - 2x} \eqqcolon \set{c_1, c_2, c_3, c_4}
  f(b_1) &= x \cdot (1) = x \\
  f(b_2) &= x \cdot (x) = x^2 \\
  f(b_3) &= x \cdot (x^2 - 1) = x^3 - x
\end{align*}

\begin{align*}
  x &= \lambda_1 \cdot 1 + \lambda_2 \cdot x + \lambda_3 \cdot (x^2 - 1) + \lambda_4 \cdot (x^3 - 2x) \\
    &= \lambda_1 - \lambda_3 + (\lambda_2 - 2 \lambda_4) x + \lambda_3 x^2 + \lambda_4 x^3
\end{align*}
By coefficient comparison, we get $\lambda_1 = \lambda_3 = 0$ and $\lambda_2 - 2\lambda_4 = 1$ where $\lambda_4 \stackrel!= 0$. Hence $\lambda_2 = 1$.

\[ \implies \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} \]

\begin{align*}
  x^2 &= \lambda_1 - \lambda_3 + (\lambda_2 - 2 \lambda_4) x + \lambda_3 x^2 + \lambda_4 x^3
\end{align*}
By coefficient comparison, we get $\lambda_3 = 1$ and $\lambda_1 = \lambda_2 = \lambda_4 = 0$.

\[ \implies \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix} \]

\begin{align*}
  x^3 - x &= \lambda_1 - \lambda_3 + (\lambda_2 - 2 \lambda_4) x + \lambda_3 x^2 + \lambda_4 x^3
\end{align*}
By coefficient comparison, we get $\lambda_1 = \lambda_3 = 0$ and $\lambda_2 - 2 \lambda_4 = -1$ with $\lambda_4 \stackrel!= 1$, hence $\lambda_2 = 1$.

\[ \implies \begin{pmatrix} 0 \\ 1 \\ 0 \\ 1 \end{pmatrix} \]

So our solution is,
\[
  M =
  \begin{pmatrix}
    0 & 0 & 0 \\
    1 & 0 & 1 \\
    0 & 1 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\]

\section{Exercise 2}
\begin{ex}
  A chain complex $C$ is a sequence of linear maps
  \[ 0 = V_n \xrightarrow{f_n} V_{n-1} \xrightarrow{f_{n-1}} V_{n-2} \xrightarrow{f_{n-2}} \cdots \xrightarrow{f_1} V_0 \xrightarrow{f_0} 0 \]
  with the property such that $\operatorname{im}{f_{k+1}} \subseteq \operatorname{ker}{f_{k}}$ for all $0 \leq k \leq n-1$, hence,
  $f_k \circ f_{k+1} = 0$. The quotient space $H_k(C) = \operatorname{ker}{f_k} / \operatorname{im}{f_{k+1}}$ is called $k$-th \emph{homology}
  of the complex. Show that for finite-dimensional chain complexs (hence, $\dim{V_k} < \infty$ for all $k$) the following formula holds:
  \[ \sum_{k=0}^{n-1} (-1)^k \dim{V_k} = \sum_{k=0}^{n-1} (-1)^k \dim{H_k}(C) \]
\end{ex}

\subsection{Blackboard solution}

$V \subset W$ vector spaces.
\[ V = \mathcal L\set{v_1, \dots, v_n} \qquad W = \mathcal L\set{v_1, \dots, v_n, w_1, \dots, w_n} \]

$\faktor{W}{V} = \set{[x]_V: x \in W}$

\[ [x]_n \coloneqq \setdef{x+v}{v \in V} \]

$[w_1]_v, \dots, [w_n]_v$ is a basis of vector space $\faktor{w}{v}$.

for $x, y \in W$,
\[ x \sim_V y \coloneqq x - y \in V \]
\[ y + v_2 \in [y]_V \]
\[ [x]_V \bigodot [y]_V = [x + v_1 + y + v_2]_V \]

\[ [x]_V \bigodot [y]_V = [x+y]_V \]
\[ \alpha [x]_V = [\alpha x]_V \]


\[ \sum_{k=0}^{n-1} (-1)^k \dim{V_k} = \sum_{k=0}^{n-1} (-1)^k \dim{H_k(C)}. \]

where $\dim(V_k) = \dim\kernel(f_k) + \dim\image(f_k)$ and $\dim(H_k) = \dim\kernel(f_k) - \dim\image(f_k) = \dim\kernel(f_k) - \dim\image(f_{k+1})$.

\section{Exercise 3}
\begin{ex}
  Let $A \in \mathbb K^{n\times n}$ be a nilpotent matrix, hence, there exists $k \in \mathbb N$ such that $A^k = 0$.
  \begin{itemize}
    \item Show that $I - A$ is invertible with $(I - A)^{-1} = I + A + A^2 + \dots + A^{k-1}$.
    \item Use the previous result to derive the inverse of the matrix:
      \[
        \begin{pmatrix}
          1 & a & b & c \\
          0 & 1 & a & b \\
          0 & 0 & 1 & a \\
          0 & 0 & 0 & 1
        \end{pmatrix}
      \]
  \end{itemize}
\end{ex}

\subsection{Blackboard solution}

\[ 1 + x + x^2 + x^3 + \dots + x^{n-1} = \frac{x^n - 1 [= (x-1)(1 + x + x^2 + \dots + x^{n-1}])}{x-1} \]

Just verify:
\[ (I - A)(I - A + A^2 + \dots + A^{n-1}) \]

\section{Exercise 4}
\begin{ex}
  \begin{enumerate}
    \item Let $A$ be an invertible $n \times n$ matrix over the field $\mathbb K$ and $u,v$ are column vectors (hence, $n\times 1$ matrices),
          such that $\sigma = 1 + v^t A^{-1} u \neq 0$. Show that $(A + uv^t)$ is invertible and that
          \[ (A + uv^t)^{-1} = A^{-1} - \frac1\sigma A^{-1} uv^t A^{-1} \]
    \item Apply this formula, to determine the inverse of matrix
          \[
            \begin{pmatrix}
              5 & 3 & 0 & 1 \\
              3 & 2 & 0 & 0 \\
              0 & 0 & 2 & 3 \\
              0 & 0 & 3 & 5
            \end{pmatrix}
          \]
          efficiently.
  \end{enumerate}
\end{ex}

\subsection{Blackboard solution}

\[ (A + uv^t)^{-1} = A^{-1} - \frac1\sigma A^{-1} uv^t A^{-1} \qquad \text{ (Sherman-Morrison-Formula)} \]
\[ \sigma = 1 + v^t A^{-1} u \neq 0 \]

\[ (A + uv^t)(A^{-1} - \frac1\sigma A^{-1} uv^t A^{-1}) = A A^{-1} + uv^t A^{-1} - \frac1\sigma (A A^{-1} uv^t A^{-1} + uv^t A^{-1} uv^t A^{-1}) \]
\[ = I + uv^t A^{-1} - \frac1\sigma (uv^t A^{-1} + (v^t A^{-1} u) uv^t A^{-1} )\]
\[ = I + uv^t A^{-1} - \frac1\sigma (1 + v^t A^{-1} u) uv^t A^{-1} \]
\[ = I + uv^t A^{-1} - \frac\sigma\sigma uv^t A^{-1} = I \]

\dateref{2018/03/14}

\section{Exercise 5}
\begin{ex}
  \begin{enumerate}
    \item[a.] Determine the dual basis of $(\mathbb R)^4$ to $B$
    \[
      B \coloneqq \set{
        \begin{pmatrix} 1 \\ 2 \\ 1 \\ 0 \end{pmatrix},
        \begin{pmatrix} 1 \\ 0 \\ -1 \\ 1 \end{pmatrix},
        \begin{pmatrix} -1 \\ -2 \\ 2 \\ -1 \end{pmatrix},
        \begin{pmatrix} 2 \\ -1 \\ 1 \\ 1 \end{pmatrix}
      }
    \]

    \item[b.] Determine the matrix of the distinct (why distinct?) projection map
      $\varphi: \mathbb R^4 \to \mathbb R^4$ with
      \[
        \image{\varphi} = \mathcal L\set{\begin{pmatrix} 1 \\ 2 \\ 1 \\ 0 \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ -1 \\ 1 \end{pmatrix}}
        \text{ and }
        \kernel{\varphi} = \mathcal L\set{\begin{pmatrix} -1 \\ -2 \\ 2 \\ -1 \end{pmatrix}, \begin{pmatrix} 2 \\ -1 \\ 1 \\ 1 \end{pmatrix}}
      \]
  \end{enumerate}
\end{ex}

\subsection{Blackboard solution}

It must hold that
\[ \angel{b_1, b_1^*} = 1 \]
\[ \angel{b_2, b_2^*} = 0 \]


\[
  \begin{pmatrix}
    1 & 2 & 1 & 0     & 1 & 0 & 0 & 0 \\
    1 & 0 & -1 & 1    & 0 & 1 & 0 & 0 \\
    -1 & -2 & 2 & -1  & 0 & 0 & 1 & 0 \\
    2 & -1 & 1 & 1    & 0 & 0 & 0 & 1
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 0 & 0 & 0 &  3 & -4 & -5 & 4 \\
    0 & 1 & 0 & 0 &  1 & 2 & 1 & -1 \\
    0 & 0 & 1 & 0 &  2 & 5 & 3 & -2 \\
    0 & 0 & 0 & 1 &  5 & 15 & 8 & -6
  \end{pmatrix}
\]
Pay attention! We transposed the matrix initially.
Now we can read the solution vectors in columns.
You can also transpose it only in the end.

\[ B^* = \set{b_1^*, b_2^*, b_3^*, b_4^*} \]
where e.g. $b_1^* = (3, 1, 2, 5)^T$.

Exercise b: $\varphi: \mathbb R^4 \to \mathbb R^4$.

\[ \image{\varphi} = L((b_1, b_2)) \]
\[ \kernel{\varphi} = L((b_3, b_4)) \]
\[
  \begin{pmatrix}
    1 & 1 & 0 & 0 \\
    2 & 0 & 0 & 0 \\
    1 & -1 & 0 & 0 \\
    0 & 1 & 0 & 0
  \end{pmatrix}
  \cdot B^{{*}^T} = P
\]

\[
  P = \begin{pmatrix}
    -12 & 3 & 7 & 20 \\
    -6 & 2 & 4 & 10 \\
    6 & -1 & -3 & -10 \\
    -4 & 2 & 5 & 15
  \end{pmatrix}
\]

Why distinct?
The projection matrix is given with
\[
  \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\]
where row $i$ is $b_i$ and column $j$ is $d_j$ where $b$ and $d$ are the bases of the two vector spaces.

\[ \begin{pmatrix} 1 \\ 2 \\ 3 \\ 4 \end{pmatrix}_B = 1 \cdot b_1 + 2 \cdot b_2 + 3 \cdot b_3 + 4 \cdot b_4 \]

\[ P_{E,E} = \Phi_B^E \cdot P_{B,B} \cdot \overbrace{\underbrace{\Phi_{E}^B}_{(\Phi_B^E)^{-1}} v_E}^{v_B} \]



How to compute the inverse efficiently?

Let $A, B, C \in \mathbb R^{2 \times 2}$.
\[
  \begin{pmatrix}
    A & B \\
    0 & C
  \end{pmatrix} \begin{pmatrix}
    \alpha & \beta \\
    0 & \gamma
  \end{pmatrix}
  = \begin{pmatrix}
    A \alpha & A \beta + B \gamma \\
    0 & C \gamma
  \end{pmatrix}
  \stackrel!= \mathcal 1
\]
\[ \alpha = A^{-1} \qquad \gamma = C^{-1} \]
\[ \beta = -A^{-1} B \gamma \]

\section{Exercise 6}
\begin{ex}
  Let $V = \mathbb R[x]_2$.
  \[ \xi_1 < \xi_2 < \xi_3 \in \mathbb R \]
\end{ex}

\subsection{Whiteboard solution}

Exercise a:
\[ \beta_i: V \to \mathbb R \]
\[ p(x) \mapsto p(\xi_i) \]
\[ \dim(V) = \dim(V^*) = 3 \]
\[ \sum a_i \beta_i =0 \iff a_i = 0 \forall i \]

\[ \forall p \in \mathbb R[x]_2: \sum a_i \beta_i(p(x)) \stackrel!= 0 \]
\[ \forall p \in \mathbb R[x]_2: \sum a_i \beta_i(\xi_i) \stackrel!= 0 \]

\[ \implies p_1(\xi_1) = p_1(x_2) = 0 \implies a_3 = 0 \dots a_i = 0 \forall i \]
hence linear independent.

Exercise b:
\[ \gamma: p(x) \mapsto p'(\xi_2) \]
\[ \gamma(p(x)) = \sum a_i \beta_i(p(x)) = \sum a_i p(\xi_i) = p'(\xi_2) \]
\[ p(x) = \alpha + \beta x + \delta x^2 \]
\[ \implies p'(\xi_2) = \beta + 2 \delta \xi_2 \]
\[ p(x) = \alpha + \beta x + \delta x^2 \]

\[
  \underbrace{\begin{pmatrix}
    1 & 1 & 1 \\
    \xi_1 & \xi_2 & \xi_3 \\
    \xi_1^2 & \xi_2^2 & \xi_3^2
  \end{pmatrix}}_{= A}
  \begin{pmatrix} a_1 \\ a_2 \\ a_3 \end{pmatrix}
  = \begin{pmatrix} 0 \\ 1 \\ 2\xi_2 \end{pmatrix}
\]


\[
  A^{-1} = \begin{pmatrix}
    \frac{\xi_2 \xi_3}{(\xi_2 - \xi_1)(\xi_3 - \xi_1)} & \dots \\
    -\frac{\xi_3 \xi_1}{(\xi_2 - \xi_1)(\xi_3 - \xi_2)} & \dots \\
    \frac{\xi_1 \xi_2}{(\xi_3 - \xi_1)(\xi_3 - \xi_2)} & \dots
  \end{pmatrix}
\]
\[
  \begin{pmatrix} a_1 \\ a_2 \\ a_3 \end{pmatrix}
  = A^{-1} \begin{pmatrix} 0 \\ 1 \\ 2 \xi_2 \end{pmatrix}
  = \begin{pmatrix}
    \frac{\xi_2 - \xi_3}{(\xi_2 - \xi_1)(\xi_3 - \xi_1)} \\
    \frac{\xi_1 - 2\xi_2 + \xi_3}{(\xi_2 - \xi_1)(\xi_3 - \xi_2)} \\
    \frac{\xi_2 - \xi_1}{(\xi_3 - \xi_1)(\xi_3 - \xi_2)}
  \end{pmatrix}
\]

Exercise c:
\[ B = \set{b_1(x), b_2(x), b_3(x)} \]
\[ l_i = \sum_{j=1}^2 a_{ji} x^j \]
\[ \beta_l(l_i(x)) = \delta_{li} \]

\[
  \begin{pmatrix}
    1 & \xi_1 & \xi_1^2 \\
    1 & \xi_2 & \xi_2^2 \\
    1 & \xi_3 & \xi_3^2
  \end{pmatrix} \cdot
  \begin{pmatrix}
    a_{11} & a_{12} & a_{13} \\
    a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & a_{33}
  \end{pmatrix}
  = \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\]
In essence, we look for $p(x) = \frac{(x_1 - x)(x_2 - x)}{(\xi_1 - \xi_3)(\xi_2 - \xi_3)}$.
This is a Lagrange polynomial with $l_3 = p$.

\section{Exercise 7}
\begin{ex}
  Let $V$ be a vector space with $\dim{V} = n < \infty$
  and $U \subseteq V$ is a subspace with $\dim{U} = m$.
  \begin{enumerate}
    \item[a.] Show that $U^\bot = \set{v^* \in V^*}{U \subseteq \kernel{v^*}}$ is a subspace of dual space $V^*$ and give $\dim{U^{\bot}}$.
    \item[b.] Is $\setdef{v^* \in V^*}{U = \kernel{v^*}}$ also a subspace?
  \end{enumerate}
\end{ex}

Exercise a:
\[
  \begin{pmatrix}
    U^\bot &= \setdef{v^* \in V^*}{U \subseteq \kernel{v^*}}
           &= \setdef{v^* \in V}{\forall u \in U: v^*(u) = 0}
  \end{pmatrix}
\]
We prove subspace criteria:
\begin{enumerate}
  \item $U^\bot \neq \emptyset$. Let $v^*: V \to \mathbb K$ with $v \mapsto 0$.
  \item
    \[ \forall u^\bot_1, u^\bot_2 \in U^\bot \forall \lambda, \mu \in \mathbb K: \lambda u_1^\bot + \mu u_2^\bot \in U^\bot \]
    \[ \lambda \underbrace{v_1^*(u)}_{0} + \mu v_2^*(u) = 0  \qquad \text{ for } \forall v_1^*, v_2^* \in U^\bot, u \in U \]
\end{enumerate}

Now, we need to determine the dimension $\dim{U^{\bot}}$.

Let $B_U = \set{v_1, v_2, \dots, v_m}$.
\[ B_V = \set{v_1, v_2, \dots, v_m, v_{m+1}, \dots, v_n} \]
\[ B_{V^*} = \set{v_1^*, v_2^*, \dots, v_n^*} \]
\[ B_{U^{\bot}} = \set{v_{m+1}^*, v_{m+2}^*, \dots, v_n^*} \text{ is basis of } U^\bot \]

\[ \forall u \in U: v^*_j(u) = 0^C \forall j \in \set{m+1, \dots, n} \]
\[ B_U = \set{v_1, v_2, \dots, v_m} \]
\[ B_V = \set{v_1, v_2, \dots, v_m, v_{m+1}, \dots, v_n} \]
\[ B_{V^*} = \set{v_1^*, v_2^*, \dots, v_n^*} \]
\[ B_{U^\bot} = \set{v_{m+1}^*, v_{m+2}^*, \dots, v_n^*} \text{ is basis of } U^\bot \]
\[ \implies \dim(U^\bot) = n - m \]

Exercise b:
\[ W^\bot = \setdef{v^* \in V^*}{U = \kernel(v^*)} \]
The reason was given orally.

\section{Exercise 8}
\begin{ex}
  Let $f \in \operatorname{Hom}(V, W)$ be a linear map between two finite-dimensional vector space with bases $B \subseteq V$ and $C \subseteq W$. We define the transposed map
  \[ f^T: W^* \to V^* \]
  \[ w^* \mapsto w^* \circ f \]
  Hence $f^T(w^*)$ is a linear functional and $(f^T(w^*))(v) = w^*(f(v))$
  \begin{enumerate}
  	\item[a.]
  	  Show that $f^T$ is linear.
  	\item[b.]
  	  Show that the matrix representation, in regards of dual bases $C^*$ and $B^*$, has the following matrix representation: $\Phi_{B^*}^{C^*}(f^T) = \Phi_C^B(f)^T$
  \end{enumerate}
\end{ex}

Exercise a:
Let $v \in V$ and $\lambda \in \mathbb K$, $w_1^*, w_2^* \in W^*$.
\[ (f^T(w_1^* + w_2^*))(v) = (w_1^* + w_2^*)f(v) = w_1^*(f(v)) + w_2^*(f(w_1^*))(v) + (f^T(w_2^*))(v) \]
\[ (f^T(\lambda w_1^*))(v) = (\lambda w_1^*)(f(v)) = \lambda w_1^*(f(v)) = \lambda (f^T(w_1^*))(v) \]
We proved $g(w_1 + \lambda w_2) = g(w_1) + \lambda g(w_2)$. Hence $f^*$ is linear.

Exercise b:
\[ \Phi_{B^*}^{C^*}(f^T) = \Phi_C^B(f)^T \]
\[ \set{v_1 \dots, v_n} = B \qquad \set{w_1, \dots, w_m} = C \]
\[ f(v_j) = \sum_{i=1}^m m_{ij} w_i \]
\[ (f^t(w_i^*))(v_k) = w_j^*(f(v_k)) = w_j^* \left(\sum_{l=1}^m {lk} w_l\right) = m_{jk} \]
\[ m_{jk} = \sum_{l=1}^n m_{jl} \underbrace{v_{l}^*(v_k)}_{\delta_{lk}} \]
\[ = \sum_{l=1}^n m_{jl} v_l^*(v_k) \]
\[ \implies f^T(w_j^*) = \sum_{l=1}^n A_{l,j} v_l^* \]
\[ \implies A = \Phi_C^B(f)^T \]
\[ A = \Phi_{B^*}^{C^*}(f^T) \]

\dateref{2018/03/21}

\section{Exercise 10}
\begin{ex}
  A permutation $\pi \in \sigma_n$ is called cyclic, if there exists some $k \geq 1$ and a sequence $i_1, i_2, \dots, i_k$ such that $\pi(i_j) = i_{j+1}$ for $1 \leq j \leq k-1$, $\pi(i_k) = i_1$ and $\pi(i) = i$ for $i \not\in \set{i_1, i_2, \dots, i_k}$, hence
  \[ i_1 \to i_2 \to \dots \to i_1. \]
  and all other $i$ are fixed. Common notation: $\pi = (i_1, i_2, \dots, i_k)$.
  \begin{itemize}
    \item Show, that two cyclic permutations $\pi = (i_1, i_2, \dots, i_k)$ and $\rho = (j_1, j_2, \dots, j_l)$ commutate ($\pi \circ \rho = \rho \circ \pi$), if $\set{i_1, i_2, \dots, i_k} \cap \set{j_1, j_2, \dots, j_l} = \emptyset$.
    \item Decompose the cycle into a product of transpositions and show that for a cyclic permutation, it holds that $\sign(\pi) = (-1)^{k-1}$.
  \end{itemize}
\end{ex}

For the first part,

Let $\operatorname{supp}(\pi) \cap \operatorname{supp}(\rho) = \emptyset$ where $\operatorname{supp}(\pi)$ defines the elements in the cycle of permutation $\pi$.
\begin{description}
  \item[$i \not\in \operatorname{supp}(\pi) \cup \operatorname{supp}(\rho)$] 
    \[ \implies \rho(i) = i = \pi(i) = i \]
    \[ \implies \pi(\rho(i)) = \rho(\pi(i)) = i \]
  \item[$i \in \operatorname{supp}(\pi)$]
    $i \in \operatorname{supp}(\pi) \implies \pi(i) \in \operatorname{supp}(\pi)$
    \[ \rho(\pi(i)) = \pi(i) \implies \rho(\pi(i)) = \pi(i) = \pi(\rho(i)) \]
\end{description}

For the second part,

\[ \pi = \tau_1 \cdot \tau_2 \cdot \dots = (i_1, i_2) (i_2, i_3) \dots (i_{k-1}, i_k) (i_k, i_1) \]
giving $k-1$ transposition.
\[ \implies \sign(\pi) = (-1)^{k-1} \]

\[ \tau_{24} = 1432 \]
\[ T_{34}^{2341} T_{23}^{2314} T_{42}^{2134} \]

\section{Exercise 11}
\begin{ex}
  Let $\pi \in \sigma_n$ be a permutation and $i \in \set{1, 2, \dots, n}$.
  \begin{enumerate}
    \item Show that the sequence $i, \pi(i), \pi^2(i), \dots$ is periodic and that the first number occuring twice is $i$.
    \item The sequence $(i, \pi(i), \pi^2(i), \dots, \pi^{k-1}(i))$, where $k$ is the smallest exponent such that $\pi^k(i) = i$, is called \emph{cycle of $i$}. Show that the relation $i \sim j : \iff $($j$ is in inside the cycle) defines an equivalence relation in $\set{1,2,\dots,n}$.
    \item Show that every permutation can be written as product of commutative cycles.
    \item Apply this decomposition to permutation $\pi$ in Exercise~9.
  \end{enumerate}
\end{ex}

Exercise (a).

$k$ is certainly finite, because of the pidgeonhole principle. Furthermore smaller than $n$, because there are at most $n$ numbers it can be mapped to. We have $n$ distinct elements. $i$ is the first element, which is not mapped to any number. So $i$ is the first number which will occur for the second time. This implies that the map is bijective, which is given for any permutation.

Exercise (b).

Reflexivity is trivial.
Symmetry: Let $\pi^l(i) = j$, then $\pi^{k-l}(j) = i$. This shows that both are in the same cycle and symmetry is given.
If $i \sim j \land j \sim m \implies i \sim m$.
\[ \pi(i) = j \qquad \pi^p(j) = m \iff \pi^p(\pi^l(i)) = m \iff \pi^{p+l}(i) = m \]
\[ \pi^p \circ \pi^l(i) = m \]

Exercise (c).

\[ 1 \quad \pi(1) \quad \pi(\pi(1)) \quad \pi(\pi(\pi(1))) \quad \dots \]
\[ \pi = (\quad)  (1, \dots, \pi^{k-1}) a_2 \pi(a_2) \neq a_2 \]

Exercise (d).

\[ \begin{pmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ 2 & 5 & 1 & 6 & 3 & 7 & 4 \end{pmatrix} = (1253) (467) \]

\section{Exercise 12}
\begin{ex}
  Show that every permutation $\pi \in \sigma_n$ can be written as composition of permutations
  $\gamma = \begin{pmatrix} 1 & 2 & \dots & n-1 & n \\ 2 & 3 & \dots & n & n-1 \end{pmatrix}$
  and $\tau = \begin{pmatrix} 1 & 2 & \dots & n-1 & n \\ 2 & 1 & \dots & n-1 & n \end{pmatrix}$
\end{ex}

From the lecture:
\begin{quote}
  Every permutation $\sigma \in \sigma_n$ with $\sigma \neq \operatorname{id}$ can be denoted as a product of transpositions.
\end{quote}

\begin{enumerate}
  \item Consider the theorem from the lecture.
  \item Every transposition can be represented as composition of swapping two neighbors.
    \[ \tau_{ij} = (i, i+1) (i+1, i+2) \dots (j-1, j) (j-2, j-1) \dots (i, i+1) \]
  \item
    \[ \tau_{i,i+1} = \gamma^{i-1} \cdot \tau \cdot \gamma^{-(i-1)} \]
\end{enumerate}

\section{Exercise 13}
\begin{ex}
  In the sliding 6-puzzle, which permutations can be reached?
\end{ex}

We begin with the initial position (right-bottom shows the vacant field) and need to end with the initial position as well.
We can only do transpositions with the vacant field.
\begin{enumerate}
  \item even number of transpositions
  \item signature $\pi = (-1)^{\text{\# transpositions}}$
  \item no permutation with $\sign - 1$
\end{enumerate}

The second item is wrong.

\[
  \pi_1 = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 \\ 2 & 3 & 4 & 5 & 1 \end{pmatrix} \qquad
  \pi_2 = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 \\ 1 & 2 & 4 & 5 & 3 \end{pmatrix}
\]
Any permutation is a product of $\pi_1$ and $\pi_2$.

We can permute in a shape of the infinity symbol.

\section{Exercise 14}
\begin{ex}
  Determine the determinant using three different methods (Leibniz, Laplace, Gauss-Jordan) of the matrix
  \[
    \begin{vmatrix}
      1 & 2 & 3 \\
      1 & 1 & 2 \\
      2 & -1 & 2
    \end{vmatrix}
  \]
\end{ex}

TODO

\section{Exercise 15}
\begin{ex}
  The numbers $18270$, $16128$, $63042$, $17304$ and $17934$ are divisible by $42$.
  Show that the determinant
  \[
    \det(A) = \begin{vmatrix}
      1 & 8 & 2 & 7 & 0 \\
      1 & 6 & 1 & 2 & 8 \\
      6 & 3 & 0 & 4 & 2 \\
      1 & 7 & 3 & 0 & 4 \\
      1 & 7 & 9 & 3 & 4
    \end{vmatrix}
  \]
  is divisible by $42$ without explicit evaluation.
\end{ex}

\[
  \begin{vmatrix}
    1 & 8 & 2 & 7 & 0 \\
    1 & 6 & 1 & 2 & 8 \\
    6 & 3 & 0 & 4 & 2 \\
    1 & 7 & 3 & 0 & 4 \\
    1 & 7 & 9 & 3 & 4
  \end{vmatrix}
  =
  \begin{vmatrix}
    1 & 8 & 2 & 7 & 18270 \\
    1 & 6 & 1 & 2 & 16128 \\
    6 & 3 & 0 & 4 & 63042 \\
    1 & 7 & 3 & 0 & 17304 \\
    1 & 7 & 9 & 3 & 17934
  \end{vmatrix}
\]
\[
  \det(A) = \sum_{k=1}^5 a_{k,5} \underbrace{(-1)^{k+5} \det{A_{k,5}}}_{\in \mathbb Z}
\]
$\det(A)$ consists of $5$ summands, which are divisible by $42$ each, hence the sum is divisible 

\dateref{2018/04/11}

\section{Exercise 17}
\begin{ex}
  Evaluate the determinants:
\end{ex}

\subsection{Exercise 17a}
\begin{ex}
  \[
    \begin{vmatrix}
      1+x & 1 & 1 & 1 \\
      1 & 1-x & 1 & 1 \\
      1 & 1 & 1+y & 1 \\
      1 & 1 & 1 & 1-y
    \end{vmatrix}
  \]
\end{ex}

\[
  \begin{vmatrix}
    0 & -x & -x & y+xy-x \\
    0 & -x & 0 & y \\
    0 & 0 & y & y \\
    1 & 1 & 1 & 1-y
  \end{vmatrix}
  =
  -1 \cdot
  \begin{vmatrix}
    -x & -x & y+xy-x \\
    -x & 0 & y \\
    0 & y & y
  \end{vmatrix}
\] \[
  = (-1) (-xy^2 - (xy)^2 + x^2y - x^2y + xy^2)
  = (xy)^2
\]

\subsubsection{A simpler solution}

Assume $C \in \operatorname{GL}(\mathbb R)$ and $\vec{V}, \vec{W} \in \mathbb R^n$ where GL is the set of invertible matrices.
Then it holds that
\[ \operatorname{det}(C + \vec v \vec w^t) = \det C \left( 1 + \langle C^{-1} \vec v, \vec w\rangle \right) \]
where $\langle \cdot, \cdot \rangle$ is an inner product with $\langle \vec v, \vec w \rangle = v_1 \cdot w_1 + \ldots + v_n \cdot w_n$.
\[ A \vec x = \vec b \]
\[ x_i = \frac{\det(A_j)}{\det{A}} \]

\subsection{Exercise 17b}
\begin{ex}
  \[
    \begin{vmatrix}
      x  & 0  & \ldots & a_0 \\
      -1 & x  & \ldots & a_1 \\
         & -1 & \ddots & \\
         & \ddots & \ddots & \\
      0  &    & -1 & x+a_{n-1}
    \end{vmatrix}
  \]
\end{ex}

Alternative approach: Use Laplace expansion theorem along the last column.

Always consider: A division by $x$ requires a case distinction!

Case 1: $x \neq 0$:

\[
  \begin{vmatrix}
    x &   & \ldots & a_0 \\
    0 & x & \ldots & a_1 + \frac{a_0}{x} \\
      & -1 & \ddots& \vdots \\
    \vdots & \ddots & \ddots & \\
    0 &   & -1 & x + a_{n-1}
  \end{vmatrix}
  =
  \begin{vmatrix}
    x &        & a_0 \\
      & \ddots & a_1 + \frac{a_0}{x} \\
      &        & x + a_{n-1} + \frac{a_{n-2}}{x} + \ldots + \frac{a_0}{x^{n-1}}
  \end{vmatrix}
\] \[
  = x^{n-1} (x + a_{n-1} + \frac{a_{n-2}}{x} + \ldots)
  = x^n + x^{n-1} a_{n-1} + \ldots + a_0
  = x^n + \sum_{i=1}^n a_{n-i} x^{n-i}
\]

Case 2: $x = 0$.

\[
  \begin{vmatrix}
    0 &         & a_0 \\
    -1 & \ddots & \\
       &        & -1\cdot a_{n-1}
  \end{vmatrix}
  = (-1)^{n+1} \cdot a_0 \cdot
  \begin{vmatrix}
    -1     &        & 0 \\
    \vdots & \ddots & \vdots \\
    0      &        & -1
  \end{vmatrix}
  = (-1)^{n+1} \cdot a_0 \cdot (-1)^{n-1} = (-1)^{2n} \cdot a_0 = a_0
\]

\subsection{Exercise 17c}
\begin{ex}
  \[
    \begin{vmatrix}
      0 & 0 & \ldots &         & a_n \\
      0 & 0 & \ldots & a_{n-1} & * \\
      \vdots & & & & \vdots \\
      0 & a_2 & & & \vdots
      a_1 & * & & & *
    \end{vmatrix}
  \]
\end{ex}

Case distinction: $n$ is even.

\[
  = (-1)^{\frac n2} \begin{vmatrix}
    a_1 & *   &   & & * \\
        & a_2 & * & & \vdots \\
        &     & \ddots & & \\
    0   &     &        & & a_n
  \end{vmatrix}
  = (-1)^{\frac{n-1}{2}} \prod_{i=1}^n a_i
\]

You can skip the case distinction if you use the Gaussian bracket: $(-1)^{\lfloor \frac n2\rfloor}$

\section{Exercise 18}
\begin{ex}
  Show: There exists some matrix $A \in \mathbb R^{n\times n}$ with entries $a_{ij} = \pm 1$ such that $\det(A) = n!$ if and only if $n < 3$.

  Hint: For $n=2$, it is easy. For $n=3$, consider why no all summands in Leibniz' formula for determinants have the same sign. The case $n>3$ can be reduced to the case $n=3$.
\end{ex}

For $n=2$,
\[ 2! = 2 \qquad \begin{vmatrix} 1 & 1 \\ -1 & 1 \end{vmatrix} = 1 - (-1) = 2 \]

For $n=3$, we consider the Rule of Sarrus and assume such a matrix $A$ exists.
Because $n! = 6$, we need all summands of the Rule of Sarrus to be positive. We consider the diagonals given in the Rule of Sarrus and recognize, that both diagonals use the same elements. 
Consider the diagonals with positive sign. All of them must either use zero or two $-1$. At the same time, all diagonals with negative sign must either use three or one $-1$. This contradicts assuming they use the same elements. The proof by contradiction has been completed.

Now we look for the generalization of $n \to n+1$ for $n \geq 3$.

This will be proven by complete induction.
\begin{description}
  \item[Induction hypothesis] $A \in \mathbb R^{n \times n}$ with $a_{ij} = \pm 1$
  \item[Induction base] $n=3$ has been proven
  \item[Induction step] We apply Laplace expansion along one row.
    Let $\varepsilon^{(i)}$ be the value of $\det(A_n^{(i)})$ where $A_n$ is a square matrix of dimension $n \times n$.
    \begin{align*}
      \det(A_{n+1}) &= +\underbrace{\det(A_n^{(1)})}_{< n!} - \underbrace{\det(A_n^{(2)})}_{< n!} + \underbrace{\det(A_n^{(3)})}_{< n!} - \ldots \\
        &= \sum_{i=1}^{n+1} \det(A_n^{(i)}) = \sum_{i=1}^{n+1} \varepsilon^{(i)} < (n+1) n! = (n+1)!
    \end{align*}
    Hence $\det(A_{n+1}) < (n+1) n!$.
\end{description}

\section{Exercise 19}
\begin{ex}
  \begin{enumerate}
    \item[(a)]
      Let $\mathbb K$ be a field and $a_1, a_2, \dots, a_n \in \mathbb K$. Show that
      \[
        \begin{vmatrix}
          1 & a_1 & a_1^2 & \ldots & a_1^{n-1} \\
          1 & a_2 & a_2^2 & \ldots & a_2^{n-1} \\
          \ldots & \ldots & \ldots & \ldots & \ldots \\
          1 & a_n & a_n^2 & \ldots & a_n^{n-1} \\
        \end{vmatrix}
        = \prod_{i < j} (a_j - a_i)
      \]
    \item[(b)]
      Conclude from this, that for given pairwise different numbers $x_0, x_1, \ldots, x_n \in \mathbb K$
      and arbitrary $y_0, y_1, \ldots, y_n \in \mathbb K$ there exists exactly one polynomial $p(x) \in \mathbb K[x]$ with degree $n$,
      such that $p(x_i) = y_i$ for all $i$.
    \item[(c)]
      Extra point to be solved on a computer:
      Determine for each different $n$, one polynomial $p(x) \in \mathbb R[x]$, such that $p(x_k) = \card{x_k}$, $k = -n, \ldots, n$, with $x_k = \frac{k}{n}$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 19a}

Induction base: $n=2$.
\[ \begin{vmatrix} 1 & a_1 \\ 1 & a_2 \end{vmatrix} = (a_2 - a_1) \]

Induction step: $n-1 \to n$.
\[
  \begin{vmatrix}
    1 & a_1 & a_1^2 & \ldots & a_1^{n-1} \\
    1 & a_2 & a_2^2 & \ldots & a_2^{n-1} \\
    \ldots & \ldots & \ldots & \ldots & \ldots \\
    1 & a_n & a_n^2 & \ldots & a_n^{n-1} \\
  \end{vmatrix}
  = \begin{vmatrix}
    1 & a_1       & \ldots        &        & a_1^{n-1} \\
    0 & a_2 - a_1 & a_2^2 - a_1^2 & \ldots & a_2^{n-1} - a_1^{n-1} \\
    \ldots & & & & \\
    0 & a_n-a_1 & a_2^2 - a_1^2 & & a_n^{n-1} - a_1^{n-1}
  \end{vmatrix}
\]

The following equation holds:
\[
  (x^n - y^n) = (x - y) \sum_{i=0}^{n-1} x^{n-1-i} y^i
\]

\[
  =
  \begin{vmatrix}
    (a_2 - a_1) & (a_2^2 - a_1^2) & (a_2^{n-1} - a_1^{n-1}) \\
    \vdots      & \vdots          & \vdots \\
    (a_n - a_1) & (a_n^2 - a_n^2) & (a_n^{n-1} - a_1^{n-1})
  \end{vmatrix}
  = \prod_{i=2}^n (a_j - a_1) \cdot
  \begin{vmatrix}
    1      & (a_2 + a_1) & (a_2^{n-2} + a_2^{n-3} a_1 + \ldots + a_1^{n-2}) \\
    1      & (a_3 + a_1) & \vdots \\
    \vdots & \vdots      & \vdots \\
    1      & (a_n + a_1) & (a_n^{n-2} + \ldots + a_1^{n-2})
  \end{vmatrix}
\] \[
  = \prod_{j=2}^n (a_j - a_1) \cdot
  \begin{vmatrix}
    1      & a_2    & a_2^2  & \ldots & a_2^{n-2} \\
    1      & a_3    & a_3^2  & \ldots & a_3^{n-2} \\
    \vdots & \vdots & \vdots & \ldots & \vdots \\
    1      & a_n    & a_n^2  & \ldots & a_n^{n-2}
  \end{vmatrix}
\] \[
  = \prod_{j=2}^n (a_j - a_1) \prod_{\substack{i < j \\ i,j \neq 1}}^n (a_j - a_i) = \prod_{i < j}^n (a_j - a_i)
\]

\subsection{Exercise 19b}

Show: there exists exactly one polynomial $p \in \mathbb K_n[x] (\forall i \in \set{0, \ldots, n}): p(x_i) = y_i$.

\[ p(x) = a_0 + a_1 x + a_2 x^2 + \ldots + a_n x^n \]

\[
  \begin{array}{cccccccc}
    a_0 & + & a_1 x_0 & + & \ldots & a_n x_0^n & = & y_0 \\
    a_0 & + & a_1 x_1 & + & \ldots & a_n x_1^n & = & y_1 \\
    \vdots & & & & & & & \\
    a_0 & + & a_1 x_n & + & \ldots & a_n x_n^n & = & y_n
  \end{array}
  \iff
  \begin{pmatrix}
    1 & x_0 & x_0^2 & \ldots & x_0^n \\
    1 & x_1 & x_1^2 & \ldots & x_1^n \\
    \vdots & &      & \ddots & \vdots \\
    1 & x_n & x_n^2 & \ldots & x_n^2
  \end{pmatrix} \begin{pmatrix}
    a_0 \\ a_1 \\ \vdots \\ a_n
  \end{pmatrix} = \begin{pmatrix}
    y_0 \\ y_1 \\ \vdots \\ y_n
  \end{pmatrix}
\]

\[ \det(M) = \prod_{i<j} (x_j - x_i) \]
\[
  \begin{pmatrix} a_0 \\ a_1 \\ \vdots \\ a_n \end{pmatrix}
  = \begin{pmatrix} 1 & \ldots & x_0^1 \\ \vdots & & \vdots \\ 1 & \ldots & x_n^n \end{pmatrix}
  \begin{pmatrix} y_0 \\ y_1 \\ \vdots \\ y_n \end{pmatrix}
\]

\subsection{Exercise 20}
\begin{ex}
  Let $A, B \in \mathbb K^{n\times n}$. Show by elementary row- and column transformations, that the following identity for block matrices holds:
  \[
    \begin{vmatrix}
     I & B \\
     -A & 0
    \end{vmatrix} = \begin{vmatrix}
      I & B \\
      0 & AB
    \end{vmatrix}
  \]
  Derive an alternative proof for the multiplication law of determinants ($\det(AB) = \det(A) \cdot \det(B)$).
\end{ex}

\begin{enumerate}
  \item We consider the left-hand side.
  \item We add the $n+1$-th row to the first row multiplied by $a_{11}$ and use the result as row $n+1$.
    As a result, the value in $a_{n+1,1}$ becomes $0$.
  \item We add the $n+2$-th row to the first row multiplied by $a_{21}$ and use the result as row $n+2$.
    As a result, the value in $a_{n+2,1}$ becomes $0$.
  \item We also do this process for columns and the second row.
  \item As a result we get $\begin{vmatrix} I & B \\ 0 & AB \end{vmatrix}$.
\end{enumerate}

\[
  \det(AB)
  = \begin{vmatrix} I & B \\ 0 & AB \end{vmatrix}
  = \begin{vmatrix} I & B \\ -A & 0 \end{vmatrix}
  = (-1)^n \begin{vmatrix} I & B \\ A & 0 \end{vmatrix}
  = (-1)^n (-1)^n \begin{vmatrix} A & 0 \\ I & B \end{vmatrix}
  = (-1)^{2n} \det(A) \det(B)
\]


\section{Exercise 21}
\begin{ex}
  Prove by induction:
  \[
    A \coloneqq
    \begin{vmatrix}
      \alpha & \beta & \beta & \ldots & \beta \\
      \beta & \alpha & \beta & \ldots & \beta \\
      \vdots &       &       & \ddots & \vdots \\
      \beta & \beta & \beta & \ldots & \alpha
    \end{vmatrix}
    = (\alpha - \beta)^{n-1} (\alpha + (n - 1) \beta)
  \]
\end{ex}

\begin{description}
  \item[Induction base] 
    For $n=1$, it holds that $|\alpha| = \alpha$. Induction base satisfied.
  \item[Induction step]
    \[
      \frac1{\alpha^n}
      \begin{vmatrix}
        \alpha & \alpha \beta & \alpha\beta & \ldots & \\
        \beta  & \alpha^2     &             &        & \\
        \vdots &              & \ddots      &        & \\
               &              &             &        & a^2
      \end{vmatrix}
    \] \[
       = \frac1{\alpha^n}
      \begin{vmatrix}
        \alpha & \alpha \beta & \alpha \beta & \ldots & \\
        \beta  & \alpha^2     &              &        & \\
        \vdots &              & \ddots       &        & \\
               &              &              &        & a^2
      \end{vmatrix}
    \] \[
       = \frac1{\alpha^n}
      \begin{vmatrix}
        \alpha & 0            & 0            & \ldots & \\
        \beta  & \alpha^2 - \beta^2 &              &        & \\
        \vdots & \beta (\alpha - \beta) & \ddots       &        & \\
               &              &              &        &
      \end{vmatrix}
    \] \[
      = \alpha \frac{1}{alpha^n}
      \begin{vmatrix}
        \alpha^2 - \beta^2 & & \beta (\alpha - \beta) \\
                           & \ddots & \\
        \beta (\alpha - \beta) &    & \alpha^2 - \beta^2
      \end{vmatrix} \eqqcolon d
    \]
    \begin{align*}
      d &=
          \frac{1}{\alpha^{n-1}} (\alpha^2 - \beta^2 - \alpha \beta + \beta^2)^{n-1}
          \left(\alpha^2 - \beta^2 + (n-1)(\alpha \beta - \beta^2) \right) \\
        &= \frac{1}{\alpha^{n-1}} (\alpha(\alpha - \beta))^{n-1} (\alpha + \beta)(\alpha - \beta) + (n-1)\beta(\alpha - \beta) \\
        &= \frac{1}{\alpha^{n-1}} \alpha^{n-1} (\alpha - \beta)^{n-1} \cdot (\alpha - \beta)(\alpha + \beta + (n-1) \beta) \\
        &= (\alpha - \beta)^n (\alpha + n\beta)
    \end{align*}
\end{description}

Again: the division by $\alpha$ implies that $\alpha \neq 0$. It is important to consider $\alpha = 0$. It is easy to show this case, but if you skip it, points are lost.

\section{Exercise 22}
\begin{ex}
  Let $P_i = (x_i, y_i)$ are pairwise different points in $\mathbb R^2$.
  \begin{enumerate}
    \item Show that the uniquely determined line $g$ crossing points $P_1$ and $P_2$ can be described by the following equation:
      \[ g = \set{(x,y) \in \mathbb R^2: \begin{vmatrix} 1 & x_1 & y_1 \\ 1 & x_2 & y_2 \\ 1 & x & y \end{vmatrix} = 0} \]
    \item Show that the uniquely determined circle $k$ crossing points $P_1$, $P_2$ and $P_3$,
      can be described by:
      \[
        k = \set{
          (x,y) \in \mathbb R^2:
          \begin{vmatrix}
            1 & x_1 & y_1 & x_1^2 + y_1^2 \\
            1 & x_2 & y_2 & x_2^2 + y_2^2 \\
            1 & x_3 & y_3 & x_3^2 + y_3^2 \\
            1 & x & y & x^2 + y^2
          \end{vmatrix}
        } = 0
      \]
      What is the result, if the points are colinear?
    \item Determine the center of the circle crossing points $(-4, 1)$, $(-2, -3)$ and $(4,5)$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 22a}
\[ k =\frac{y_2 - y_1}{x_2 - x_1} \]
Again, consider: $x_2 = x_1$ separately!

Laplace expansion along the last row:
\[ 1 \cdot (x_1 y_2 - x_2 y_1) - x(y_2 - y_1) + y(x_2 - x_1) \overset!= 0 \]
\[
  \underbrace{\frac{(x_1 y_2 - x_2 y_1)}{x_2 - x_1}}_{d}
  - x \underbrace{\frac{(y_2 - y_1)}{x_2 - x_1}}_{k}
\] \[
  y_0 = \frac{y_2 - y_1}{x_2 - x_1} x_1 + d
\] \[
  d = y_1 - \frac{(y_2 - y_1) x_1}{(x_2 - x_1) x_1}
  = \frac{y_1 x_2 - y_1 x_1 - y_2 x_1 + y_2 x_1}{x_2 - x_1}
\]
This corresponds to the slope of the line. Hence, our model matches the formula (the one involving the determinant).

What about $x_2 = x_1$? Then the second column is a linear combination of the others. Hence, determinant equals 0.

\subsection{Exercise 22b}

Consider 3 points $P_1$, $P_2$ and $P_3$.
Consider point $A$ half-way of $\overline{P_1 P_2}$.
Consider point $B$ half-way of $\overline{P_1 P_3}$.
If the line $g_1$, orthogonal to $P_1 P_2$ and crossing $A$, crosses with the line $g_2$,
orthogonal to $P_1 P_3$ and crossing $B$, meet this crosspoint $M$ is the center of the circumference circle of $P_1$, $P_2$ and $P_3$.

\[ v_1 = P_2 - P_1 = (2, -4) \to A = P_1 + \frac{v_1}{2} = (-3, -1) \]
\[ v_2 = P_3 - P_1 = (8, 4) \to B = P_1 + \frac{v_2}{2} = (0, 3) \]

\[ n_1 = \bot v_1 = (4, 2) \]
\[ n_2 = \bot v_2 = (4, -8) \]

\[ g_1 = A + t \cdot n_1 \]
\[ g_2 = B + s \cdot n_2 \]

\subsection{Exercise 22c}

\[ \vectwo{-3}{-1} + t \vectwo42 = \vectwo03 + s\vectwo{4}{-8} \]
Gives $t=1$ and
\[ \vectwo{-3}{-1} + 1 \vectwo42 = \vectwo11 = M \]

\subsection{Exercise 22b: What if all points are colinear?}

A generic circle equation is given by
\[ (x - \overline x)^2 + (y - \overline y)^2 = r^2 \]

\[ x^2 - 2x \overline x + \overline x^2 + y^2 - 2y\overline y + \overline y^2 = r^2 \]
\[ x^2 + y^2 = \underbrace{r^2 - \overline x^2 - \overline y^2}_{K} + 2 \overline y y + 2 \overline x x \]
\[ M \cdot \begin{pmatrix} K \\ 2 \overline x \\ 2 \overline y \end{pmatrix} = V \]
where $M$ are the first three columns and $V$ is the last column.

\section{Exercise 23}
\begin{ex}
  Let $A, B, C, D \in \mathbb K_{n\times n}$ be matrices.
  $D$ is invertible and $M$ is a $2n \times 2n$ block matrix.
  \[ M = \begin{bmatrix} A & B \\ C & D \end{bmatrix} \]
  \begin{enumerate}
    \item Show: $M$ is invertible iff $A - BD^{-1}C$ is invertible
    \item Show: $\det(M) = \det(A - BD^{-1} C) \det(D)$
  \end{enumerate}
\end{ex}

\subsection{Exercise 23a}
\[ \det(M) = \underbrace{\det(A - BD^{-1} C)}_{\neq 0 \text{ if invertible}} \underbrace{\det(D)}_{\neq 0 \text{ if invertible}} \]
$\det(D)$ is invertible by the exercise specification.
\[ \det(A - BD^{-1} C) \neq 0 \implies A - BD^{-1} C = \text{ invertible} \]

\subsection{Exercise 23b}
\[
  M = \begin{bmatrix} A & B \\ C & D \end{bmatrix}
  = \begin{bmatrix} I & B \\ 0 & D \end{bmatrix} \begin{bmatrix} A-BD^{-1}C & 0 \\ D^{-1}C & I \end{bmatrix}
\] \[
  \begin{vmatrix} I & B \\ 0 & D \end{vmatrix}
  \begin{vmatrix} A - BD^{-1} C & 0 \\ D^{-1} C & I \end{vmatrix}
  = \det(D) \cdot \det(A - BD^{-1}C) \det(I)
\]

\section{Exercise 25}
\begin{ex}
  Let $A$ be a $m \times n$ matrix. Show that $\rank(A)$ is identical with the largest number $k \in \set{1,2,\ldots,\min(m,n)}$ for which a non-vanishing subdeterminant of order $k$ exists, hence
  index sets $i_1 < i_2 < \ldots < i_k$ and $j_1 < j_2 < \ldots < j_k$, such that
  \[
    \card{A_{i_k,j_k}} \coloneqq
    \begin{vmatrix}
      a_{i_1,j_1} & a_{i_1,j_2} & \ldots & a_{i_1,j_k} \\
      a_{i_2,j_1} & a_{i_2,j_2} & \ldots & a_{i_2,j_k} \\
      \ldots      & \ldots      & \ddots & \vdots      \\
      a_{i_k,j_1} & a_{i_k,j_2} & \ldots & a_{i_k,j_k} \\
    \end{vmatrix}
    \neq 0
  \]
\end{ex}

Assume $k \geq \rank(A)$.
\[ A \to \tilde A \]
$m - \rank(A)$ rows and $n - \rank(A)$ columns.
$\rank(A)$ is the number linear independent rows (or equivalently, columns)

\[ \implies k \leq \rank(A) \implies k = \rank(A) \]

\section{Exercise 26}
\begin{ex}
  Let $A \in \mathbb K^{m\times n}, B \in \mathbb K^{n \times m}$. Show that
  \[
    \det(AB) = \sum_{i_1 < i_2 < \ldots < i_m}
    \begin{vmatrix}
      a_{1i_1} & a_{1i_2} & \ldots & a_{1i_m} \\
      a_{2i_1} & a_{2i_2} & \ldots & a_{2i_m} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{mi_1} & a_{mi_2} & \ldots & a_{mi_m}
    \end{vmatrix}
    \begin{vmatrix}
      a_{i_11} & a_{i_21} & \ldots & a_{i_m1} \\
      a_{i_12} & a_{i_22} & \ldots & a_{i_m2} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{i_1m} & a_{i_2m} & \ldots & a_{i_mm}
    \end{vmatrix}
  \]
  Hint: Use Leibniz formula.
\end{ex}

\[ \det(AB) = \sum \det(A_{i_m \ldots}) \det(B^{i_1 \ldots i_m}) \]
\[ A,B \in \mathbb K^{m \times m} \]
\[ \det(AB) = \sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^m (AB)_{i \sign(i)} =
  \sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^n \left(\sum_{k=1}^n A_{i,k} B_{k \sigma(i)} \right)
\]
Let $N = \set{1, \ldots, n}$. Let $M = \set{1, \ldots, m}$. Let $N^M$ be the functions mapping $M$ to $N$.
\[
  \sum _{\sigma \in \sigma_n} \sign(\sigma) \sum_{k \in N^M} \prod_{i=1}^m A_{i k(i)} B_{k(i) \sigma(i)}
\] \[
  = \sum_{k \in N^M} \sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^m A_{ik(i)} \prod_{i=1}^m B_{k(i) \sigma(i)}
  = \sum_{k \in N^M} \prod_{i=1}^m A_{i k(i)} \underbrace{\sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^m B_{k(i) \sigma(i)}}_{\det(B^{k(1) \ldots k(m)})}
\]
Let $k, \tilde k \in N^M$. $k \sim \tilde k :\iff \image(k) = \image(\tilde k)$.
\[ = \sum_{k \in N^M \text{injective} / \sim} \sum_{\tilde k \sim k} \prod_{i=1}^m A_{ik(i)} \underbrace{\det(B^{(\tilde k(1) \ldots \tilde k(m))})}_{\sign(\delta) \det(B^{k(1) \ldots k(m)} \text{ with } k(1) < k(2) < \ldots < k(n)}) \]
where $\cdot/\sim$ denotes the set of equivalence classes. $\tilde k \sim k \implies \exists \delta \in \delta_m: \tilde k = k \circ \delta$.
\[ = \sum_{k \in N^M \text{ injective} / \sim} \left(\sum_{\delta \in \delta_m} \sign(\delta) \prod A_{i k(\delta_i)}\right) \det(B^*) \]

\section{Exercise 28}
\begin{ex}
  Let $A \in \mathbb C^{n \times n}$ be a Hermitian matrix. Show
  \begin{enumerate}
    \item $A \geq 0 \iff \exists B \in \mathbb C^{n \times n}: A = B^* \cdot B$
    \item $A > 0 \implies A \text{ regular and } A^{-1} > 0$
    \item Let $A \geq 0 \implies a_{ii} \geq 0 \forall i$ and if $\exists i: a_{ii} = 0 \implies a_{ij} = 0$
    \item Does the following generalized first-minors criterion apply?
      \enquote{A $n \times n$ matrix $A$ is positive semidefinite iff $\det{A_r} \geq 0 \forall r = 1, 2, \ldots, n$}
  \end{enumerate}
\end{ex}

\subsection{Exercise 28a}

Direction $\Leftarrow$.

Let $B$ be given such that $B^* \cdot B = A$.

\[ z^* \cdot B^* \cdot B \cdot z = (Bz)^* \cdot B \cdot z \]
\[ (Bz)^* = z^* B^* \]
\[ (Bz)^* Bz = [v_1, \ldots, v_n] \cdot \begin{bmatrix} \overline{v_1} \\ \vdots \\ \overline{v_n} \end{bmatrix} \coloneqq \sum_{i=1}^n \overline{v_1} \cdot v_1 = \sum_{i=1}^n \card{v_i}^2 \geq 0 \]

Direction $\Rightarrow$.

Side remark:
\[
  \begin{bmatrix} I_r & 0 \\ 0 & 0 \end{bmatrix}^2 =
  \begin{bmatrix} I_r & 0 \\ 0 & 0 \end{bmatrix}
\]

Let $A \geq 0$.
\[
  \implies \exists C \in \mathbb C^{n \times n}:
  A = C^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} C
\] \[
  A = C^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} C = C^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix}^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} C = (C')^* \cdot C' \iff A = (C')^* \cdot C'
\]

\subsection{Exercise 28b}

$A > 0$, iff $A \hat= I_n$.

\[ B^* AB = I_n \iff B^* AB = I_n \iff AB = (B^*)^{-1} \iff ABB^* = I_n \]
\[ B^*A = B^{-1} \qquad \underbrace{BB^* A}_{A^{-1}} = I_n \]

$A^{-1} > 0$.

\[ A^{-1} \hat= I_n \iff \exists C \in \operatorname{GL}(n, \mathbb C): C^* \cdot A^{-1} \cdot C = I_n \iff A^{-1} = (C^*)^{-1} \cdot C^{-1} \]
\[ A^{-1} = B \cdot B^* \qquad (B^{-1})^* = C \]

\subsection{Exercise 28c}

Show: $A \geq 0 \implies a_{ii} = 0$ and $a_{ii} = 0 \implies \text{ without loss of generality } a_{11} = 0 \qquad a_{1i} \neq 0 \quad a_{ij} = 0 \forall j$.

\[ A = B^* B \implies a_{11} = \sum_{j=1}^n \overline{b_{j1}} \cdot b_{j1} = \sum_{j=1}^n \card{b_{j1}}^2 \overset!= 0 \]
\[ \implies b_{j1} = 0 \forall j \]
\[ a_{1i} = 0 \qquad \text{gives a contradiction} \]

\subsection{Exercise 28d}

\[ A = 0 \iff \det(A_r) \geq 0 \forall r \in \set{1, \ldots, n} \]
\[
  \begin{vmatrix}
    1 & 0 & 0 \\
    0 & 0 & 0 \\
    0 & 0 & -1
  \end{vmatrix}
\]

\section{Exercise 29}
\begin{ex}
  Show
  \begin{enumerate}
    \item $A \leq B :\iff B - A \geq 0$ (hence $B-A$ is semidefinite) defines an order relation on the set of self-adjoint matrices.
    \item If $B > 0$ and $A \geq B$, then $A > 0$
  \end{enumerate}
\end{ex}

\subsection{Exercise 29a}

An order relation is a partial order. We show:
\begin{description}
  \item[reflexivity] $xRx$
  \item[anti symmetry] $xRy \land yRx \implies x = y$
  \item[transitivity] $xRy \land yRz \implies xRz$
\end{description}

We show antisymmetry.

\[ \forall A \in M \text{ with } B-A \geq 0 \text{ and } A - B = 0 \]
it holds that $\forall x \in V:$
\[ x^T (B - A) \overline{x} \geq 0 \land x^T (A - B) \overline{x} \geq 0 \]
\[ x^T (B - A) \overline{x} = 0 \implies x^T B \overline{x} = x^T A \overline{x} \]


\[ B - A = C^* DC \]
\[ D = \begin{bmatrix} 1 &  & & &  & \\ & \ddots & & &  & \\ & & 1 & & & \\ & & & 0 & & \\ & & & & \ddots & \\ & & & & & 0 \end{bmatrix} \]

\[ A - B = C^* (-D) C \]
\[ D = -D = 0 \]
\[ \implies B = A \]

We show reflexivity.

\[ \forall A \in M \forall x \in V: 0 = x^T \cdot 0 \cdot \overline{x} = x^T (A - A) \overline{x} = 0 \implies A - A \geq 0 \]

We show transitivity.

\[ \forall A, B, C \in M: B - A \geq 0 \land A - B > 0 \]

It holds that
\[ \forall x \in V: x^T (B - A) \overline{x} \geq 1 \qquad x^T (C - B) \overline{x} \geq 0 \]
\[ \implies 0 \leq x^T (B - A) \overline{x} + x^T (C - B) \overline{x} \]
\[ = x^T \left((B - A) \overline{x} + (C - B) \overline{x}\right) = x^T (B - A, C - B) \overline{x} = \underbrace{x^T (C - A) \overline{x}}_{0 \leq} \]
\[ \implies C - A \geq 0 \]

\subsection{Exercise 29b}

Let $B > 0$ and $A \geq B$ then it holds that $A > 0$.
\[ \forall x \in V: x^T B \overline{x} > 0: x^T (A - B) \overline{x} - x^T A \overline{x}- x^T B \overline{x} \geq 0 \]
\[ \implies x^T A \overline{x} \geq x^T B \overline{x} > 0 \]


\[ \langle x, x\rangle_B = x^T B x = x^T Ax = \langle x,x\rangle_A \]
\[ x = e_j \implies B_{jj} = A_{jj} \]

\[ A = 0 \qquad B = \operatorname{rot}(\frac\pi2) \qquad \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} = \pi \]

\section{Exercise 30}
\begin{ex}
  Let $Tr(A) = \sum_{i=1}^n a_{ii}$ be the trace of an $n\times n$ matrix over $\mathbb R$ or $\mathbb C$.
  Show:
  \begin{enumerate}
    \item $Tr: \mathbb K^{n\times n} \to \mathbb K$ is linear and for $A \in \mathbb K^{n\times m}, B \in \mathbb K^{m\times n}$ it holds that $Tr(AB) = Tr(BA)$ but in general $Tr(ABC) = Tr(ACB)$ does not hold.
    \item Let $A,B$ be $n\times n$ matrices. $B$ is invertible. Show $Tr(B^{-1}AB) = Tr(A)$.
    \item Show: $\not\exists A,B: AB - BA = I$
    \item Show that $\langle A,B\rangle = Tr(B^*A)$ defines a positive definite scalar product over $\mathbb C^{n\times n}$.
    \item Find a real matrix $A$ such that $Tr(A^2) < 0$
    \item For a fixed positive definite matrix $A$, $\langle A,B\rangle_Q = Tr(B^*QA)$ defines a positive definite scalar product.
  \end{enumerate}
  Hint: Exercise 28 can be helpful.
\end{ex}

\subsection{Exercise 30a}

Show linearity.
\[ \forall A,B \in \mathbb K^{n \times n}: \underbrace{Tr(A + B)}_{\sum_{i=1}^n (a_{ii} + b_{ii})} = \underbrace{Tr(A)}_{\sum_{i=1}^n a_{ii}} + \underbrace{Tr(B)}_{\sum_{i=1}^n b_{ii}} \]
\[ \lambda \in K: \lambda Tr(A) + Tr(\lambda A) \]
\[ \lambda \sum_{i=1}^n a_{ii} = \sum_{i=1}^n \lambda a_{ii} \]

Show that multiplication is commutative for two traces.
Let $A \in \mathbb K^{n\times m}, B \in \mathbb K^{m\times n}$.
\[ Tr(AB) = Tr(BA) \]
\[ \sum_{i=1}^n \sum_{j=1}^m a_{ij} b_{{ji}} = \sum_{i=1}^m \sum_{j=1}^n b_{ij} a_{ji} = \sum_{i=1}^m \sum_{j=1}^n a_{ji} b_{ij} \]

Show that multiplication is not commutative in general. Does not hold unless $B = C$.
\[ Tr(ABC) \neq Tr(ACB) \]

\subsection{Exercise 30b}

Show that $Tr(B^{-1}(AB)) = Tr(A) \iff Tr(ABB^{-1}) = Tr(A)$.

\subsection{Exercise 30c}

Let $A, B \in \mathbb K^{n\times n}$.
\[ Tr(I_n) = n \]
\[ Tr(AB - BA) = Tr(AB) - Tr(BA) = 0 \]
\[ 0 \neq n \]
This gives a contradiction.

\subsection{Exercise 30d}

\begin{enumerate}
  \item Sesquilinearity:
    \[ \langle A+\lambda B, C\rangle \overset!= \angel{A,C} + \lambda \angel{B,C} \]
    \[ \angel{A, C+\lambda B} = Tr((C + \lambda B)^* A) = Tr((C^* + \overline{\lambda} B^*) A) = Tr(C^* A + \lambda B) \]
  \item Positive definiteness:
    \[ \angel{A,A} > 0 \qquad A \neq 0 \]
    \[ \Tr(A^*A) = \sum_{j=1}^n \sum_{l=1}^n \overline{a}_{l_j} a_{l_j} = \sum_{j=1}^{n} \sum_{l=1}^{n} \card{a_{lj}}^2 \]
\end{enumerate}

\subsection{Exercise 30e}

\[ A = \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} \]

\subsection{Exercise 30f}

$Q$ is positive definite.
\begin{align*}
  \angel{A,B}_Q &= Tr(B^*QA) \\
  \angel{A,A}_Q &= Tr(A^* M^* M A) \\
    &= Tr((MA)^* MA) \\
    &= \sum_{i=1}^n \sum_{j=1}^n \overline{(ma)}_j (ma)_j = \sum_{i=1}^n \sum_{j=1}^n  \card{ma_j}^2
\end{align*}

\[ Q = C^* DC \]
\[ \exists M: (Q)^{-1} = (M^* M)^{-1} = M^{-1} (M^*)^{-1} \]

Show $MA \neq 0$ if $A \neq 0$ and $\exists M^{-1} \iff A = M^{-1} 0$ gives a contradiction. Thus, we are finished.

\section{Exercise 31}
\begin{ex}
  Let $A, B \in \mathbb C^{n\times n}$ be Hermitian matrices. Show:
  \begin{enumerate}
    \item $A \geq 0 \iff \exists x_1, x_2, \dots, x_n \in \mathbb C^{n\times 1}: A = \sum_{i=1}^n x_i x_i^*$.
    \item Let $C$ be the matrix with entries $c_{ij} = a_{ij} b_{ij}$. If $A \geq 0$ and $B \geq 0$, then also $C \geq 0$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 31a}

By Exercise 28, we know: $A \geq 0 \implies \exists B: A \cdot B^* \cdot B$.
\[ x_i \ldots (B^*)_i \qquad x_i^* \ldots (B)_i \]

\[ (x_i \cdot x_i^*)_W = x_i^k \cdot x_i^{*j} \]
\[ \sum_{i} (x_i x_i^*)_{k,j} = (B^*)_k \cdot (B)_j \]

\[ a_{kj} = \sum_{i=1}^n b_k^* b_{ij} \]

\subsection{Exercise 31b}

Direction $\Leftarrow$.

\[ A = \sum_{i=-1}^n x_i x_i^* \]
\[ y^T A \overline{y} = y^T \sum_{i=1}^n x_i x_i^* \cdot \overline{y} = \sum (y^T x_i)_{1\times 1} (x_i^* \overline{y})_{1 \times 1} = \sum \norm{y^T x_i}^2 \geq 0 \]

Direction $\Rightarrow$.

\[ A = \sum x_i x_i^* \qquad B = \sum y_i y_i^* \]
\[
  c_{ij} = a_{ij} \cdot b_{ij}
    = \sum_{k=1}^n x_k^i \cdot \overline{x_k^j} \cdot \sum_{l=1}^n y_l^i \overline{y_l^j}
    = \sum_{k,l=1}^n \underbrace{\left(x_k^i y_l^j\right)}_{z_{k,l^i}} \underbrace{\left(\overline{x_k^j} \overline{y_l^j}\right)}_{\overline{z_{k,l^j}}}
\]
\[
  \implies C = \sum_{k,l=1}^n z_{k,l} \cdot z_{k,l}^*
\]

\section{Exercise 32}
\begin{ex}
  Let $(V, \ip{.}{.})$ be a vector space with scalar product and $U \subseteq V$ is a subspace. Show:
  \begin{enumerate}
    \item $U^\bot = U^{\bot\bot\bot}$;
    \item $V = U \dot{+} U^{\bot} \implies U = U^{\bot\bot}$.
    \item Show that the following construction is a counterexample for inversion of the previous statement:
      $V = C[-1,1]$ with scalar product $\langle f,g\rangle = \int_{-1}^1 f(t) g(t) \, dt$
      and subspace $U = \set{f \in C[-1,1] \middle| f(t) = 0 \forall t < 0}$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 32a}

\[ U^\bot = \set{v \in V: \forall u \in U: \ip uv = 0} \]
We prove:
\begin{enumerate}
  \item $U^\bot \subseteq U^{\bot\bot\bot}$
  \item $U^\bot \supseteq U^{\bot\bot\bot}$
\end{enumerate}

We begin with (1.)

Let $v \in U^\bot \implies v \in U^{\bot\bot\bot}$
\[ U^{\bot\bot\bot} = \set{v \in V \middle| \ip{v}{u''} = 0 \forall u'' \in U^{\bot\bot}} \]
By definition, this satisfies the claim.

In other words: we know $U \subseteq U^{\bot\bot}$. Consider $W = U^{\bot}$. Then $W \subset W^{\bot\bot}$.

We prove (2.)

Let $x \in U^{\bot\bot\bot} \implies \forall u \in U^{\bot\bot}: \ip xu = 0$.
Because $U \subseteq U^{\bot\bot}$, $\implies \forall u' \in U: \ip{x}{u'} = 0 \implies x \in U^{\bot}$.
Hence $U^{\bot} \in U^{\bot\bot\bot}$.

\subsection{Exercise 32b}

\[ V = U + U^{\bot} \implies U = U^{\bot\bot} \]
Show that $U^{\bot\bot} \subseteq U$.
Let $x \in U^{\bot\bot}$. $x = U + W$. $u \in U, w \in U^{\bot}$.
\[ \implies \forall y \in U^{\bot}: \ip xy = 0 = \ip{u+w}{y} = \ip uy + \ip wy = 0 \implies w = 0 \]
\[ \implies x = u \in U \]

\subsection{Exercise 32c}
Example for $U = U^{\bot\bot}$ but $V \neq U + U^{\bot}$.

\[ V = [-1,1] \qquad \ip fg = \int_{-1}^1 f(x) \cdot g(x) \, dx \]
\[ U = \set{f \in C[-1,1]: f(t) = 0 \forall t < 0} \]

Claim:
\[ U^{\bot} = \set{f \in C[-1,1], f(t) = 0 \forall t \geq 0} \]

Assume $f \in U^{\bot}$. Choose $g \in U$. We build a triangle below the point $f(g)$ and function $f$. The area of the triangle is non-negative and therefore non-zero.

Claim:
\[ U^{\bot\bot} = \set{f \in C[-1,1], f(t) = 0 \forall t < 0} \implies U = U^{\bot\bot} \]

\section{Exercise 33}
\begin{ex}
  Let $V = \mathbb R^{n\times n}$ and $\langle A,B\rangle = \operatorname{Tr}(B^TA)$ the scalar product of Exercise~30.
  Determine the orthogonal complement.
  \[ \set{A \in \mathbb R^{n\times n} \middle| A = A^T}^\bot \]
\end{ex}

\[ U = \set{A \in \mathbb R^{n\times 1}: A = A^T}, \qquad V = \mathbb R^{n\times n} \]
\[
  A_{ii} = \begin{pmatrix}
    0 &   & 0 \\
      & 1 & \\
    0 &   & 0
  \end{pmatrix}
\]
positive at $(i,i)$.
\[
  A_{ij} = \begin{pmatrix}
    0 &   & 1 \\
      & 0 &  \\
    1 &   & 0
  \end{pmatrix}
\]
positive at $(j,i)$ with $i \neq j$.

\[ \Tr(B^T A) = \sum_{k,i=1}^n B_{ik} A_{ki} \overset!= 0 \]

For $A = A_{ii} \implies B_{ii} = 0$.
For $A = A_{ij} \implies B_{ij} + B_{ji} = 0$.
Skew-symmetric.

\section{Exercise 34}
\begin{ex}
  Let
  \[ U = \set{x \in \mathbb R^5 \middle| \substack{x_1 - x_2 + x_3 - x_4 + x_5 = 0 \\ x_1 + x_3 + x_5 = 0}} \]
  be a subspace of $\mathbb R^5$ and $v = (1,-1,1,-1,1)^T$.
  \begin{enumerate}
    \item Determine the orthogonal projection $\pi_U(v)$ using the Gramian matrix.
    \item Determine the orthonormal basis of $U$
    \item Determine $\pi_U(v)$ using the orthonormal basis.
    \item Determine the matrix representation of $\pi_U$ in terms of the canonical basis.
  \end{enumerate}
\end{ex}

\subsection{Exercise 34b}

\[ \tilde a_1 = \begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} \]
\[ \norm{\tilde a_1} = \sqrt2 \]
\[ a_1 = \frac1{\sqrt2} \tilde a_1 \]
\[ \tilde a_2 = \begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix} - \frac12 \ip{\begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}}{\begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix}} \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} = \begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix} \]
\[ \norm{\tilde a_2} = \sqrt2 \qquad a_2 = \frac1{\sqrt{2}} \tilde a_2 \]
\[ \tilde a_3 = \begin{pmatrix} -1 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix} - \frac12 \ip{\begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}}{\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}} \begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} = \frac12 \ip{\begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix}}{\begin{pmatrix} -1 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}} \begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix} = \begin{pmatrix} -\frac12 \\ 0 \\ -\frac12 \\ 0 \\ 1 \end{pmatrix} \]
\[ \norm{\tilde a_3} = \frac{\sqrt{6}}{2} \qquad a_3 = \frac2{\sqrt{6}} \tilde a_3 \]

\subsection{Exercise 34d}

\[ P = \sum_{i=1}^3 a_i a_i^* \]
\[
  P = \begin{pmatrix}
    \frac23 & 0 & -\frac23 & 0 & -\frac13 \\
    0 & \frac12 & 0 & -\frac12 & 0 \\
    -\frac23 & 0 & \frac23 & 0 & \frac13 \\
    0 & -\frac12 & 0 & \frac12 & 0 \\
    -\frac13 & 0 &\frac13 & 0 & \frac23
  \end{pmatrix}
\]


\section{Exercise 35}
\begin{ex}
  Given the data $\vec x = (-2, -1, 1, 2)$ and $y = (1,1,-1, 1)$. Determine the coefficients $a_0, a_1, a_2$ of the quadratic polynomial function $f$ using an orthogonal projection.
  \[ f: \mathbb R \to \mathbb R \qquad x \mapsto a_0 + a_1 x + a_2 x^2 \]
  such that the value
  \[ \sum_{i=1}^4 (f(x_i) - y_i)^2 \]
  is minimal. Reason that the solution is unique.
\end{ex}

\end{document}
