\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{baskervald}
\usepackage{bbold}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{faktor}
\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red]{hyperref}
\usepackage{imakeidx} % before hyperref
\usepackage{mathalfa}
\usepackage{mathtools}
\usepackage{mdframed}
\usepackage[bigdelims,vvarbb]{newtxmath}
\usepackage{rotating}
\usepackage{stmaryrd}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{xcolor}

\renewcommand*\oldstylenums[1]{\textosf{#1}}

\theoremstyle{definition}
\newmdtheoremenv[%
  backgroundcolor=white,
  linecolor=white!60!black,
  linewidth=3pt]{ex}{Exercise}

\DeclareMathOperator\kernel{kernel}
\DeclareMathOperator\image{image}
\DeclareMathOperator\sign{sign}
\DeclareMathOperator\Hom{Hom}
\DeclareMathOperator\Tr{Tr}

\title{Linear Algebra 2 -- Practicals}
\author{Lukas Prokop}
\date{summer term 2018}

\newcommand\dateref[1]{These practicals took place on #1.\par}
\newcommand\meta[3]{This #1 took place on #2 (#3).\par}
\newcommand\abs[1]{|\,#1\,|}
\newcommand\set[1]{\left\{#1\right\}}
\newcommand\setdef[2]{\left\{#1\,\middle|\,#2\right\}}
\newcommand\card[1]{\left|\,#1\,\right|}
\newcommand\divides[2]{#1\,\mid\,#2}
\newcommand\angel[1]{\langle#1\rangle}
\newcommand\mathspace{\hspace{20pt}}
\newcommand\fun[1]{\left\langle{#1}\right\rangle}
\newcommand\ip[2]{\langle{#1},{#2}\rangle}
\newcommand\norm[1]{\left\|{#1}\right\|}
\newcommand\vectwo[2]{\begin{pmatrix} #1 \\ #2 \end{pmatrix}}
\newcommand\Q{\mathbb{Q}}
\newcommand\nope{\lightning}
\newcommand\vecfour[4]{\begin{pmatrix} #1 \\ #2 \\ #3 \\ #4 \end{pmatrix}}
\newcommand{\textgreek}[1]{\begingroup\fontencoding{LGR}\selectfont#1\endgroup}

\DeclareMathOperator\rank{rank}

\parindent0pt
\parskip7pt
\setcounter{tocdepth}{1}

\begin{document}

\maketitle
\tableofcontents

\clearpage

Exercises, I did on the board: 

\section*{Exercise 1}
\begin{ex}
  Determine the matrix representation of the linear map
  \[ f: \mathbb R_2[x] \to \mathbb R_3[x] \]
  \[ p(x) \mapsto x \cdot p(x) \]
  in terms of the bases $B = \set{1, x, x^2 - 1} \subseteq \mathbb R_2[x]$ and $C = \set{1, x, x^2 - 1, x^3 - 2x} \subseteq \mathbb R_3[x]$
\end{ex}

\subsection{Blackboard solution}

\[ \mathcal L(\set{\underbrace{1, x, x^2-1}_{b_1, b_2, b_3}}) \to \mathcal L(\set{\underbrace{1, x, x^2-1, x^3 - 2x}_{c_1, c_2, c_3, c_4}}) \]
\[ f: \alpha \mapsto x \cdot \alpha \]

\[ f(1) = x = 1 c_2 \]
\[ f(x) = x = x^2 = 1c_3 + 1 c_1 \]
\[ f(x^2-1) = x^3 - x = 1 c_4 + 1 c_2 \]

\[
  \begin{matrix}
        & b_1 & b_2 & b_3 \\
  \hline
    c_1 & 0 & 1 & 0 \\
    c_2 & 1 & 0 & 1 \\
    c_3 & 0 & 1 & 0 \\
    c_4 &   & 0 & 1
  \end{matrix}
\]

\subsection{My solution}

\begin{align*}
  B &= \set{1, x, x^2 - 1} \eqqcolon \set{b_1, b_2, b_3} \\
  C &= \set{1, x, x^2 - 1, x^3 - 2x} \eqqcolon \set{c_1, c_2, c_3, c_4}
  f(b_1) &= x \cdot (1) = x \\
  f(b_2) &= x \cdot (x) = x^2 \\
  f(b_3) &= x \cdot (x^2 - 1) = x^3 - x
\end{align*}

\begin{align*}
  x &= \lambda_1 \cdot 1 + \lambda_2 \cdot x + \lambda_3 \cdot (x^2 - 1) + \lambda_4 \cdot (x^3 - 2x) \\
    &= \lambda_1 - \lambda_3 + (\lambda_2 - 2 \lambda_4) x + \lambda_3 x^2 + \lambda_4 x^3
\end{align*}
By coefficient comparison, we get $\lambda_1 = \lambda_3 = 0$ and $\lambda_2 - 2\lambda_4 = 1$ where $\lambda_4 \stackrel!= 0$. Hence $\lambda_2 = 1$.

\[ \implies \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} \]

\begin{align*}
  x^2 &= \lambda_1 - \lambda_3 + (\lambda_2 - 2 \lambda_4) x + \lambda_3 x^2 + \lambda_4 x^3
\end{align*}
By coefficient comparison, we get $\lambda_3 = 1$ and $\lambda_1 = \lambda_2 = \lambda_4 = 0$.

\[ \implies \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix} \]

\begin{align*}
  x^3 - x &= \lambda_1 - \lambda_3 + (\lambda_2 - 2 \lambda_4) x + \lambda_3 x^2 + \lambda_4 x^3
\end{align*}
By coefficient comparison, we get $\lambda_1 = \lambda_3 = 0$ and $\lambda_2 - 2 \lambda_4 = -1$ with $\lambda_4 \stackrel!= 1$, hence $\lambda_2 = 1$.

\[ \implies \begin{pmatrix} 0 \\ 1 \\ 0 \\ 1 \end{pmatrix} \]

So our solution is,
\[
  M =
  \begin{pmatrix}
    0 & 0 & 0 \\
    1 & 0 & 1 \\
    0 & 1 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\]

\section*{Exercise 2}
\begin{ex}
  A chain complex $C$ is a sequence of linear maps
  \[ 0 = V_n \xrightarrow{f_n} V_{n-1} \xrightarrow{f_{n-1}} V_{n-2} \xrightarrow{f_{n-2}} \cdots \xrightarrow{f_1} V_0 \xrightarrow{f_0} 0 \]
  with the property such that $\operatorname{im}{f_{k+1}} \subseteq \operatorname{ker}{f_{k}}$ for all $0 \leq k \leq n-1$, hence,
  $f_k \circ f_{k+1} = 0$. The quotient space $H_k(C) = \operatorname{ker}{f_k} / \operatorname{im}{f_{k+1}}$ is called $k$-th \emph{homology}
  of the complex. Show that for finite-dimensional chain complexs (hence, $\dim{V_k} < \infty$ for all $k$) the following formula holds:
  \[ \sum_{k=0}^{n-1} (-1)^k \dim{V_k} = \sum_{k=0}^{n-1} (-1)^k \dim{H_k}(C) \]
\end{ex}

\subsection{Blackboard solution}

$V \subset W$ vector spaces.
\[ V = \mathcal L\set{v_1, \dots, v_n} \qquad W = \mathcal L\set{v_1, \dots, v_n, w_1, \dots, w_n} \]

$\faktor{W}{V} = \set{[x]_V: x \in W}$

\[ [x]_n \coloneqq \setdef{x+v}{v \in V} \]

$[w_1]_v, \dots, [w_n]_v$ is a basis of vector space $\faktor{w}{v}$.

for $x, y \in W$,
\[ x \sim_V y \coloneqq x - y \in V \]
\[ y + v_2 \in [y]_V \]
\[ [x]_V \bigodot [y]_V = [x + v_1 + y + v_2]_V \]

\[ [x]_V \bigodot [y]_V = [x+y]_V \]
\[ \alpha [x]_V = [\alpha x]_V \]


\[ \sum_{k=0}^{n-1} (-1)^k \dim{V_k} = \sum_{k=0}^{n-1} (-1)^k \dim{H_k(C)}. \]

where $\dim(V_k) = \dim\kernel(f_k) + \dim\image(f_k)$ and $\dim(H_k) = \dim\kernel(f_k) - \dim\image(f_k) = \dim\kernel(f_k) - \dim\image(f_{k+1})$.

\section*{Exercise 3}
\begin{ex}
  Let $A \in \mathbb K^{n\times n}$ be a nilpotent matrix, hence, there exists $k \in \mathbb N$ such that $A^k = 0$.
  \begin{itemize}
    \item Show that $I - A$ is invertible with $(I - A)^{-1} = I + A + A^2 + \dots + A^{k-1}$.
    \item Use the previous result to derive the inverse of the matrix:
      \[
        \begin{pmatrix}
          1 & a & b & c \\
          0 & 1 & a & b \\
          0 & 0 & 1 & a \\
          0 & 0 & 0 & 1
        \end{pmatrix}
      \]
  \end{itemize}
\end{ex}

\subsection{Blackboard solution}

\[ 1 + x + x^2 + x^3 + \dots + x^{n-1} = \frac{x^n - 1 [= (x-1)(1 + x + x^2 + \dots + x^{n-1}])}{x-1} \]

Just verify:
\[ (I - A)(I - A + A^2 + \dots + A^{n-1}) \]

\section*{Exercise 4}
\begin{ex}
  \begin{enumerate}
    \item Let $A$ be an invertible $n \times n$ matrix over the field $\mathbb K$ and $u,v$ are column vectors (hence, $n\times 1$ matrices),
          such that $\sigma = 1 + v^t A^{-1} u \neq 0$. Show that $(A + uv^t)$ is invertible and that
          \[ (A + uv^t)^{-1} = A^{-1} - \frac1\sigma A^{-1} uv^t A^{-1} \]
    \item Apply this formula, to determine the inverse of matrix
          \[
            \begin{pmatrix}
              5 & 3 & 0 & 1 \\
              3 & 2 & 0 & 0 \\
              0 & 0 & 2 & 3 \\
              0 & 0 & 3 & 5
            \end{pmatrix}
          \]
          efficiently.
  \end{enumerate}
\end{ex}

\subsection{Blackboard solution}

\[ (A + uv^t)^{-1} = A^{-1} - \frac1\sigma A^{-1} uv^t A^{-1} \qquad \text{ (Sherman-Morrison-Formula)} \]
\[ \sigma = 1 + v^t A^{-1} u \neq 0 \]

\[ (A + uv^t)(A^{-1} - \frac1\sigma A^{-1} uv^t A^{-1}) = A A^{-1} + uv^t A^{-1} - \frac1\sigma (A A^{-1} uv^t A^{-1} + uv^t A^{-1} uv^t A^{-1}) \]
\[ = I + uv^t A^{-1} - \frac1\sigma (uv^t A^{-1} + (v^t A^{-1} u) uv^t A^{-1} )\]
\[ = I + uv^t A^{-1} - \frac1\sigma (1 + v^t A^{-1} u) uv^t A^{-1} \]
\[ = I + uv^t A^{-1} - \frac\sigma\sigma uv^t A^{-1} = I \]

\dateref{2018/03/14}

\section*{Exercise 5}
\begin{ex}
  \begin{enumerate}
    \item[a.] Determine the dual basis of $(\mathbb R)^4$ to $B$
    \[
      B \coloneqq \set{
        \begin{pmatrix} 1 \\ 2 \\ 1 \\ 0 \end{pmatrix},
        \begin{pmatrix} 1 \\ 0 \\ -1 \\ 1 \end{pmatrix},
        \begin{pmatrix} -1 \\ -2 \\ 2 \\ -1 \end{pmatrix},
        \begin{pmatrix} 2 \\ -1 \\ 1 \\ 1 \end{pmatrix}
      }
    \]

    \item[b.] Determine the matrix of the distinct (why distinct?) projection map
      $\varphi: \mathbb R^4 \to \mathbb R^4$ with
      \[
        \image{\varphi} = \mathcal L\set{\begin{pmatrix} 1 \\ 2 \\ 1 \\ 0 \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ -1 \\ 1 \end{pmatrix}}
        \text{ and }
        \kernel{\varphi} = \mathcal L\set{\begin{pmatrix} -1 \\ -2 \\ 2 \\ -1 \end{pmatrix}, \begin{pmatrix} 2 \\ -1 \\ 1 \\ 1 \end{pmatrix}}
      \]
  \end{enumerate}
\end{ex}

\subsection{Blackboard solution}

It must hold that
\[ \angel{b_1, b_1^*} = 1 \]
\[ \angel{b_2, b_2^*} = 0 \]


\[
  \begin{pmatrix}
    1 & 2 & 1 & 0     & 1 & 0 & 0 & 0 \\
    1 & 0 & -1 & 1    & 0 & 1 & 0 & 0 \\
    -1 & -2 & 2 & -1  & 0 & 0 & 1 & 0 \\
    2 & -1 & 1 & 1    & 0 & 0 & 0 & 1
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 0 & 0 & 0 &  3 & -4 & -5 & 4 \\
    0 & 1 & 0 & 0 &  1 & 2 & 1 & -1 \\
    0 & 0 & 1 & 0 &  2 & 5 & 3 & -2 \\
    0 & 0 & 0 & 1 &  5 & 15 & 8 & -6
  \end{pmatrix}
\]
Pay attention! We transposed the matrix initially.
Now we can read the solution vectors in columns.
You can also transpose it only in the end.

\[ B^* = \set{b_1^*, b_2^*, b_3^*, b_4^*} \]
where e.g. $b_1^* = (3, 1, 2, 5)^T$.

Exercise b: $\varphi: \mathbb R^4 \to \mathbb R^4$.

\[ \image{\varphi} = L((b_1, b_2)) \]
\[ \kernel{\varphi} = L((b_3, b_4)) \]
\[
  \begin{pmatrix}
    1 & 1 & 0 & 0 \\
    2 & 0 & 0 & 0 \\
    1 & -1 & 0 & 0 \\
    0 & 1 & 0 & 0
  \end{pmatrix}
  \cdot B^{{*}^T} = P
\]

\[
  P = \begin{pmatrix}
    -12 & 3 & 7 & 20 \\
    -6 & 2 & 4 & 10 \\
    6 & -1 & -3 & -10 \\
    -4 & 2 & 5 & 15
  \end{pmatrix}
\]

Why distinct?
The projection matrix is given with
\[
  \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\]
where row $i$ is $b_i$ and column $j$ is $d_j$ where $b$ and $d$ are the bases of the two vector spaces.

\[ \begin{pmatrix} 1 \\ 2 \\ 3 \\ 4 \end{pmatrix}_B = 1 \cdot b_1 + 2 \cdot b_2 + 3 \cdot b_3 + 4 \cdot b_4 \]

\[ P_{E,E} = \Phi_B^E \cdot P_{B,B} \cdot \overbrace{\underbrace{\Phi_{E}^B}_{(\Phi_B^E)^{-1}} v_E}^{v_B} \]



How to compute the inverse efficiently?

Let $A, B, C \in \mathbb R^{2 \times 2}$.
\[
  \begin{pmatrix}
    A & B \\
    0 & C
  \end{pmatrix} \begin{pmatrix}
    \alpha & \beta \\
    0 & \gamma
  \end{pmatrix}
  = \begin{pmatrix}
    A \alpha & A \beta + B \gamma \\
    0 & C \gamma
  \end{pmatrix}
  \stackrel!= \mathcal 1
\]
\[ \alpha = A^{-1} \qquad \gamma = C^{-1} \]
\[ \beta = -A^{-1} B \gamma \]

\section*{Exercise 6}
\begin{ex}
  Let $V = \mathbb R[x]_2$.
  \[ \xi_1 < \xi_2 < \xi_3 \in \mathbb R \]
\end{ex}

\subsection{Whiteboard solution}

Exercise a:
\[ \beta_i: V \to \mathbb R \]
\[ p(x) \mapsto p(\xi_i) \]
\[ \dim(V) = \dim(V^*) = 3 \]
\[ \sum a_i \beta_i =0 \iff a_i = 0 \forall i \]

\[ \forall p \in \mathbb R[x]_2: \sum a_i \beta_i(p(x)) \stackrel!= 0 \]
\[ \forall p \in \mathbb R[x]_2: \sum a_i \beta_i(\xi_i) \stackrel!= 0 \]

\[ \implies p_1(\xi_1) = p_1(x_2) = 0 \implies a_3 = 0 \dots a_i = 0 \forall i \]
hence linear independent.

Exercise b:
\[ \gamma: p(x) \mapsto p'(\xi_2) \]
\[ \gamma(p(x)) = \sum a_i \beta_i(p(x)) = \sum a_i p(\xi_i) = p'(\xi_2) \]
\[ p(x) = \alpha + \beta x + \delta x^2 \]
\[ \implies p'(\xi_2) = \beta + 2 \delta \xi_2 \]
\[ p(x) = \alpha + \beta x + \delta x^2 \]

\[
  \underbrace{\begin{pmatrix}
    1 & 1 & 1 \\
    \xi_1 & \xi_2 & \xi_3 \\
    \xi_1^2 & \xi_2^2 & \xi_3^2
  \end{pmatrix}}_{= A}
  \begin{pmatrix} a_1 \\ a_2 \\ a_3 \end{pmatrix}
  = \begin{pmatrix} 0 \\ 1 \\ 2\xi_2 \end{pmatrix}
\]


\[
  A^{-1} = \begin{pmatrix}
    \frac{\xi_2 \xi_3}{(\xi_2 - \xi_1)(\xi_3 - \xi_1)} & \dots \\
    -\frac{\xi_3 \xi_1}{(\xi_2 - \xi_1)(\xi_3 - \xi_2)} & \dots \\
    \frac{\xi_1 \xi_2}{(\xi_3 - \xi_1)(\xi_3 - \xi_2)} & \dots
  \end{pmatrix}
\]
\[
  \begin{pmatrix} a_1 \\ a_2 \\ a_3 \end{pmatrix}
  = A^{-1} \begin{pmatrix} 0 \\ 1 \\ 2 \xi_2 \end{pmatrix}
  = \begin{pmatrix}
    \frac{\xi_2 - \xi_3}{(\xi_2 - \xi_1)(\xi_3 - \xi_1)} \\
    \frac{\xi_1 - 2\xi_2 + \xi_3}{(\xi_2 - \xi_1)(\xi_3 - \xi_2)} \\
    \frac{\xi_2 - \xi_1}{(\xi_3 - \xi_1)(\xi_3 - \xi_2)}
  \end{pmatrix}
\]

Exercise c:
\[ B = \set{b_1(x), b_2(x), b_3(x)} \]
\[ l_i = \sum_{j=1}^2 a_{ji} x^j \]
\[ \beta_l(l_i(x)) = \delta_{li} \]

\[
  \begin{pmatrix}
    1 & \xi_1 & \xi_1^2 \\
    1 & \xi_2 & \xi_2^2 \\
    1 & \xi_3 & \xi_3^2
  \end{pmatrix} \cdot
  \begin{pmatrix}
    a_{11} & a_{12} & a_{13} \\
    a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & a_{33}
  \end{pmatrix}
  = \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\]
In essence, we look for $p(x) = \frac{(x_1 - x)(x_2 - x)}{(\xi_1 - \xi_3)(\xi_2 - \xi_3)}$.
This is a Lagrange polynomial with $l_3 = p$.

\section*{Exercise 7}
\begin{ex}
  Let $V$ be a vector space with $\dim{V} = n < \infty$
  and $U \subseteq V$ is a subspace with $\dim{U} = m$.
  \begin{enumerate}
    \item[a.] Show that $U^\bot = \set{v^* \in V^*}{U \subseteq \kernel{v^*}}$ is a subspace of dual space $V^*$ and give $\dim{U^{\bot}}$.
    \item[b.] Is $\setdef{v^* \in V^*}{U = \kernel{v^*}}$ also a subspace?
  \end{enumerate}
\end{ex}

Exercise a:
\[
  \begin{pmatrix}
    U^\bot &= \setdef{v^* \in V^*}{U \subseteq \kernel{v^*}}
           &= \setdef{v^* \in V}{\forall u \in U: v^*(u) = 0}
  \end{pmatrix}
\]
We prove subspace criteria:
\begin{enumerate}
  \item $U^\bot \neq \emptyset$. Let $v^*: V \to \mathbb K$ with $v \mapsto 0$.
  \item
    \[ \forall u^\bot_1, u^\bot_2 \in U^\bot \forall \lambda, \mu \in \mathbb K: \lambda u_1^\bot + \mu u_2^\bot \in U^\bot \]
    \[ \lambda \underbrace{v_1^*(u)}_{0} + \mu v_2^*(u) = 0  \qquad \text{ for } \forall v_1^*, v_2^* \in U^\bot, u \in U \]
\end{enumerate}

Now, we need to determine the dimension $\dim{U^{\bot}}$.

Let $B_U = \set{v_1, v_2, \dots, v_m}$.
\[ B_V = \set{v_1, v_2, \dots, v_m, v_{m+1}, \dots, v_n} \]
\[ B_{V^*} = \set{v_1^*, v_2^*, \dots, v_n^*} \]
\[ B_{U^{\bot}} = \set{v_{m+1}^*, v_{m+2}^*, \dots, v_n^*} \text{ is basis of } U^\bot \]

\[ \forall u \in U: v^*_j(u) = 0^C \forall j \in \set{m+1, \dots, n} \]
\[ B_U = \set{v_1, v_2, \dots, v_m} \]
\[ B_V = \set{v_1, v_2, \dots, v_m, v_{m+1}, \dots, v_n} \]
\[ B_{V^*} = \set{v_1^*, v_2^*, \dots, v_n^*} \]
\[ B_{U^\bot} = \set{v_{m+1}^*, v_{m+2}^*, \dots, v_n^*} \text{ is basis of } U^\bot \]
\[ \implies \dim(U^\bot) = n - m \]

Exercise b:
\[ W^\bot = \setdef{v^* \in V^*}{U = \kernel(v^*)} \]
The reason was given orally.

\section*{Exercise 8}
\begin{ex}
  Let $f \in \operatorname{Hom}(V, W)$ be a linear map between two finite-dimensional vector space with bases $B \subseteq V$ and $C \subseteq W$. We define the transposed map
  \[ f^T: W^* \to V^* \]
  \[ w^* \mapsto w^* \circ f \]
  Hence $f^T(w^*)$ is a linear functional and $(f^T(w^*))(v) = w^*(f(v))$
  \begin{enumerate}
    \item[a.]
      Show that $f^T$ is linear.
    \item[b.]
      Show that the matrix representation, in regards of dual bases $C^*$ and $B^*$, has the following matrix representation: $\Phi_{B^*}^{C^*}(f^T) = \Phi_C^B(f)^T$
  \end{enumerate}
\end{ex}

Exercise a:
Let $v \in V$ and $\lambda \in \mathbb K$, $w_1^*, w_2^* \in W^*$.
\[ (f^T(w_1^* + w_2^*))(v) = (w_1^* + w_2^*)f(v) = w_1^*(f(v)) + w_2^*(f(w_1^*))(v) + (f^T(w_2^*))(v) \]
\[ (f^T(\lambda w_1^*))(v) = (\lambda w_1^*)(f(v)) = \lambda w_1^*(f(v)) = \lambda (f^T(w_1^*))(v) \]
We proved $g(w_1 + \lambda w_2) = g(w_1) + \lambda g(w_2)$. Hence $f^*$ is linear.

Exercise b:
\[ \Phi_{B^*}^{C^*}(f^T) = \Phi_C^B(f)^T \]
\[ \set{v_1 \dots, v_n} = B \qquad \set{w_1, \dots, w_m} = C \]
\[ f(v_j) = \sum_{i=1}^m m_{ij} w_i \]
\[ (f^t(w_i^*))(v_k) = w_j^*(f(v_k)) = w_j^* \left(\sum_{l=1}^m {lk} w_l\right) = m_{jk} \]
\[ m_{jk} = \sum_{l=1}^n m_{jl} \underbrace{v_{l}^*(v_k)}_{\delta_{lk}} \]
\[ = \sum_{l=1}^n m_{jl} v_l^*(v_k) \]
\[ \implies f^T(w_j^*) = \sum_{l=1}^n A_{l,j} v_l^* \]
\[ \implies A = \Phi_C^B(f)^T \]
\[ A = \Phi_{B^*}^{C^*}(f^T) \]

\dateref{2018/03/21}

\section*{Exercise 10}
\begin{ex}
  A permutation $\pi \in \sigma_n$ is called cyclic, if there exists some $k \geq 1$ and a sequence $i_1, i_2, \dots, i_k$ such that $\pi(i_j) = i_{j+1}$ for $1 \leq j \leq k-1$, $\pi(i_k) = i_1$ and $\pi(i) = i$ for $i \not\in \set{i_1, i_2, \dots, i_k}$, hence
  \[ i_1 \to i_2 \to \dots \to i_1. \]
  and all other $i$ are fixed. Common notation: $\pi = (i_1, i_2, \dots, i_k)$.
  \begin{itemize}
    \item Show, that two cyclic permutations $\pi = (i_1, i_2, \dots, i_k)$ and $\rho = (j_1, j_2, \dots, j_l)$ commutate ($\pi \circ \rho = \rho \circ \pi$), if $\set{i_1, i_2, \dots, i_k} \cap \set{j_1, j_2, \dots, j_l} = \emptyset$.
    \item Decompose the cycle into a product of transpositions and show that for a cyclic permutation, it holds that $\sign(\pi) = (-1)^{k-1}$.
  \end{itemize}
\end{ex}

For the first part,

Let $\operatorname{supp}(\pi) \cap \operatorname{supp}(\rho) = \emptyset$ where $\operatorname{supp}(\pi)$ defines the elements in the cycle of permutation $\pi$.
\begin{description}
  \item[$i \not\in \operatorname{supp}(\pi) \cup \operatorname{supp}(\rho)$] 
    \[ \implies \rho(i) = i = \pi(i) = i \]
    \[ \implies \pi(\rho(i)) = \rho(\pi(i)) = i \]
  \item[$i \in \operatorname{supp}(\pi)$]
    $i \in \operatorname{supp}(\pi) \implies \pi(i) \in \operatorname{supp}(\pi)$
    \[ \rho(\pi(i)) = \pi(i) \implies \rho(\pi(i)) = \pi(i) = \pi(\rho(i)) \]
\end{description}

For the second part,

\[ \pi = \tau_1 \cdot \tau_2 \cdot \dots = (i_1, i_2) (i_2, i_3) \dots (i_{k-1}, i_k) (i_k, i_1) \]
giving $k-1$ transposition.
\[ \implies \sign(\pi) = (-1)^{k-1} \]

\[ \tau_{24} = 1432 \]
\[ T_{34}^{2341} T_{23}^{2314} T_{42}^{2134} \]

\section*{Exercise 11}
\begin{ex}
  Let $\pi \in \sigma_n$ be a permutation and $i \in \set{1, 2, \dots, n}$.
  \begin{enumerate}
    \item Show that the sequence $i, \pi(i), \pi^2(i), \dots$ is periodic and that the first number occuring twice is $i$.
    \item The sequence $(i, \pi(i), \pi^2(i), \dots, \pi^{k-1}(i))$, where $k$ is the smallest exponent such that $\pi^k(i) = i$, is called \emph{cycle of $i$}. Show that the relation $i \sim j : \iff $($j$ is in inside the cycle) defines an equivalence relation in $\set{1,2,\dots,n}$.
    \item Show that every permutation can be written as product of commutative cycles.
    \item Apply this decomposition to permutation $\pi$ in Exercise~9.
  \end{enumerate}
\end{ex}

Exercise (a).

$k$ is certainly finite, because of the pidgeonhole principle. Furthermore smaller than $n$, because there are at most $n$ numbers it can be mapped to. We have $n$ distinct elements. $i$ is the first element, which is not mapped to any number. So $i$ is the first number which will occur for the second time. This implies that the map is bijective, which is given for any permutation.

Exercise (b).

Reflexivity is trivial.
Symmetry: Let $\pi^l(i) = j$, then $\pi^{k-l}(j) = i$. This shows that both are in the same cycle and symmetry is given.
If $i \sim j \land j \sim m \implies i \sim m$.
\[ \pi(i) = j \qquad \pi^p(j) = m \iff \pi^p(\pi^l(i)) = m \iff \pi^{p+l}(i) = m \]
\[ \pi^p \circ \pi^l(i) = m \]

Exercise (c).

\[ 1 \quad \pi(1) \quad \pi(\pi(1)) \quad \pi(\pi(\pi(1))) \quad \dots \]
\[ \pi = (\quad)  (1, \dots, \pi^{k-1}) a_2 \pi(a_2) \neq a_2 \]

Exercise (d).

\[ \begin{pmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ 2 & 5 & 1 & 6 & 3 & 7 & 4 \end{pmatrix} = (1253) (467) \]

\section*{Exercise 12}
\begin{ex}
  Show that every permutation $\pi \in \sigma_n$ can be written as composition of permutations
  $\gamma = \begin{pmatrix} 1 & 2 & \dots & n-1 & n \\ 2 & 3 & \dots & n & n-1 \end{pmatrix}$
  and $\tau = \begin{pmatrix} 1 & 2 & \dots & n-1 & n \\ 2 & 1 & \dots & n-1 & n \end{pmatrix}$
\end{ex}

From the lecture:
\begin{quote}
  Every permutation $\sigma \in \sigma_n$ with $\sigma \neq \operatorname{id}$ can be denoted as a product of transpositions.
\end{quote}

\begin{enumerate}
  \item Consider the theorem from the lecture.
  \item Every transposition can be represented as composition of swapping two neighbors.
    \[ \tau_{ij} = (i, i+1) (i+1, i+2) \dots (j-1, j) (j-2, j-1) \dots (i, i+1) \]
  \item
    \[ \tau_{i,i+1} = \gamma^{i-1} \cdot \tau \cdot \gamma^{-(i-1)} \]
\end{enumerate}

\section*{Exercise 13}
\begin{ex}
  In the sliding 6-puzzle, which permutations can be reached?
\end{ex}

We begin with the initial position (right-bottom shows the vacant field) and need to end with the initial position as well.
We can only do transpositions with the vacant field.
\begin{enumerate}
  \item even number of transpositions
  \item signature $\pi = (-1)^{\text{\# transpositions}}$
  \item no permutation with $\sign - 1$
\end{enumerate}

The second item is wrong.

\[
  \pi_1 = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 \\ 2 & 3 & 4 & 5 & 1 \end{pmatrix} \qquad
  \pi_2 = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 \\ 1 & 2 & 4 & 5 & 3 \end{pmatrix}
\]
Any permutation is a product of $\pi_1$ and $\pi_2$.

We can permute in a shape of the infinity symbol.

\section*{Exercise 14}
\begin{ex}
  Determine the determinant using three different methods (Leibniz, Laplace, Gauss-Jordan) of the matrix
  \[
    \begin{vmatrix}
      1 & 2 & 3 \\
      1 & 1 & 2 \\
      2 & -1 & 2
    \end{vmatrix}
  \]
\end{ex}

TODO

\section*{Exercise 15}
\begin{ex}
  The numbers $18270$, $16128$, $63042$, $17304$ and $17934$ are divisible by $42$.
  Show that the determinant
  \[
    \det(A) = \begin{vmatrix}
      1 & 8 & 2 & 7 & 0 \\
      1 & 6 & 1 & 2 & 8 \\
      6 & 3 & 0 & 4 & 2 \\
      1 & 7 & 3 & 0 & 4 \\
      1 & 7 & 9 & 3 & 4
    \end{vmatrix}
  \]
  is divisible by $42$ without explicit evaluation.
\end{ex}

\[
  \begin{vmatrix}
    1 & 8 & 2 & 7 & 0 \\
    1 & 6 & 1 & 2 & 8 \\
    6 & 3 & 0 & 4 & 2 \\
    1 & 7 & 3 & 0 & 4 \\
    1 & 7 & 9 & 3 & 4
  \end{vmatrix}
  =
  \begin{vmatrix}
    1 & 8 & 2 & 7 & 18270 \\
    1 & 6 & 1 & 2 & 16128 \\
    6 & 3 & 0 & 4 & 63042 \\
    1 & 7 & 3 & 0 & 17304 \\
    1 & 7 & 9 & 3 & 17934
  \end{vmatrix}
\]
\[
  \det(A) = \sum_{k=1}^5 a_{k,5} \underbrace{(-1)^{k+5} \det{A_{k,5}}}_{\in \mathbb Z}
\]
$\det(A)$ consists of $5$ summands, which are divisible by $42$ each, hence the sum is divisible 

\dateref{2018/04/11}

\section*{Exercise 17}
\begin{ex}
  Evaluate the determinants:
\end{ex}

\subsection{Exercise 17a}
\begin{ex}
  \[
    \begin{vmatrix}
      1+x & 1 & 1 & 1 \\
      1 & 1-x & 1 & 1 \\
      1 & 1 & 1+y & 1 \\
      1 & 1 & 1 & 1-y
    \end{vmatrix}
  \]
\end{ex}

\[
  \begin{vmatrix}
    0 & -x & -x & y+xy-x \\
    0 & -x & 0 & y \\
    0 & 0 & y & y \\
    1 & 1 & 1 & 1-y
  \end{vmatrix}
  =
  -1 \cdot
  \begin{vmatrix}
    -x & -x & y+xy-x \\
    -x & 0 & y \\
    0 & y & y
  \end{vmatrix}
\] \[
  = (-1) (-xy^2 - (xy)^2 + x^2y - x^2y + xy^2)
  = (xy)^2
\]

\subsubsection{A simpler solution}

Assume $C \in \operatorname{GL}(\mathbb R)$ and $\vec{V}, \vec{W} \in \mathbb R^n$ where GL is the set of invertible matrices.
Then it holds that
\[ \operatorname{det}(C + \vec v \vec w^t) = \det C \left( 1 + \langle C^{-1} \vec v, \vec w\rangle \right) \]
where $\langle \cdot, \cdot \rangle$ is an inner product with $\langle \vec v, \vec w \rangle = v_1 \cdot w_1 + \ldots + v_n \cdot w_n$.
\[ A \vec x = \vec b \]
\[ x_i = \frac{\det(A_j)}{\det{A}} \]

\subsection{Exercise 17b}
\begin{ex}
  \[
    \begin{vmatrix}
      x  & 0  & \ldots & a_0 \\
      -1 & x  & \ldots & a_1 \\
         & -1 & \ddots & \\
         & \ddots & \ddots & \\
      0  &    & -1 & x+a_{n-1}
    \end{vmatrix}
  \]
\end{ex}

Alternative approach: Use Laplace expansion theorem along the last column.

Always consider: A division by $x$ requires a case distinction!

Case 1: $x \neq 0$:

\[
  \begin{vmatrix}
    x &   & \ldots & a_0 \\
    0 & x & \ldots & a_1 + \frac{a_0}{x} \\
      & -1 & \ddots& \vdots \\
    \vdots & \ddots & \ddots & \\
    0 &   & -1 & x + a_{n-1}
  \end{vmatrix}
  =
  \begin{vmatrix}
    x &        & a_0 \\
      & \ddots & a_1 + \frac{a_0}{x} \\
      &        & x + a_{n-1} + \frac{a_{n-2}}{x} + \ldots + \frac{a_0}{x^{n-1}}
  \end{vmatrix}
\] \[
  = x^{n-1} (x + a_{n-1} + \frac{a_{n-2}}{x} + \ldots)
  = x^n + x^{n-1} a_{n-1} + \ldots + a_0
  = x^n + \sum_{i=1}^n a_{n-i} x^{n-i}
\]

Case 2: $x = 0$.

\[
  \begin{vmatrix}
    0 &         & a_0 \\
    -1 & \ddots & \\
       &        & -1\cdot a_{n-1}
  \end{vmatrix}
  = (-1)^{n+1} \cdot a_0 \cdot
  \begin{vmatrix}
    -1     &        & 0 \\
    \vdots & \ddots & \vdots \\
    0      &        & -1
  \end{vmatrix}
  = (-1)^{n+1} \cdot a_0 \cdot (-1)^{n-1} = (-1)^{2n} \cdot a_0 = a_0
\]

\subsection{Exercise 17c}
\begin{ex}
  \[
    \begin{vmatrix}
      0 & 0 & \ldots &         & a_n \\
      0 & 0 & \ldots & a_{n-1} & * \\
      \vdots & & & & \vdots \\
      0 & a_2 & & & \vdots
      a_1 & * & & & *
    \end{vmatrix}
  \]
\end{ex}

Case distinction: $n$ is even.

\[
  = (-1)^{\frac n2} \begin{vmatrix}
    a_1 & *   &   & & * \\
        & a_2 & * & & \vdots \\
        &     & \ddots & & \\
    0   &     &        & & a_n
  \end{vmatrix}
  = (-1)^{\frac{n-1}{2}} \prod_{i=1}^n a_i
\]

You can skip the case distinction if you use the Gaussian bracket: $(-1)^{\lfloor \frac n2\rfloor}$

\section*{Exercise 18}
\begin{ex}
  Show: There exists some matrix $A \in \mathbb R^{n\times n}$ with entries $a_{ij} = \pm 1$ such that $\det(A) = n!$ if and only if $n < 3$.

  Hint: For $n=2$, it is easy. For $n=3$, consider why no all summands in Leibniz' formula for determinants have the same sign. The case $n>3$ can be reduced to the case $n=3$.
\end{ex}

For $n=2$,
\[ 2! = 2 \qquad \begin{vmatrix} 1 & 1 \\ -1 & 1 \end{vmatrix} = 1 - (-1) = 2 \]

For $n=3$, we consider the Rule of Sarrus and assume such a matrix $A$ exists.
Because $n! = 6$, we need all summands of the Rule of Sarrus to be positive. We consider the diagonals given in the Rule of Sarrus and recognize, that both diagonals use the same elements. 
Consider the diagonals with positive sign. All of them must either use zero or two $-1$. At the same time, all diagonals with negative sign must either use three or one $-1$. This contradicts assuming they use the same elements. The proof by contradiction has been completed.

Now we look for the generalization of $n \to n+1$ for $n \geq 3$.

This will be proven by complete induction.
\begin{description}
  \item[Induction hypothesis] $A \in \mathbb R^{n \times n}$ with $a_{ij} = \pm 1$
  \item[Induction base] $n=3$ has been proven
  \item[Induction step] We apply Laplace expansion along one row.
    Let $\varepsilon^{(i)}$ be the value of $\det(A_n^{(i)})$ where $A_n$ is a square matrix of dimension $n \times n$.
    \begin{align*}
      \det(A_{n+1}) &= +\underbrace{\det(A_n^{(1)})}_{< n!} - \underbrace{\det(A_n^{(2)})}_{< n!} + \underbrace{\det(A_n^{(3)})}_{< n!} - \ldots \\
        &= \sum_{i=1}^{n+1} \det(A_n^{(i)}) = \sum_{i=1}^{n+1} \varepsilon^{(i)} < (n+1) n! = (n+1)!
    \end{align*}
    Hence $\det(A_{n+1}) < (n+1) n!$.
\end{description}

\section*{Exercise 19}
\begin{ex}
  \begin{enumerate}
    \item[(a)]
      Let $\mathbb K$ be a field and $a_1, a_2, \dots, a_n \in \mathbb K$. Show that
      \[
        \begin{vmatrix}
          1 & a_1 & a_1^2 & \ldots & a_1^{n-1} \\
          1 & a_2 & a_2^2 & \ldots & a_2^{n-1} \\
          \ldots & \ldots & \ldots & \ldots & \ldots \\
          1 & a_n & a_n^2 & \ldots & a_n^{n-1} \\
        \end{vmatrix}
        = \prod_{i < j} (a_j - a_i)
      \]
    \item[(b)]
      Conclude from this, that for given pairwise different numbers $x_0, x_1, \ldots, x_n \in \mathbb K$
      and arbitrary $y_0, y_1, \ldots, y_n \in \mathbb K$ there exists exactly one polynomial $p(x) \in \mathbb K[x]$ with degree $n$,
      such that $p(x_i) = y_i$ for all $i$.
    \item[(c)]
      Extra point to be solved on a computer:
      Determine for each different $n$, one polynomial $p(x) \in \mathbb R[x]$, such that $p(x_k) = \card{x_k}$, $k = -n, \ldots, n$, with $x_k = \frac{k}{n}$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 19a}

Induction base: $n=2$.
\[ \begin{vmatrix} 1 & a_1 \\ 1 & a_2 \end{vmatrix} = (a_2 - a_1) \]

Induction step: $n-1 \to n$.
\[
  \begin{vmatrix}
    1 & a_1 & a_1^2 & \ldots & a_1^{n-1} \\
    1 & a_2 & a_2^2 & \ldots & a_2^{n-1} \\
    \ldots & \ldots & \ldots & \ldots & \ldots \\
    1 & a_n & a_n^2 & \ldots & a_n^{n-1} \\
  \end{vmatrix}
  = \begin{vmatrix}
    1 & a_1       & \ldots        &        & a_1^{n-1} \\
    0 & a_2 - a_1 & a_2^2 - a_1^2 & \ldots & a_2^{n-1} - a_1^{n-1} \\
    \ldots & & & & \\
    0 & a_n-a_1 & a_2^2 - a_1^2 & & a_n^{n-1} - a_1^{n-1}
  \end{vmatrix}
\]

The following equation holds:
\[
  (x^n - y^n) = (x - y) \sum_{i=0}^{n-1} x^{n-1-i} y^i
\]

\[
  =
  \begin{vmatrix}
    (a_2 - a_1) & (a_2^2 - a_1^2) & (a_2^{n-1} - a_1^{n-1}) \\
    \vdots      & \vdots          & \vdots \\
    (a_n - a_1) & (a_n^2 - a_n^2) & (a_n^{n-1} - a_1^{n-1})
  \end{vmatrix}
  = \prod_{i=2}^n (a_j - a_1) \cdot
  \begin{vmatrix}
    1      & (a_2 + a_1) & (a_2^{n-2} + a_2^{n-3} a_1 + \ldots + a_1^{n-2}) \\
    1      & (a_3 + a_1) & \vdots \\
    \vdots & \vdots      & \vdots \\
    1      & (a_n + a_1) & (a_n^{n-2} + \ldots + a_1^{n-2})
  \end{vmatrix}
\] \[
  = \prod_{j=2}^n (a_j - a_1) \cdot
  \begin{vmatrix}
    1      & a_2    & a_2^2  & \ldots & a_2^{n-2} \\
    1      & a_3    & a_3^2  & \ldots & a_3^{n-2} \\
    \vdots & \vdots & \vdots & \ldots & \vdots \\
    1      & a_n    & a_n^2  & \ldots & a_n^{n-2}
  \end{vmatrix}
\] \[
  = \prod_{j=2}^n (a_j - a_1) \prod_{\substack{i < j \\ i,j \neq 1}}^n (a_j - a_i) = \prod_{i < j}^n (a_j - a_i)
\]

\subsection{Exercise 19b}

Show: there exists exactly one polynomial $p \in \mathbb K_n[x] (\forall i \in \set{0, \ldots, n}): p(x_i) = y_i$.

\[ p(x) = a_0 + a_1 x + a_2 x^2 + \ldots + a_n x^n \]

\[
  \begin{array}{cccccccc}
    a_0 & + & a_1 x_0 & + & \ldots & a_n x_0^n & = & y_0 \\
    a_0 & + & a_1 x_1 & + & \ldots & a_n x_1^n & = & y_1 \\
    \vdots & & & & & & & \\
    a_0 & + & a_1 x_n & + & \ldots & a_n x_n^n & = & y_n
  \end{array}
  \iff
  \begin{pmatrix}
    1 & x_0 & x_0^2 & \ldots & x_0^n \\
    1 & x_1 & x_1^2 & \ldots & x_1^n \\
    \vdots & &      & \ddots & \vdots \\
    1 & x_n & x_n^2 & \ldots & x_n^2
  \end{pmatrix} \begin{pmatrix}
    a_0 \\ a_1 \\ \vdots \\ a_n
  \end{pmatrix} = \begin{pmatrix}
    y_0 \\ y_1 \\ \vdots \\ y_n
  \end{pmatrix}
\]

\[ \det(M) = \prod_{i<j} (x_j - x_i) \]
\[
  \begin{pmatrix} a_0 \\ a_1 \\ \vdots \\ a_n \end{pmatrix}
  = \begin{pmatrix} 1 & \ldots & x_0^1 \\ \vdots & & \vdots \\ 1 & \ldots & x_n^n \end{pmatrix}
  \begin{pmatrix} y_0 \\ y_1 \\ \vdots \\ y_n \end{pmatrix}
\]

\subsection{Exercise 20}
\begin{ex}
  Let $A, B \in \mathbb K^{n\times n}$. Show by elementary row- and column transformations, that the following identity for block matrices holds:
  \[
    \begin{vmatrix}
     I & B \\
     -A & 0
    \end{vmatrix} = \begin{vmatrix}
      I & B \\
      0 & AB
    \end{vmatrix}
  \]
  Derive an alternative proof for the multiplication law of determinants ($\det(AB) = \det(A) \cdot \det(B)$).
\end{ex}

\begin{enumerate}
  \item We consider the left-hand side.
  \item We add the $n+1$-th row to the first row multiplied by $a_{11}$ and use the result as row $n+1$.
    As a result, the value in $a_{n+1,1}$ becomes $0$.
  \item We add the $n+2$-th row to the first row multiplied by $a_{21}$ and use the result as row $n+2$.
    As a result, the value in $a_{n+2,1}$ becomes $0$.
  \item We also do this process for columns and the second row.
  \item As a result we get $\begin{vmatrix} I & B \\ 0 & AB \end{vmatrix}$.
\end{enumerate}

\[
  \det(AB)
  = \begin{vmatrix} I & B \\ 0 & AB \end{vmatrix}
  = \begin{vmatrix} I & B \\ -A & 0 \end{vmatrix}
  = (-1)^n \begin{vmatrix} I & B \\ A & 0 \end{vmatrix}
  = (-1)^n (-1)^n \begin{vmatrix} A & 0 \\ I & B \end{vmatrix}
  = (-1)^{2n} \det(A) \det(B)
\]


\section*{Exercise 21}
\begin{ex}
  Prove by induction:
  \[
    A \coloneqq
    \begin{vmatrix}
      \alpha & \beta & \beta & \ldots & \beta \\
      \beta & \alpha & \beta & \ldots & \beta \\
      \vdots &       &       & \ddots & \vdots \\
      \beta & \beta & \beta & \ldots & \alpha
    \end{vmatrix}
    = (\alpha - \beta)^{n-1} (\alpha + (n - 1) \beta)
  \]
\end{ex}

\begin{description}
  \item[Induction base] 
    For $n=1$, it holds that $|\alpha| = \alpha$. Induction base satisfied.
  \item[Induction step]
    \[
      \frac1{\alpha^n}
      \begin{vmatrix}
        \alpha & \alpha \beta & \alpha\beta & \ldots & \\
        \beta  & \alpha^2     &             &        & \\
        \vdots &              & \ddots      &        & \\
               &              &             &        & a^2
      \end{vmatrix}
    \] \[
       = \frac1{\alpha^n}
      \begin{vmatrix}
        \alpha & \alpha \beta & \alpha \beta & \ldots & \\
        \beta  & \alpha^2     &              &        & \\
        \vdots &              & \ddots       &        & \\
               &              &              &        & a^2
      \end{vmatrix}
    \] \[
       = \frac1{\alpha^n}
      \begin{vmatrix}
        \alpha & 0            & 0            & \ldots & \\
        \beta  & \alpha^2 - \beta^2 &              &        & \\
        \vdots & \beta (\alpha - \beta) & \ddots       &        & \\
               &              &              &        &
      \end{vmatrix}
    \] \[
      = \alpha \frac{1}{alpha^n}
      \begin{vmatrix}
        \alpha^2 - \beta^2 & & \beta (\alpha - \beta) \\
                           & \ddots & \\
        \beta (\alpha - \beta) &    & \alpha^2 - \beta^2
      \end{vmatrix} \eqqcolon d
    \]
    \begin{align*}
      d &=
          \frac{1}{\alpha^{n-1}} (\alpha^2 - \beta^2 - \alpha \beta + \beta^2)^{n-1}
          \left(\alpha^2 - \beta^2 + (n-1)(\alpha \beta - \beta^2) \right) \\
        &= \frac{1}{\alpha^{n-1}} (\alpha(\alpha - \beta))^{n-1} (\alpha + \beta)(\alpha - \beta) + (n-1)\beta(\alpha - \beta) \\
        &= \frac{1}{\alpha^{n-1}} \alpha^{n-1} (\alpha - \beta)^{n-1} \cdot (\alpha - \beta)(\alpha + \beta + (n-1) \beta) \\
        &= (\alpha - \beta)^n (\alpha + n\beta)
    \end{align*}
\end{description}

Again: the division by $\alpha$ implies that $\alpha \neq 0$. It is important to consider $\alpha = 0$. It is easy to show this case, but if you skip it, points are lost.

\section*{Exercise 22}
\begin{ex}
  Let $P_i = (x_i, y_i)$ are pairwise different points in $\mathbb R^2$.
  \begin{enumerate}
    \item Show that the uniquely determined line $g$ crossing points $P_1$ and $P_2$ can be described by the following equation:
      \[ g = \set{(x,y) \in \mathbb R^2: \begin{vmatrix} 1 & x_1 & y_1 \\ 1 & x_2 & y_2 \\ 1 & x & y \end{vmatrix} = 0} \]
    \item Show that the uniquely determined circle $k$ crossing points $P_1$, $P_2$ and $P_3$,
      can be described by:
      \[
        k = \set{
          (x,y) \in \mathbb R^2:
          \begin{vmatrix}
            1 & x_1 & y_1 & x_1^2 + y_1^2 \\
            1 & x_2 & y_2 & x_2^2 + y_2^2 \\
            1 & x_3 & y_3 & x_3^2 + y_3^2 \\
            1 & x & y & x^2 + y^2
          \end{vmatrix}
        } = 0
      \]
      What is the result, if the points are colinear?
    \item Determine the center of the circle crossing points $(-4, 1)$, $(-2, -3)$ and $(4,5)$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 22a}
\[ k =\frac{y_2 - y_1}{x_2 - x_1} \]
Again, consider: $x_2 = x_1$ separately!

Laplace expansion along the last row:
\[ 1 \cdot (x_1 y_2 - x_2 y_1) - x(y_2 - y_1) + y(x_2 - x_1) \overset!= 0 \]
\[
  \underbrace{\frac{(x_1 y_2 - x_2 y_1)}{x_2 - x_1}}_{d}
  - x \underbrace{\frac{(y_2 - y_1)}{x_2 - x_1}}_{k}
\] \[
  y_0 = \frac{y_2 - y_1}{x_2 - x_1} x_1 + d
\] \[
  d = y_1 - \frac{(y_2 - y_1) x_1}{(x_2 - x_1) x_1}
  = \frac{y_1 x_2 - y_1 x_1 - y_2 x_1 + y_2 x_1}{x_2 - x_1}
\]
This corresponds to the slope of the line. Hence, our model matches the formula (the one involving the determinant).

What about $x_2 = x_1$? Then the second column is a linear combination of the others. Hence, determinant equals 0.

\subsection{Exercise 22b}

Consider 3 points $P_1$, $P_2$ and $P_3$.
Consider point $A$ half-way of $\overline{P_1 P_2}$.
Consider point $B$ half-way of $\overline{P_1 P_3}$.
If the line $g_1$, orthogonal to $P_1 P_2$ and crossing $A$, crosses with the line $g_2$,
orthogonal to $P_1 P_3$ and crossing $B$, meet this crosspoint $M$ is the center of the circumference circle of $P_1$, $P_2$ and $P_3$.

\[ v_1 = P_2 - P_1 = (2, -4) \to A = P_1 + \frac{v_1}{2} = (-3, -1) \]
\[ v_2 = P_3 - P_1 = (8, 4) \to B = P_1 + \frac{v_2}{2} = (0, 3) \]

\[ n_1 = \bot v_1 = (4, 2) \]
\[ n_2 = \bot v_2 = (4, -8) \]

\[ g_1 = A + t \cdot n_1 \]
\[ g_2 = B + s \cdot n_2 \]

\subsection{Exercise 22c}

\[ \vectwo{-3}{-1} + t \vectwo42 = \vectwo03 + s\vectwo{4}{-8} \]
Gives $t=1$ and
\[ \vectwo{-3}{-1} + 1 \vectwo42 = \vectwo11 = M \]

\subsection{Exercise 22b: What if all points are colinear?}

A generic circle equation is given by
\[ (x - \overline x)^2 + (y - \overline y)^2 = r^2 \]

\[ x^2 - 2x \overline x + \overline x^2 + y^2 - 2y\overline y + \overline y^2 = r^2 \]
\[ x^2 + y^2 = \underbrace{r^2 - \overline x^2 - \overline y^2}_{K} + 2 \overline y y + 2 \overline x x \]
\[ M \cdot \begin{pmatrix} K \\ 2 \overline x \\ 2 \overline y \end{pmatrix} = V \]
where $M$ are the first three columns and $V$ is the last column.

\section*{Exercise 23}
\begin{ex}
  Let $A, B, C, D \in \mathbb K_{n\times n}$ be matrices.
  $D$ is invertible and $M$ is a $2n \times 2n$ block matrix.
  \[ M = \begin{bmatrix} A & B \\ C & D \end{bmatrix} \]
  \begin{enumerate}
    \item Show: $M$ is invertible iff $A - BD^{-1}C$ is invertible
    \item Show: $\det(M) = \det(A - BD^{-1} C) \det(D)$
  \end{enumerate}
\end{ex}

\subsection{Exercise 23a}
\[ \det(M) = \underbrace{\det(A - BD^{-1} C)}_{\neq 0 \text{ if invertible}} \underbrace{\det(D)}_{\neq 0 \text{ if invertible}} \]
$\det(D)$ is invertible by the exercise specification.
\[ \det(A - BD^{-1} C) \neq 0 \implies A - BD^{-1} C = \text{ invertible} \]

\subsection{Exercise 23b}
\[
  M = \begin{bmatrix} A & B \\ C & D \end{bmatrix}
  = \begin{bmatrix} I & B \\ 0 & D \end{bmatrix} \begin{bmatrix} A-BD^{-1}C & 0 \\ D^{-1}C & I \end{bmatrix}
\] \[
  \begin{vmatrix} I & B \\ 0 & D \end{vmatrix}
  \begin{vmatrix} A - BD^{-1} C & 0 \\ D^{-1} C & I \end{vmatrix}
  = \det(D) \cdot \det(A - BD^{-1}C) \det(I)
\]

\section*{Exercise 25}
\begin{ex}
  Let $A$ be a $m \times n$ matrix. Show that $\rank(A)$ is identical with the largest number $k \in \set{1,2,\ldots,\min(m,n)}$ for which a non-vanishing subdeterminant of order $k$ exists, hence
  index sets $i_1 < i_2 < \ldots < i_k$ and $j_1 < j_2 < \ldots < j_k$, such that
  \[
    \card{A_{i_k,j_k}} \coloneqq
    \begin{vmatrix}
      a_{i_1,j_1} & a_{i_1,j_2} & \ldots & a_{i_1,j_k} \\
      a_{i_2,j_1} & a_{i_2,j_2} & \ldots & a_{i_2,j_k} \\
      \ldots      & \ldots      & \ddots & \vdots      \\
      a_{i_k,j_1} & a_{i_k,j_2} & \ldots & a_{i_k,j_k} \\
    \end{vmatrix}
    \neq 0
  \]
\end{ex}

Assume $k \geq \rank(A)$.
\[ A \to \tilde A \]
$m - \rank(A)$ rows and $n - \rank(A)$ columns.
$\rank(A)$ is the number linear independent rows (or equivalently, columns)

\[ \implies k \leq \rank(A) \implies k = \rank(A) \]

\section*{Exercise 26}
\begin{ex}
  Let $A \in \mathbb K^{m\times n}, B \in \mathbb K^{n \times m}$. Show that
  \[
    \det(AB) = \sum_{i_1 < i_2 < \ldots < i_m}
    \begin{vmatrix}
      a_{1i_1} & a_{1i_2} & \ldots & a_{1i_m} \\
      a_{2i_1} & a_{2i_2} & \ldots & a_{2i_m} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{mi_1} & a_{mi_2} & \ldots & a_{mi_m}
    \end{vmatrix}
    \begin{vmatrix}
      a_{i_11} & a_{i_21} & \ldots & a_{i_m1} \\
      a_{i_12} & a_{i_22} & \ldots & a_{i_m2} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{i_1m} & a_{i_2m} & \ldots & a_{i_mm}
    \end{vmatrix}
  \]
  Hint: Use Leibniz formula.
\end{ex}

\[ \det(AB) = \sum \det(A_{i_m \ldots}) \det(B^{i_1 \ldots i_m}) \]
\[ A,B \in \mathbb K^{m \times m} \]
\[ \det(AB) = \sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^m (AB)_{i \sign(i)} =
  \sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^n \left(\sum_{k=1}^n A_{i,k} B_{k \sigma(i)} \right)
\]
Let $N = \set{1, \ldots, n}$. Let $M = \set{1, \ldots, m}$. Let $N^M$ be the functions mapping $M$ to $N$.
\[
  \sum _{\sigma \in \sigma_n} \sign(\sigma) \sum_{k \in N^M} \prod_{i=1}^m A_{i k(i)} B_{k(i) \sigma(i)}
\] \[
  = \sum_{k \in N^M} \sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^m A_{ik(i)} \prod_{i=1}^m B_{k(i) \sigma(i)}
  = \sum_{k \in N^M} \prod_{i=1}^m A_{i k(i)} \underbrace{\sum_{\sigma \in S_m} \sign(\sigma) \prod_{i=1}^m B_{k(i) \sigma(i)}}_{\det(B^{k(1) \ldots k(m)})}
\]
Let $k, \tilde k \in N^M$. $k \sim \tilde k :\iff \image(k) = \image(\tilde k)$.
\[ = \sum_{k \in N^M \text{injective} / \sim} \sum_{\tilde k \sim k} \prod_{i=1}^m A_{ik(i)} \underbrace{\det(B^{(\tilde k(1) \ldots \tilde k(m))})}_{\sign(\delta) \det(B^{k(1) \ldots k(m)} \text{ with } k(1) < k(2) < \ldots < k(n)}) \]
where $\cdot/\sim$ denotes the set of equivalence classes. $\tilde k \sim k \implies \exists \delta \in \delta_m: \tilde k = k \circ \delta$.
\[ = \sum_{k \in N^M \text{ injective} / \sim} \left(\sum_{\delta \in \delta_m} \sign(\delta) \prod A_{i k(\delta_i)}\right) \det(B^*) \]

\section*{Exercise 28}
\begin{ex}
  Let $A \in \mathbb C^{n \times n}$ be a Hermitian matrix. Show
  \begin{enumerate}
    \item $A \geq 0 \iff \exists B \in \mathbb C^{n \times n}: A = B^* \cdot B$
    \item $A > 0 \implies A \text{ regular and } A^{-1} > 0$
    \item Let $A \geq 0 \implies a_{ii} \geq 0 \forall i$ and if $\exists i: a_{ii} = 0 \implies a_{ij} = 0$
    \item Does the following generalized first-minors criterion apply?
      \enquote{A $n \times n$ matrix $A$ is positive semidefinite iff $\det{A_r} \geq 0 \forall r = 1, 2, \ldots, n$}
  \end{enumerate}
\end{ex}

\subsection{Exercise 28a}

Direction $\Leftarrow$.

Let $B$ be given such that $B^* \cdot B = A$.

\[ z^* \cdot B^* \cdot B \cdot z = (Bz)^* \cdot B \cdot z \]
\[ (Bz)^* = z^* B^* \]
\[ (Bz)^* Bz = [v_1, \ldots, v_n] \cdot \begin{bmatrix} \overline{v_1} \\ \vdots \\ \overline{v_n} \end{bmatrix} \coloneqq \sum_{i=1}^n \overline{v_1} \cdot v_1 = \sum_{i=1}^n \card{v_i}^2 \geq 0 \]

Direction $\Rightarrow$.

Side remark:
\[
  \begin{bmatrix} I_r & 0 \\ 0 & 0 \end{bmatrix}^2 =
  \begin{bmatrix} I_r & 0 \\ 0 & 0 \end{bmatrix}
\]

Let $A \geq 0$.
\[
  \implies \exists C \in \mathbb C^{n \times n}:
  A = C^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} C
\] \[
  A = C^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} C = C^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix}^* \begin{bmatrix} 1 & & & \\ & \ddots & & \\ & & 1 & \\ & & & 0 \end{bmatrix} C = (C')^* \cdot C' \iff A = (C')^* \cdot C'
\]

\subsection{Exercise 28b}

$A > 0$, iff $A \hat= I_n$.

\[ B^* AB = I_n \iff B^* AB = I_n \iff AB = (B^*)^{-1} \iff ABB^* = I_n \]
\[ B^*A = B^{-1} \qquad \underbrace{BB^* A}_{A^{-1}} = I_n \]

$A^{-1} > 0$.

\[ A^{-1} \hat= I_n \iff \exists C \in \operatorname{GL}(n, \mathbb C): C^* \cdot A^{-1} \cdot C = I_n \iff A^{-1} = (C^*)^{-1} \cdot C^{-1} \]
\[ A^{-1} = B \cdot B^* \qquad (B^{-1})^* = C \]

\subsection{Exercise 28c}

Show: $A \geq 0 \implies a_{ii} = 0$ and $a_{ii} = 0 \implies \text{ without loss of generality } a_{11} = 0 \qquad a_{1i} \neq 0 \quad a_{ij} = 0 \forall j$.

\[ A = B^* B \implies a_{11} = \sum_{j=1}^n \overline{b_{j1}} \cdot b_{j1} = \sum_{j=1}^n \card{b_{j1}}^2 \overset!= 0 \]
\[ \implies b_{j1} = 0 \forall j \]
\[ a_{1i} = 0 \qquad \text{gives a contradiction} \]

\subsection{Exercise 28d}

\[ A = 0 \iff \det(A_r) \geq 0 \forall r \in \set{1, \ldots, n} \]
\[
  \begin{vmatrix}
    1 & 0 & 0 \\
    0 & 0 & 0 \\
    0 & 0 & -1
  \end{vmatrix}
\]

\section*{Exercise 29}
\begin{ex}
  Show
  \begin{enumerate}
    \item $A \leq B :\iff B - A \geq 0$ (hence $B-A$ is semidefinite) defines an order relation on the set of self-adjoint matrices.
    \item If $B > 0$ and $A \geq B$, then $A > 0$
  \end{enumerate}
\end{ex}

\subsection{Exercise 29a}

An order relation is a partial order. We show:
\begin{description}
  \item[reflexivity] $xRx$
  \item[anti symmetry] $xRy \land yRx \implies x = y$
  \item[transitivity] $xRy \land yRz \implies xRz$
\end{description}

We show antisymmetry.

\[ \forall A \in M \text{ with } B-A \geq 0 \text{ and } A - B = 0 \]
it holds that $\forall x \in V:$
\[ x^T (B - A) \overline{x} \geq 0 \land x^T (A - B) \overline{x} \geq 0 \]
\[ x^T (B - A) \overline{x} = 0 \implies x^T B \overline{x} = x^T A \overline{x} \]


\[ B - A = C^* DC \]
\[ D = \begin{bmatrix} 1 &  & & &  & \\ & \ddots & & &  & \\ & & 1 & & & \\ & & & 0 & & \\ & & & & \ddots & \\ & & & & & 0 \end{bmatrix} \]

\[ A - B = C^* (-D) C \]
\[ D = -D = 0 \]
\[ \implies B = A \]

We show reflexivity.

\[ \forall A \in M \forall x \in V: 0 = x^T \cdot 0 \cdot \overline{x} = x^T (A - A) \overline{x} = 0 \implies A - A \geq 0 \]

We show transitivity.

\[ \forall A, B, C \in M: B - A \geq 0 \land A - B > 0 \]

It holds that
\[ \forall x \in V: x^T (B - A) \overline{x} \geq 1 \qquad x^T (C - B) \overline{x} \geq 0 \]
\[ \implies 0 \leq x^T (B - A) \overline{x} + x^T (C - B) \overline{x} \]
\[ = x^T \left((B - A) \overline{x} + (C - B) \overline{x}\right) = x^T (B - A, C - B) \overline{x} = \underbrace{x^T (C - A) \overline{x}}_{0 \leq} \]
\[ \implies C - A \geq 0 \]

\subsection{Exercise 29b}

Let $B > 0$ and $A \geq B$ then it holds that $A > 0$.
\[ \forall x \in V: x^T B \overline{x} > 0: x^T (A - B) \overline{x} - x^T A \overline{x}- x^T B \overline{x} \geq 0 \]
\[ \implies x^T A \overline{x} \geq x^T B \overline{x} > 0 \]


\[ \langle x, x\rangle_B = x^T B x = x^T Ax = \langle x,x\rangle_A \]
\[ x = e_j \implies B_{jj} = A_{jj} \]

\[ A = 0 \qquad B = \operatorname{rot}(\frac\pi2) \qquad \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} = \pi \]

\section*{Exercise 30}
\begin{ex}
  Let $Tr(A) = \sum_{i=1}^n a_{ii}$ be the trace of an $n\times n$ matrix over $\mathbb R$ or $\mathbb C$.
  Show:
  \begin{enumerate}
    \item $Tr: \mathbb K^{n\times n} \to \mathbb K$ is linear and for $A \in \mathbb K^{n\times m}, B \in \mathbb K^{m\times n}$ it holds that $Tr(AB) = Tr(BA)$ but in general $Tr(ABC) = Tr(ACB)$ does not hold.
    \item Let $A,B$ be $n\times n$ matrices. $B$ is invertible. Show $Tr(B^{-1}AB) = Tr(A)$.
    \item Show: $\not\exists A,B: AB - BA = I$
    \item Show that $\langle A,B\rangle = Tr(B^*A)$ defines a positive definite scalar product over $\mathbb C^{n\times n}$.
    \item Find a real matrix $A$ such that $Tr(A^2) < 0$
    \item For a fixed positive definite matrix $A$, $\langle A,B\rangle_Q = Tr(B^*QA)$ defines a positive definite scalar product.
  \end{enumerate}
  Hint: Exercise 28 can be helpful.
\end{ex}

\subsection{Exercise 30a}

Show linearity.
\[ \forall A,B \in \mathbb K^{n \times n}: \underbrace{Tr(A + B)}_{\sum_{i=1}^n (a_{ii} + b_{ii})} = \underbrace{Tr(A)}_{\sum_{i=1}^n a_{ii}} + \underbrace{Tr(B)}_{\sum_{i=1}^n b_{ii}} \]
\[ \lambda \in K: \lambda Tr(A) + Tr(\lambda A) \]
\[ \lambda \sum_{i=1}^n a_{ii} = \sum_{i=1}^n \lambda a_{ii} \]

Show that multiplication is commutative for two traces.
Let $A \in \mathbb K^{n\times m}, B \in \mathbb K^{m\times n}$.
\[ Tr(AB) = Tr(BA) \]
\[ \sum_{i=1}^n \sum_{j=1}^m a_{ij} b_{{ji}} = \sum_{i=1}^m \sum_{j=1}^n b_{ij} a_{ji} = \sum_{i=1}^m \sum_{j=1}^n a_{ji} b_{ij} \]

Show that multiplication is not commutative in general. Does not hold unless $B = C$.
\[ Tr(ABC) \neq Tr(ACB) \]

\subsection{Exercise 30b}

Show that $Tr(B^{-1}(AB)) = Tr(A) \iff Tr(ABB^{-1}) = Tr(A)$.

\subsection{Exercise 30c}

Let $A, B \in \mathbb K^{n\times n}$.
\[ Tr(I_n) = n \]
\[ Tr(AB - BA) = Tr(AB) - Tr(BA) = 0 \]
\[ 0 \neq n \]
This gives a contradiction.

\subsection{Exercise 30d}

\begin{enumerate}
  \item Sesquilinearity:
    \[ \langle A+\lambda B, C\rangle \overset!= \angel{A,C} + \lambda \angel{B,C} \]
    \[ \angel{A, C+\lambda B} = Tr((C + \lambda B)^* A) = Tr((C^* + \overline{\lambda} B^*) A) = Tr(C^* A + \lambda B) \]
  \item Positive definiteness:
    \[ \angel{A,A} > 0 \qquad A \neq 0 \]
    \[ \Tr(A^*A) = \sum_{j=1}^n \sum_{l=1}^n \overline{a}_{l_j} a_{l_j} = \sum_{j=1}^{n} \sum_{l=1}^{n} \card{a_{lj}}^2 \]
\end{enumerate}

\subsection{Exercise 30e}

\[ A = \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} \]

\subsection{Exercise 30f}

$Q$ is positive definite.
\begin{align*}
  \angel{A,B}_Q &= Tr(B^*QA) \\
  \angel{A,A}_Q &= Tr(A^* M^* M A) \\
    &= Tr((MA)^* MA) \\
    &= \sum_{i=1}^n \sum_{j=1}^n \overline{(ma)}_j (ma)_j = \sum_{i=1}^n \sum_{j=1}^n  \card{ma_j}^2
\end{align*}

\[ Q = C^* DC \]
\[ \exists M: (Q)^{-1} = (M^* M)^{-1} = M^{-1} (M^*)^{-1} \]

Show $MA \neq 0$ if $A \neq 0$ and $\exists M^{-1} \iff A = M^{-1} 0$ gives a contradiction. Thus, we are finished.

\section*{Exercise 31}
\begin{ex}
  Let $A, B \in \mathbb C^{n\times n}$ be Hermitian matrices. Show:
  \begin{enumerate}
    \item $A \geq 0 \iff \exists x_1, x_2, \dots, x_n \in \mathbb C^{n\times 1}: A = \sum_{i=1}^n x_i x_i^*$.
    \item Let $C$ be the matrix with entries $c_{ij} = a_{ij} b_{ij}$. If $A \geq 0$ and $B \geq 0$, then also $C \geq 0$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 31a}

By Exercise 28, we know: $A \geq 0 \implies \exists B: A \cdot B^* \cdot B$.
\[ x_i \ldots (B^*)_i \qquad x_i^* \ldots (B)_i \]

\[ (x_i \cdot x_i^*)_W = x_i^k \cdot x_i^{*j} \]
\[ \sum_{i} (x_i x_i^*)_{k,j} = (B^*)_k \cdot (B)_j \]

\[ a_{kj} = \sum_{i=1}^n b_k^* b_{ij} \]

\subsection{Exercise 31b}

Direction $\Leftarrow$.

\[ A = \sum_{i=-1}^n x_i x_i^* \]
\[ y^T A \overline{y} = y^T \sum_{i=1}^n x_i x_i^* \cdot \overline{y} = \sum (y^T x_i)_{1\times 1} (x_i^* \overline{y})_{1 \times 1} = \sum \norm{y^T x_i}^2 \geq 0 \]

Direction $\Rightarrow$.

\[ A = \sum x_i x_i^* \qquad B = \sum y_i y_i^* \]
\[
  c_{ij} = a_{ij} \cdot b_{ij}
    = \sum_{k=1}^n x_k^i \cdot \overline{x_k^j} \cdot \sum_{l=1}^n y_l^i \overline{y_l^j}
    = \sum_{k,l=1}^n \underbrace{\left(x_k^i y_l^j\right)}_{z_{k,l^i}} \underbrace{\left(\overline{x_k^j} \overline{y_l^j}\right)}_{\overline{z_{k,l^j}}}
\]
\[
  \implies C = \sum_{k,l=1}^n z_{k,l} \cdot z_{k,l}^*
\]

\section*{Exercise 32}
\begin{ex}
  Let $(V, \ip{.}{.})$ be a vector space with scalar product and $U \subseteq V$ is a subspace. Show:
  \begin{enumerate}
    \item $U^\bot = U^{\bot\bot\bot}$;
    \item $V = U \dot{+} U^{\bot} \implies U = U^{\bot\bot}$.
    \item Show that the following construction is a counterexample for inversion of the previous statement:
      $V = C[-1,1]$ with scalar product $\langle f,g\rangle = \int_{-1}^1 f(t) g(t) \, dt$
      and subspace $U = \set{f \in C[-1,1] \middle| f(t) = 0 \forall t < 0}$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 32a}

\[ U^\bot = \set{v \in V: \forall u \in U: \ip uv = 0} \]
We prove:
\begin{enumerate}
  \item $U^\bot \subseteq U^{\bot\bot\bot}$
  \item $U^\bot \supseteq U^{\bot\bot\bot}$
\end{enumerate}

We begin with (1.)

Let $v \in U^\bot \implies v \in U^{\bot\bot\bot}$
\[ U^{\bot\bot\bot} = \set{v \in V \middle| \ip{v}{u''} = 0 \forall u'' \in U^{\bot\bot}} \]
By definition, this satisfies the claim.

In other words: we know $U \subseteq U^{\bot\bot}$. Consider $W = U^{\bot}$. Then $W \subset W^{\bot\bot}$.

We prove (2.)

Let $x \in U^{\bot\bot\bot} \implies \forall u \in U^{\bot\bot}: \ip xu = 0$.
Because $U \subseteq U^{\bot\bot}$, $\implies \forall u' \in U: \ip{x}{u'} = 0 \implies x \in U^{\bot}$.
Hence $U^{\bot} \in U^{\bot\bot\bot}$.

\subsection{Exercise 32b}

\[ V = U + U^{\bot} \implies U = U^{\bot\bot} \]
Show that $U^{\bot\bot} \subseteq U$.
Let $x \in U^{\bot\bot}$. $x = U + W$. $u \in U, w \in U^{\bot}$.
\[ \implies \forall y \in U^{\bot}: \ip xy = 0 = \ip{u+w}{y} = \ip uy + \ip wy = 0 \implies w = 0 \]
\[ \implies x = u \in U \]

\subsection{Exercise 32c}
Example for $U = U^{\bot\bot}$ but $V \neq U + U^{\bot}$.

\[ V = [-1,1] \qquad \ip fg = \int_{-1}^1 f(x) \cdot g(x) \, dx \]
\[ U = \set{f \in C[-1,1]: f(t) = 0 \forall t < 0} \]

Claim:
\[ U^{\bot} = \set{f \in C[-1,1], f(t) = 0 \forall t \geq 0} \]

Assume $f \in U^{\bot}$. Choose $g \in U$. We build a triangle below the point $f(g)$ and function $f$. The area of the triangle is non-negative and therefore non-zero.

Claim:
\[ U^{\bot\bot} = \set{f \in C[-1,1], f(t) = 0 \forall t < 0} \implies U = U^{\bot\bot} \]

\section*{Exercise 33}
\begin{ex}
  Let $V = \mathbb R^{n\times n}$ and $\langle A,B\rangle = \operatorname{Tr}(B^TA)$ the scalar product of Exercise~30.
  Determine the orthogonal complement.
  \[ \set{A \in \mathbb R^{n\times n} \middle| A = A^T}^\bot \]
\end{ex}

\[ U = \set{A \in \mathbb R^{n\times 1}: A = A^T}, \qquad V = \mathbb R^{n\times n} \]
\[
  A_{ii} = \begin{pmatrix}
    0 &   & 0 \\
      & 1 & \\
    0 &   & 0
  \end{pmatrix}
\]
positive at $(i,i)$.
\[
  A_{ij} = \begin{pmatrix}
    0 &   & 1 \\
      & 0 &  \\
    1 &   & 0
  \end{pmatrix}
\]
positive at $(j,i)$ with $i \neq j$.

\[ \Tr(B^T A) = \sum_{k,i=1}^n B_{ik} A_{ki} \overset!= 0 \]

For $A = A_{ii} \implies B_{ii} = 0$.
For $A = A_{ij} \implies B_{ij} + B_{ji} = 0$.
Skew-symmetric.

\section*{Exercise 34}
\begin{ex}
  Let
  \[ U = \set{x \in \mathbb R^5 \middle| \substack{x_1 - x_2 + x_3 - x_4 + x_5 = 0 \\ x_1 + x_3 + x_5 = 0}} \]
  be a subspace of $\mathbb R^5$ and $v = (1,-1,1,-1,1)^T$.
  \begin{enumerate}
    \item Determine the orthogonal projection $\pi_U(v)$ using the Gramian matrix.
    \item Determine the orthonormal basis of $U$
    \item Determine $\pi_U(v)$ using the orthonormal basis.
    \item Determine the matrix representation of $\pi_U$ in terms of the canonical basis.
  \end{enumerate}
\end{ex}

\subsection{Exercise 34b}

\[ \tilde a_1 = \begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} \]
\[ \norm{\tilde a_1} = \sqrt2 \]
\[ a_1 = \frac1{\sqrt2} \tilde a_1 \]
\[ \tilde a_2 = \begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix} - \frac12 \ip{\begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}}{\begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix}} \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} = \begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix} \]
\[ \norm{\tilde a_2} = \sqrt2 \qquad a_2 = \frac1{\sqrt{2}} \tilde a_2 \]
\[ \tilde a_3 = \begin{pmatrix} -1 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix} - \frac12 \ip{\begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}}{\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}} \begin{pmatrix} -1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} = \frac12 \ip{\begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix}}{\begin{pmatrix} -1 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}} \begin{pmatrix} 0 \\ -1 \\ 0 \\ 1 \\ 0 \end{pmatrix} = \begin{pmatrix} -\frac12 \\ 0 \\ -\frac12 \\ 0 \\ 1 \end{pmatrix} \]
\[ \norm{\tilde a_3} = \frac{\sqrt{6}}{2} \qquad a_3 = \frac2{\sqrt{6}} \tilde a_3 \]

\subsection{Exercise 34d}

\[ P = \sum_{i=1}^3 a_i a_i^* \]
\[
  P = \begin{pmatrix}
    \frac23 & 0 & -\frac23 & 0 & -\frac13 \\
    0 & \frac12 & 0 & -\frac12 & 0 \\
    -\frac23 & 0 & \frac23 & 0 & \frac13 \\
    0 & -\frac12 & 0 & \frac12 & 0 \\
    -\frac13 & 0 &\frac13 & 0 & \frac23
  \end{pmatrix}
\]


\section*{Exercise 35}
\begin{ex}
  Given the data $\vec x = (-2, -1, 1, 2)$ and $y = (1,1,-1, 1)$. Determine the coefficients $a_0, a_1, a_2$ of the quadratic polynomial function $f$ using an orthogonal projection.
  \[ f: \mathbb R \to \mathbb R \qquad x \mapsto a_0 + a_1 x + a_2 x^2 \]
  such that the value
  \[ \sum_{i=1}^4 (f(x_i) - y_i)^2 \]
  is minimal. Reason that the solution is unique.
\end{ex}

\section*{Partial exam, Exercise 4}

\[ A= \set{a_{ij}} \qquad C = \set{(-1)^{i+j}a_{ij}} \]
\[ \det(A) = \sum_{\sigma \in S_n} \prod_{i=1}^n a_{i \in \sigma(i)} \operatorname{sign}(\sigma) \]
\[ \det(C) = \sum_{\sigma \in S_n} \underbrace{\prod_{i=1}^n \underbrace{c_{i,\sigma(i)}}_{i-\sigma(i)}}_{\prod_{i=1}^n a_{i,\sigma(i)} (-1)^{\sum i - \sigma(i)}} \operatorname{sign}(\sigma) \]

\section*{Partial exam, Exercise 5}

\[ U_i \bot U_j \qquad i \neq j \]
\[ \forall u_i, w_i \in U_i: \sum w_i = \sum u_i \iff w_i = u_i \]

Consider $\sum (w_i - u_i)$. $\sum (w_i - u_i) = 0$.
\[ 0 = \norm{w_i - u_i}^2 = \ip{\sum w_i - u_i}{\sum w_i - u_i} = \sum \norm{w_i - u_i}^2 \]

\section*{Exercise 39}
\begin{ex}
  $\ip uv = u^T Av$ is the scalar product with $A = \begin{bmatrix} 2 & 1 \\ 1 & 1 \end{bmatrix}$.
  Determine the adjugate map to the linear map $f(x,y) = (2x - y, x + y)$.
\end{ex}
\[ V = \mathbb R^2 \qquad \ip uv = u^T Av \qquad f(x,y) = 2(x-y,x+y) \]
\[ f^*: \forall x, y \in \mathbb R: \ip{f^*(x),y} = \ip{x}{f(y)} \]
\[ f\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 2 & -1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} \qquad f^*\begin{pmatrix} x \\ y \end{pmatrix} = C\begin{pmatrix} x \\ y \end{pmatrix} \]
\[ \implies C^T A = AB \implies C^T = ABA^{-1} \]
\[ \ip{f^*(x)}{y} = \ip{Cx}{y} = (Cx)^T Ay = x^T C^T Ay \]
\[ \ip{x}{f(y)} = x^T A(By) \]
\[  C^T = \begin{pmatrix} 6 & 7 \\ 3 & -3 \end{pmatrix} \implies C = \begin{pmatrix} 6 & 3 \\ -7 & -3 \end{pmatrix} \]

\section*{Exercise 40}
\begin{ex}
  \begin{enumerate}
    \item Determine the matrix representation of the orthogonal reflection $\sigma_U$ on the plane $U = \set{x \in \mathbb R^3: x_1 + x_2 - x_3 = 0}$
    in regards of an appropriate orthonormal basis and in regards of a standard basis.
    \item Let $\sigma_V$ be an orthogonal reflection on the plane
      \[ V = \set{x \in \mathbb R^3: x_1 + x_2 + x_3 = 0}. \]
      Determine the matrix of the composition $\rho = \sigma_V \circ \sigma_U$ in regards of the standard basis and give a reason, why $\rho$ is a rotation. Determine rotation axis and rotation angle of $\rho$.
  \end{enumerate}
\end{ex}

Exercise (a).

\[ V = \set{x \in \mathbb R^3 \middle| x_1 + x_2 - x_3 = 0} \qquad \vec n = \begin{pmatrix} 1 \\ 1 \\ -1 \end{pmatrix} \]
Points on the plane $U$:
\begin{align*}
  &(0, 0, 0) \\
  &(1, -1, 0) \\
  &(1, 1, 2)
\end{align*}
\[ P_0(x_{10}, x_{20}, x_{30}) \]
Solve equation system.
\[
  \begin{pmatrix} x_{10} \\ x_{20} \\ x_{30} \end{pmatrix} + \lambda_n \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}
  = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} + \lambda_1 \begin{pmatrix} 1 \\ -1 \\ 0 \end{pmatrix} + \lambda_2 \begin{pmatrix} 1 \\ 1 \\ 2 \end{pmatrix}
\]
\[ \lambda_n = \frac13 (x_{30} - x_{20} - x_{10}) \]
\[ \delta_{UB} \coloneqq \begin{pmatrix} 1&0&0 \\ 0&1&0 \\ 0&0&-1 \end{pmatrix} \]
\[ B = \begin{pmatrix} \frac{1}{\sqrt2} \\ -\frac1{\sqrt2} \\ 0 \end{pmatrix}, \begin{pmatrix} \frac1{\sqrt6} \\ \frac1{\sqrt6} \\ \frac2{\sqrt6} \end{pmatrix}, \begin{pmatrix} \frac1{\sqrt3} \\ \frac1{\sqrt{3}} \\ \frac{1}{\sqrt{3}} \end{pmatrix} \]
\[
  \sigma_U(p_0) = \begin{pmatrix} x_{10} \\ x_{20} \\ x_{30} \end{pmatrix} + 2 \frac13 (x_{30} - x_{20} - x_{10}) \begin{pmatrix} 1 \\ 1 \\ -1 \end{pmatrix}
  = \frac13 \begin{pmatrix} x_{10} - 2x_{20} + 2x_{30} \\ -2x_{10} + x_{20} + 2x_{30} \\ 2x_{10} + 2x_{20} + x_{30} \end{pmatrix} \delta_{U,B} = \begin{pmatrix} \frac13 & -\frac23 & \frac23 \\ -\frac13 & \frac13 & \frac23 \\ \frac23 & \frac23 & \frac13 \end{pmatrix}
\]

Exercise (b).

\[
  p \cdot \begin{pmatrix} 1 \\ 1 \\ 2 \end{pmatrix} = \begin{pmatrix} -\frac{15}9 \\ -\frac{15}9 \\ \frac19 \end{pmatrix}
\] \[
  \cos\varphi = \frac{\ip{\begin{pmatrix} 1 \\ 1 \\ 2\end{pmatrix}}{\begin{pmatrix} -\frac19 \\ -\frac19 \\ \frac19 \end{pmatrix}}}{\sqrt6 \cdot \sqrt{\frac{151}{81}}}
\] \[
  = \frac{-\frac{28}{9}}{\sqrt6 \cdot \sqrt{\frac{451}{81}}}
\]

\[ \varphi = 122.5^\circ \]

But these calculations contain an error. $\approx 141^\circ$ should be correct.

\section*{Exercise 41}
\begin{ex}
  Show that every matrix $U \in \operatorname{SU}_2(\mathbb C)$ has structure $U = \begin{bmatrix} z & -\overline{w} \\ w & z \end{bmatrix}$ with $\card{z}^2 + \card{w}^2 = 1$.
\end{ex}

\[ U \in \operatorname{SU}_2(\mathbb C) \iff U = \begin{bmatrix} z & -\overline{w} \\ w & \overline{w} \end{bmatrix} \land \card{z}^2 + \card{w}^2 = 1 \]

Direction $\Leftarrow$.

Is easy. $U^* U = \dots = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$.

Direction $\Rightarrow$.

\[
  \begin{pmatrix}
    \overline a & \overline c \\
    \overline b & \overline d
  \end{pmatrix} = U^{-1}
\] \[
  U^{-1} = \frac{1}{\det(U)} \cdot \begin{pmatrix} d & -b \\ -c & a \end{pmatrix}
  = \frac11 \cdot \begin{pmatrix} d & -b  \\ -c & a \end{pmatrix} = \begin{pmatrix} \overline a & \overline c \\ \overline b & \overline d \end{pmatrix}
\] \[
  \implies d = \overline a \qquad b = -\overline c
\]

\section*{Exercise 42}
\begin{ex}
  Quaternions are elements of a $4$-dimensional vector space
  \[ \mathbb H = \set{a_0 + a_1 i + a_2 j + a_3 k: a_i \in \mathbb R} \]
  over $\mathbb R$ with formal basis $\set{1,i,j,k}$ and multiplication laws:
  \[ ij = k = -ji \qquad jk = i = -kj \qquad ki = j =-ik \qquad i^2 = j^2 = k^2 = -1 \]
  Show that
  \begin{enumerate}
    \item Quaterions give an associative algebra.
    \item Every quaternion has a multiplicative inverse.
    \item The map $\Phi: \mathbb H \to M_2(\mathbb C)$
      \[ a_0 + a_1i + a_2j + a_3k \mapsto a_0 \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} + a_1 \begin{pmatrix} i & 0 \\ 0 & -i \end{pmatrix} + a_2 \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix} + a_3 \begin{pmatrix} 0 & i \\ i & 0 \end{pmatrix} \]
    \item Show that $\operatorname{SU}_2(\mathbb C) \simeq \setdef{q \in \mathbb H}{q\overline q = 1}$. Hint: compare with 41.
  \end{enumerate}
\end{ex}

Exercise (a).

Simply long calculations.

Exercise (b).

Let $q \in \mathbb H \setminus \set{0}$.
\[ (a_0 + a_1 i + a_2 j + a_3 k)(a_0 - a_1 i - a_2 j - a_3 k) = a_0^2 + a_1^2 + a_2^2 + a_3^2 \]
\[ q^{-1} = \frac{a_0 - a_1 i - a_2 j - a_3 k}{a_0^2 + a_1^2 + a_2^2 + a_3^2} \]

$0$ is a quaternion, but just like in the real numbers, a multiplicative inverse only exists for the group except for $0$.

Exercise (c).

\[ (a_1 i + a_2 j) \mapsto a_1 \underbrace{\begin{pmatrix} i & 0 \\ 0 & -i \end{pmatrix}}_{\eqqcolon A} + a_2 \underbrace{\begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix}}_{\eqqcolon B} \]
$AB = C$. $C = \begin{pmatrix} 0 & i \\ i & 0 \end{pmatrix}$. And so on and so forth.

Exercise (d).

\[ \mathbb H_1 \coloneqq \setdef{q \in \mathbb H}{g \overline g = 1} \]
\[ \Phi: \mathbb H \to M_2(\mathbb C) \]
\[
  \begin{pmatrix} \alpha \\ \beta \\ \gamma \\ \delta \end{pmatrix}
  \mapsto \begin{bmatrix}
    \alpha + i \beta & \gamma + i\delta \\
    -\overline{(\gamma + i\delta)} & \overline{\alpha + i\beta}
  \end{bmatrix}
\]

Prove injectivity:
\[ p,q \in \mathbb H_1 \]
Show: $\Phi(p) = \Phi(q) \implies p = q$.

\[
  \begin{bmatrix}
    \alpha_1 + i\beta_1 & \gamma_1 + i\delta_1 \\
    \dots & \dots
  \end{bmatrix} - \begin{bmatrix}
    \alpha_1 + i\beta_1 & \gamma_1 + i\delta_1 \\
    \dots & \dots
  \end{bmatrix}
  = \begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix}
\] \[
  (\alpha_1 + i \beta_1) - (\alpha_2 + i\beta_2) = 0 \implies \alpha_1 = \alpha_2 \land \beta_1 = \beta_2
\]

Prove surjectivity:

Immediate if you look at the matrix representation above.

\section*{Remark: Rationale for quaternions}

\[ v - (v_x, v_y, v_z) \in S^2 = \set{\card{x}^2 + \card{y}^2 + \card{z}^2 = 1} \]
\[ \nu \in [0,2\pi] \]
Rotation with axis $v$ and angle $\theta = R_{\theta}^v$.
\[ q_{\nu}^V \coloneqq \cos(\frac\nu 2) - (v_x i + v_y j + v_z k) \sin(\frac\nu{2}) \]
\[ R_{\nu}^V w = q_\nu^v w \overline{q^v}_w \]
with $w = (w_x i + w_y j + w_z k)$.

Every rotation matrix can be represented as quaternion.

\section*{Exercise 38}

Exercise b.

Let $\set{p_n}_{n\geq 0}$ be orthogonal polynomials in $\mathbb R[x]$ in regards of $\int fgw \, dx$ (from Exercise a)
$\det(P_n) = n$ with leading coefficients $(p_n) = 1$.
What is $xp_n(x)$? $\sum_{j=0}^{n+i} \alpha_j p_j$.
The claim is $\alpha_j = 0 \forall j \in \set{0,\dots, n-2}$. $\alpha_{n+1} = 1$.

How about $\ip{xp_n}{p_0}$?
\[ \ip{xp_n}{p_0} = \int_{a}^b xp_2 1 w \, dt + 0 = \int_{a}^b xp_2 1 w \, dt + \int_{a}^b p_n \cdot c \cdot w \, dt = \int_{a}^b xp_2 1 w \, dt + \ip{p_n}{c \cdot p_0} \]
\[ \int_a^b p_n\underbrace{(x + c)}_{\eqqcolon p_1} w \,dt = \underbrace{\ip{p_n}{p_n}}_{n > 1} = 0 \]

How about $\ip{xp_n}{p_1}$?
\[ \ip{xp_1}{p_1} = \int_a^b \overbrace{x p_n (x + c)}^{p_n (x^2 + cx)} w \, dt + \underbrace{0}_{= \int_a^b p_n(x + c) \lambda w \, dt = \ip{p_n}{\lambda p_1}} \]
\[ = \int_a^b p_1(x^2 + (c + \lambda) x + \lambda c) w \, dt + \underbrace{0}_{\ip{p_n}{\gamma}} \]
\[ \gamma = \gamma \cdot p_0 \]
\[ \int_a^b p_n \underbrace{\left(x^2 + (c + \lambda) x + c \lambda + \gamma\right)}_{p_2} w \, dt \]
\[ \ip{p_n}{p_2} = 0 \]

\dateref{2018/05/23}

\section*{Exercise 43}
\begin{ex}
  The derivative of the polynomial $p(x) = a_0 + a_1x + \dots + a_n x^n \in \mathbb K[x]$ is defined (over an arbitrary field!) as
  \[ p'(x) = a_1 + 2a_2 x + 3a_3 x^2 + \dots + na_n x^{n-1}. \]
  Show:
  \begin{enumerate}
    \item The map $p(x) \mapsto p'(x)$ is linear and the Leibniz rule holds
      \[ (pq)'(x) = p'(x) q(x) + p(x) q'(x) \]
      as well as the chain rule
      \[ (p \circ q)'(x) = p'(q(x)) q'(x) \]
    \item If $q(x)$ is an irreducible factor of $p(x)$ with multiplicity $\geq 2$, then also $q(x)$ is a divisor of $\operatorname{gcd}(p(x), p'(x))$
    \item For $\mathbb K = \mathbb Q, \mathbb R, \mathbb C$ the inverse of the previous item holds as well. What can go wrong in finite fields?
  \end{enumerate}
\end{ex}

\subsection{Exercise 43a}
\[ (x^n x^m)' = (x^{n + m})' = (n + m) x^{n + m-1} \]
\[ \overset{\text{?}}= n x^{n-1} x^m + m x^{m-1} x^n \]

\subsection{Exercise 43b}
\[ ((p(x))^n)' = n p(x)^{n-1} p'(x) \]
\[ p(x)' = (q(x) q(x) p_R(x))' = q(x)' q(x) p_R(x) x q'(x) q(x) p_R(x) + p'_R(x) q(x) g(x) \]

\subsection{Exercise 43c}
Remark: $q(x)$ is irreducible.
\[ q(x) | p(x) \]
\[ q(x) | p'(x) \]


\[ q(x)^2 = p(x) \]

\section*{Exercise 44}
\begin{ex}
  \[ p(x) \coloneqq 8 + 12x + 14x^2 + 13x^3 + 6x^4 + x^5 \]
  Decompose polynomial $p(x)$ into irreducible factors over
  \[
    (a) \: \mathbb Q \qquad
    (b) \: \mathbb R \qquad
    (c) \: \mathbb C \qquad
    (d) \: \mathbb Z_{11} \qquad
    (e) \: \mathbb Z_{13}
  \]
\end{ex}

\subsection{Exercise 44c}
\[ (x + 2)^3 (x^2+1) \]
\begin{align*}
  x^2 + 1 &= 0 \\
  x^2 &= -1 \\
    &= \pm 1
\end{align*}
Factors are:
\[ (x + 2)^3 (x + i) (x - i) \]

\subsection{Exercise 44a,b}
Factors are:
\[ (x^2)^3 (x^2 + 1) \]

\subsection{Exercise 44d}
Considering $(x^2+1)$ in $\mathbb Z_{11}$.
\begin{align*}
  x^2 &\equiv -1 \\
  x^2 &\equiv -1 \pmod{11} \\
  x^2 &\equiv 10 \pmod{11} \\
  x^2 &\equiv -1 \pmod{11} \\
\end{align*}

\subsection{Exercise 44e}
Considering $(x^2+1)$ in $\mathbb Z_{13}$.
\[ x^2 \equiv -1 \pmod{13} \]
holds for $x = 5 \land x = 8$.
\[ (x^2 + 1) = (x - 5)(x - 8) = x^2 - \underbrace{13x}_{\equiv 0} + \underbrace{40}_{\equiv 1} \]

\section*{Exercise 45}
\begin{ex}
  Let $p(x) \coloneqq x^7 - x^5 + x^4 - x^3 + x - 1$ and $q(x) \coloneqq x^8 - x^5 - x^4 + x^3 - 2x^2 + 2x - 2$.
  Determine $\operatorname{gcd}(p(x), q(x))$ with Euclidean algorithm over $\mathbb Q[x]$ and polynomials $a(x)$ and $b(x)$ such that $a(x) p(x) + b(x) q(x) = \operatorname{gcd}(p(x), q(x))$
\end{ex}

\[ x^8 - x^5 - x^4 + x^3 - 2x^2 + 2x - 2 = (x^3 - 2) \cdot \operatorname{gcd} \]
\[ \operatorname{gcd} = x^5 + x^2 - x + 1 \overset!= (x^2 + 1)(x^3 - x + 1) \]

\[ a(x) p(x) + b(x) q(x) = \operatorname{gcd} \]

Evaluation:
\[ q(x) : p(x) = x \]
\[ p(x) : R_1 = x+2 \]
\[ 3x^5 + 3x^2 - 3x + 3 = R_2 \]
\[ R_1 : R_2 = \frac13 x - \frac23 \]
\[ 0 = R_3 \]

\begin{align*}
  q(x) &= p(x) x + R_1 \\
    &= \left[(x + 2) \cdot R_1 + R_2\right] \cdot x + R_1 \\
    &= \left[(x + 2) \cdot \left(\frac13 x - \frac23\right) R_2 + R_2\right] \cdot x + \left[\frac13 x - \frac23\right] R_2 \\
    &R_2\left[\left[(x + 2) \left(\frac13 x^2 - \frac23\right) + 1\right] \cdot x + \left(\frac13 x - \frac23\right)\right] \\
    &= \frac13 R_2 \left[\left[(x + 2) (1x - 2) + 3\right] \cdot x + (1x - 2)\right] \\
    &\frac13 R_2 [(x^2 - 4) + 3] \cdot x + (1x - 2) \\
    &x^3 - 4x + 3x + 1x - 2 \\
    &x^3 - x + x - 2 \\
    &\frac13 R_2(x^3 - 2)
\end{align*}

\begin{center}
  \begin{tabular}{ccc}
    i & $b_i$  & $a_i$ \\
  \hline
    1 & 0      & 1 \\
    2 & 1      & $0 - (x + 2)$ \\
    3 & $-x-2$ & $1 - [x (x + 2)]$
  \end{tabular}
\end{center}
\[ 1 - [x (x + 2)] = x^2 + 2x + 1 \]

\section*{Exercise 46}
\begin{ex}
  Let $p(x)$ and $q(x)$ be non-disappearing polynomials of degree $m$ and $n$ over some field $\mathbb K$. Show:
  \begin{itemize}
    \item $\operatorname{gcd}(p(x), q(x)) = 1 \iff$ polynomials $a(x)$ and $b(x)$ exist such that $a(x) p(x) + b(x) q(x) = 1$.
    \item $\operatorname{gcd}(p(x), q(x))$ is non-trivial iff polynomials $A(x)$ and $B(x)$ exist with $\deg{A(x)} < n$ and $\deg{B(x)} < m$ such that $A(x) p(x) + B(x) q(x) = 0$.
    \item Let $p(x) = p_0 + p_1 x + \dots + p_m x^m$ and $q(x) = q_0 + q_1 x + \dots + q_n x^n$ polynomials of degree $m$ and $n$ with $p_m, q_n \neq 0$.
      Show that $p(x)$ and $q(x)$ have a non-trivial common divisor iff the determinant $R(p, q)$ disappears.
      \[
        R(p, q) \coloneqq \begin{bmatrix}
          p_m & 0 & \dots & 0 & q_n & 0 & \dots & 0 \\
          p_{m-1} & p_m & \ddots & \vdots & q_{n-1} & q_n & \ddots & \vdots \\
          \vdots & p_{m-1} & \ddots & 0 & \vdots & q_{n-1} & \ddots & 0 \\
          p_0 & \vdots & \ddots & p_m & q_0 & \vdots & \ddots & q_n \\
          0 & p_0 & \ddots & p_{m-1} & 0 & q_0 & \ddots & q_{n-1} \\
          \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \dots & p_0 & 0 & 0 & \dots & q_0
        \end{bmatrix}
      \]
      with $n + m$ columns.
  \end{itemize}
\end{ex}

\subsection{Exercise 46a}
$\operatorname{gcd}(p(x), q(x)) = 1 \iff \exists a(x), b(x): a(x) p(x) + b(x) q(x) = 1$.

\textbf{Personal notes:}
\begin{align*}
  a(x) \cdot p(x) + b(x) \cdot q(x) &= 1 \\
  1 \cdot gcd(p(x), q(x)) &= d(x) \qquad \deg(d(x)) > 1 \\
  a(x) \cdot d(x) \cdot p_1(x) + b(x) \cdot d(x) \cdot q_1(x) &= 1 \\
  d(x) \cdot \left[a(x) \cdot p_1(x) + b(x) \cdot q_1(x)\right] &= 1 \\
  a(x) \cdot p_1(x) + b(x) \cdot q_1(x) &= \frac1{d(x)}
\end{align*}
$1$ has a lower polynomial degree than $d(x)$. Thus $\frac1{d(x)}$ represents a hyperbola.
As $x \to \infty$, a polynomial goes to infinity or minus infinity. A hyperbola goes to zero.
Thus, $\frac1{d(x)}$ cannot be a polynomial unless $d(x) = 1$.

\subsection{Exercise 46b}
\[ \deg(\operatorname{gcd}(p(x), q(x))) \geq 1 \iff \exists A(x), B(x) \]
s.t. $\deg(A(x)) < n = \deg(q(x))$ and $\deg(B(x)) < m = \deg(p(x))$
and $A(x) p(x) + B(x) q(x) = 0$.

Direction $\implies$.

\[ p(x) = \operatorname{gcd} \cdot \underbrace{p_R(x)}_{\deg < m} \]
\[ q(x) = \operatorname{gcd} \cdot \underbrace{q_R(x)}_{\deg < n} \]

\[ A(x) = q_R(x)(-1) \qquad B(x) = p_R(x) \]

\[ a(x) p_R(x) \cdot \operatorname{gcd}(p, q) + b(x) q_R \cdot \operatorname{gcd}(p, q) = 1 \]
\[ \deg(\operatorname{polynom}(x) \cdot \operatorname{gcd}) = \deg(1) = 0 \]
\[ \underbrace{\deg(\operatorname{polynom}(x))}_{\leq 0} + \underbrace{\deg(\operatorname{gcd})}_{\geq 0} = 0 \]

Direction $\impliedby$.

Without loss of generality, $\operatorname{A, B} = 1$.
\[ A(x) p(x) = -B(x) q(x) \]
\[ \underbrace{\deg(A(x) p(x))}_{< m + n} = \deg(B \cdot q) \]

\[ \implies p(x) | B(x) q(x) \]
$\implies \exists$ factor/irreducible polynomial.
\[ p(x) = \prod_{i=1}^{m'} \underbrace{p_i(x)}_{\text{irreducible}} \]
\[ \deg(B) < m \]
$p(x)$ does not divide $B(x)$. Thus, $\exists i \in \set{1, \dots, m}: p_i | q(x)$.

\textbf{Personal notes:}
\enquote{nichtverschwindend} = \enquote{nicht konstant}
\[ \deg(p) = m \qquad \deg(g) = n \]
\[ \gcd(p(x), g(x)) \neq 1 \iff \exists A(x), B(x): A(x) p(x) + B(x) q(x) = 0 \iff \exists A(x), B(x): \frac{A(x)}{B(x)} = -\frac{g(x)}{p(x)} \]

Direction $\implies$:
\[ \gcd(p(x), g(x)) = d(x) \qquad \deg{d} \geq 1 \]
\[ p(x) = d(x) \cdot p_1(x) \qquad g(x) = d(x) \cdot g_1(x) \]
\[ \implies \frac{g(x)}{p(x)} = \frac{d(x)}{d(x)} \cdot \frac{g_1(x)}{p_1(x)} = -\left(-\frac{g_1(x)}{p_1(x)}\right) \]
\[ \implies \frac{g(x)}{p(x)} = -\frac{A(x)}{B(x)} \]

\subsection{Exercise 46c}

\[ L: \mathbb R^{n + m} \to \mathbb R \]
\[ \begin{pmatrix} a_n \\ a_{n-1} \\ a_{n-2} \\ \vdots \\ a_0 \\ b_m \\ b_{m-1} \\ \vdots \\ b_0 \end{pmatrix} \mapsto p(x) \overbrace{(a_n x^n + a_{n-1} x^{n-1} + \dots + a_0^{0})}^{\eqqcolon A(x)} + q(x) (\overbrace{b_m x^m + b_{m-1} x^{m-1} + \dots + b_0}^{\eqqcolon B(x)}) \to \mathbb R^{n + m} \]
$\angle(\vec v) = R(q, p) \cdot \vec v$

\section*{Exercise 47}
\begin{ex}
  Let $A = \begin{bmatrix} a & b \\ 0 & a \end{bmatrix}$ and $p(x) \in \mathbb K[x]$ is a polynomial.
  Determine $p(A)$. Hint: Consider the polynomials $p(x) = x^n$, $n = 1, 2, \dots$ and prove the result.
\end{ex}

\[ p(x) = \alpha_m x^m + \alpha_{m-1} x^{m-1} + \dots + \alpha_1 x^1 + \alpha_0 x^0 \]
\[ A^2 = A \cdot A = \begin{pmatrix} a & b \\ 0 & a \end{pmatrix} \begin{pmatrix} a & b \\ 0 & a \end{pmatrix} = \begin{pmatrix} a^2 & 2ab \\ 0 & a^2 \end{pmatrix} \]
\[ A^3 = \begin{pmatrix} a^3 & 3a^2 b \\ 0 & a^3 \end{pmatrix} \]
\[ A^n = \begin{pmatrix} a^n & na^{n-1} b \\ 0 & a^n \end{pmatrix} \]
\[
  \forall A > 0:
  p(A) = \begin{pmatrix}
    p(a) & p'(a) b \\
    0 & p(a)
  \end{pmatrix} \qquad a \neq 0
\]

\section*{Exercise 48}
\begin{ex}
  Determine the eigenvalues and eigenvectors of the matrix
  \[
    \begin{bmatrix}
      9 & 6 & -2 & 3 \\
      -15 & -9 & 4 & -5 \\
      15 & 9 & -4 & 5 \\
      12 & 6 & -4 & 4
    \end{bmatrix}
  \]
  over $\mathbb R$ and $\mathbb C$ and if possible, a matrix $B$ such that $B^{-1} AB = \operatorname{diag}(\lambda_1, \lambda_2, \lambda_3, \lambda_4)$.
\end{ex}

\[ \det(A - \lambda I) = \lambda^4 - \lambda^2 \]

\[ v_1 = \begin{pmatrix} 0 & -2 & 3 & 6 \end{pmatrix} \]
\[ v_2 = \begin{pmatrix} 2 & -2 & 4 & 0 \end{pmatrix} \]
\[ v_3 = \begin{pmatrix} -i-3 & 5 & -5 & 2i-4 \end{pmatrix} \]
\[ v_4 = \begin{pmatrix} i-3 & 5 & -5 & -2i-4 \end{pmatrix} \]

\section*{Exercise 49}
\begin{ex}
  Let $A$ be a $\mathbb K^{n\times n}$ matrix. Show:
  \begin{enumerate}
    \item If $p(x) \in \mathbb K[x]$ is a polynomial such that $p(A) = 0$, then all eigenvalues $\lambda \in \operatorname{spec}(A)$ satisfy $p(\lambda) = 0$.
    \item If $A$ is regular, then the eigenvalues are given by
      \[ \operatorname{spec}(A^{-1}) = \set{\frac1{\lambda} : \lambda \in \operatorname{spec}(A)} \]
      and the associated eigenspaces are the same.
  \end{enumerate}
\end{ex}

\section*{Exercise 50}
\begin{ex}
  Let $A, B \in \mathbb K^{n \times n}$. Show that $\operatorname{spec}(AB) = \operatorname{spec}(BA)$.
\end{ex}

We use a case distinction. Consider $\lambda \neq 0$.

There exists $v \neq 0$, such that
\[ AB v = \lambda v \iff (BA)(Bv) = \lambda (Bv) \iff \lambda \in \operatorname{spec}(BA) \text{ with } Bv \neq 0 \]
We chose some $v \neq 0$. The opposite direction works analogously, but we cannot simply claim the proof works for both directions (because we chose some specific $v$).

Consider $\lambda = 0$.

\[ \det(0I - AB) = 0 \iff \det(-A) \det(B) = 0 \iff \det(-BA) = 0 \iff 0 \in \operatorname{spec}(BA) \]

\section*{Exercise 51}
\begin{ex}
  Let $A$ be a $\mathbb K^{n\times n}$ diagonalizable matrix with eigenvalues $\lambda_1, \lambda_2, \dots, \lambda_n$.
  \begin{enumerate}
    \item Show there exist matrices $M_1, M_2, \dots, M_n \in \mathbb K^{n\times n}$ with properties:
      \begin{enumerate}
        \item idempotent, $M_i^2 = M_i$
        \item $M_i M_j = 0$ if $i \neq j$
        \item $\operatorname{rank}(M_i) = 1$
      \end{enumerate}
      such that $A = \sum_{i=1}^n \lambda_i M_i$. Furthermore $A^k = \sum_{i=1}^n \lambda_i^k M_i \forall k \in \mathbb N$.
    \item Let $\mathbb K = \mathbb C$. Determine the matrices $M_1, M_2, \dots, M_n$ for the $n\times n$ matrix
      \[
        \begin{bmatrix}
          0 & 0 & 0 & \dots & 0 & 1 \\
          1 & 0 & 0 & \dots & 0 & 0 \\
          0 & 1 & 0 & \dots & 0 & 0 \\
          \ldots & \ldots & \ldots & \ddots & \vdots & \ldots \\
          0 & 0 & 0 & \dots & 1 & 0 \\
        \end{bmatrix}
      \]
  \end{enumerate}
\end{ex}

\[ \exists B \in \mathbb K^{n\times n}: B^{-1} AB = D = \operatorname{diag}(\lambda_1, \dots, \lambda_n) \iff A = BDB^{-1} \]
\begin{align*}
  a_{ij} &= (BDB^{-1})_{ij} \\
         &= \sum_{k=1}^n (BD)_{ik} (B^{-1})_{kj} \\
         &= \sum_{k=1}^n \left((\sum_{i=1}^n B)_{il} \cdot (D)_k\right) \cdot (B^{-1})_{kj} \\
         &= \sum_{k=1}^n (B_{ik}) \cdot \lambda_k \cdot (B^{-1})_{kj}
\end{align*}
\[ B = (b_{ij})_{1 \leq i, j \leq n} \qquad B^{-1} = (b'_{ij})_{1 \leq i,j \leq n} \]

\[ a_{ij} = \sum_{k=1}^n \lambda_k \cdot b_{ik} \cdot b_{kj}' \]
\[ M_i = (b_{ir} \cdot b'_{rj})_{1 \leq i,j \leq n} \implies A = \sum_{i=1}^{n} \lambda_i \cdot M_i \]

The three properties:
\begin{enumerate}
  \item
    \begin{align*}
      (M_r^2) &= \sum_{k=1}^n (M_r)_{ik} \cdot (M_r)_{kj} \\
        &= \sum_{k=1}^n b_{ir} \cdot b_{rk}' \cdot b_{kr} \cdot b_{ij}' \\
        &= b_{ir} \cdot b_{ij} \cdot \sum_{k=1}^{n} b_{rk}' \cdot b_{kl} \\
        &= (M_r)_{ij} (B^{-1} B)_{rr} = (M_r)_{ij}
    \end{align*}
  \item Let $r \neq s$.
    \begin{align*}
      (M_r M_s)_{ij} &= \sum_{k=1}^n (M_i)_{ik} (M_j)_{kj} \\
        &= \sum_{k=1}^n b_{ii} \cdot b_{ik}' \cdot b_{ks} \cdot b_{si}' \\
        &= b_{ir} \cdot b_{sj}' \cdot (B^{-1} B)_{is} = 0
    \end{align*}
  \item $\operatorname{rank}(M_i) = 1$. Let $r \in \set{1, \dots, n}$ is arbitrarily fixed and let $v_k$ be the k-th column vector. \dots. 1
\end{enumerate}


\subsection{Exercise 51b}
\[ \mathbb K = \mathbb C \]
\[
  T = \begin{pmatrix}
    0 & 0 & \ldots & 1 \\
    1 & \ddots & 0 & 0 \\
    \vdots & \ddots & 0 & \vdots \\
  \end{pmatrix}
\]
\[ \det(\lambda - T) = \begin{vmatrix} \lambda & 0 & & -1 \\ -1 & \ddots & 0 & 0 \\ \vdots & \ddots & \ddots & \vdots \\ 0 & & -1 & \lambda \end{vmatrix} = \lambda \begin{vmatrix} \lambda & & 0 \\ -1 & \ddots & \\ \vdots & \ddots & \\ 0 & & -i\lambda \end{vmatrix} + (-1)(-1)^{n+1} \begin{vmatrix} -1 & \lambda & &  \\ & \ddots & \ddots & \\ & & -1 \end{vmatrix} \]
\[ = \lambda^n - 1 \overset!= 0 \implies \lambda = \sqrt[n]{n} \]
\[ \lambda_k = e^{i \frac{2\pi k}{n}}: k \in \set{1,\dots,n} \]
\[ T v_{k} = T\begin{pmatrix} v_{k,1} \\ \vdots \\ v_{k,n} \end{pmatrix} = \begin{pmatrix} v_{k,1} \\ v_{k,2} \\ \vdots \\ v_{k,n-1} \end{pmatrix} = \lambda_k \begin{pmatrix} v_{k,1} \\ \vdots \\ v_{k,n} \end{pmatrix} \implies v_{k,l} = \frac{e^{-i \frac{2\pi kl}{n}}}{\sqrt{n}} \]
\[ v_{k,n} = \lambda_k v_{k,n} \qquad v_{k,l} = \lambda_k v_{k,l+1} \qquad l = 1, \dots, n-2 \]
\[ \langle v_k, v_m\rangle = \sum_{l=1}^n e^{-i \frac{2\pi (k-m) l}{n}} = \frac{e^{-i \frac{2\pi (k-m)}{n}} \left(1 - e^{-i 2\pi (k-m) \frac nn}\right)}{1 - e^{-i \frac{2\pi(k-m)}{n}}} = 0 \]
\[ \implies B = \begin{pmatrix} \vdots v_1 \vdots & \dots & \vdots v_n \vdots \end{pmatrix} \]
\[ B^{-1} = B^* \]
\[ M_k = B\begin{pmatrix} 0 & & & & 0 \\ & \ddots & & & \\ & & 1 & & \\ & & & \ddots & \\ 0 & & & & 0 \end{pmatrix} \cdot B^{-1} = v_k \cdot v_k^* = M_k \]


\dateref{2018/06/06}

\section*{Exercise 52}
\begin{ex}
  Let $A \in \mathbb K^{n \times n}$. Show equivalence of the following statements:
  \begin{enumerate}
    \item $\rank(A) = 1$
    \item $0$ is an eigenvalue of geometric multiplicity $n-1$
    \item There are vectors $x, y \in \mathbb K^n$ with $x, y \neq 0$ such that $A = xy^T$
  \end{enumerate}
\end{ex}

Trivial for $n = 1$. Let $n > 1$.

Let $A \in \mathbb K^{n \times n}$.
\begin{enumerate}
  \item[$1 \to 2.$]
    \[ \rank(A) = 1 \iff \text{rowrank}(A) = 1 \implies A = \begin{bmatrix} a_1 & \dots & a_n \\ \lambda_1 a_1 & \dots & \lambda_n a_n \\ \vdots & \ddots & \vdots \\ \lambda_n a_1 & \dots & \lambda_n a_n \end{bmatrix} \]
    \[ \det(0 \cdot I - A) = 0 = \det(-A) = 0 \]
    \[ d(0) = \dim\ker(0 \cdot I - A) = \dim\ker(-A) \]
    \[ \dim\image(A) = \rank(A) = 1 \]
    \[ \underbrace{\dim(A)}_{= n} = 1 + d(0) \]
  \item[$1 \iff 3.$]
    \[
      A
      = \begin{bmatrix} \lambda_1 a_1 & \dots & \lambda_n a_n \\ \vdots & \ddots & \vdots \\ \lambda_n a_1 & \dots & \lambda_n a_n \end{bmatrix}
      = \begin{bmatrix} \lambda_1 \\ \vdots \\ \lambda_n \end{bmatrix} [a_1, \dots, a_n]
      = \begin{bmatrix} a_1 \\ \vdots \\ a_n \end{bmatrix}^T
    \]
  \item[$2 \to 1.$]
    $0 \in \operatorname{spec}(A)$. $d(0) = n - 1 = \dim\ker(A - 0 \cdot I) = \dim\ker(A)$.
    \[ \dim(A) = \dim\image(A) + \dim\ker(A) = \rank(A) + n - 1 \]
    \[ n = \rank(A) + n - 1 \implies \rank(A) = 1 \]
\end{enumerate}

\section*{Exercise 53}
\begin{ex}
  \begin{enumerate}
    \item Let $f: V \to V$ be a diagonalizable linear map and $W \subseteq V$ an invariant subspace. Show that $f|_W: W \to W$ is diagonalizable as well.
    \item Let $A, B \in \mathbb K^{n \times n}$ be diagonalizable matrices. Show that $AB = BA$ holds iff there exists a basis whose entries are eigenvectors of $A$ and $B$ simultaneously.
  \end{enumerate}
  Hint: Show that the eigenspaces of $A$ and $B$ are invariant.
\end{ex}

\subsection{Exercise 53a}

Diagonalizable $\iff \exists$ basis $B$ of $V$ of eigenvectors $V$ of $f$.
\[ V = \oplus \gamma_{\lambda_i} \]
Let $n$ be the number of eigenvalues.
\[ \forall v \in V: \exists! v_i \in \gamma_{\lambda_i}: v = \sum_{i=1}^n v_i \]
\[ \forall w \in W: \exists! v_i \in \gamma_{\lambda_i}: w = \sum_{i=1}^n w_i \implies \exists! B = \set{b_1, \dots, b_m}: b_i \in \gamma_{\lambda_{j_i}} \]

Recall that
\[ V \cap W = W = \oplus \underbrace{(\gamma_{\lambda_i} \cap W)}_{\neq 0 \text{ thus gives a vector of the basis}} \]

\subsection{Exercise 53b}
Let $C$ be the basis of eigenvectors of $A$ and $B$.

Direction $\impliedby$.
\[ \forall c \in C: ABc = A \lambda^B_C c = \lambda_C^A \lambda_C^B c = B \lambda_C^A C = BA c \implies AB = BA \]

Direction $\implies$.
Let $x \in \gamma_\lambda^A$ and let $AB = BA$.
\[ BA x = B \lambda x = \lambda Bx = ABx \implies Bx \in \gamma_{\lambda}^A \]

By (1), $B|_{\ker(\lambda - A)}$ diagonal $\forall \lambda \in \operatorname{spec}(A)$.
\[ \implies \exists b'_1, \dots, b'_n \eqqcolon B \text{ for } \ker(\lambda_i - A) \implies B = \bigcup_i B^i \text{ basis of } V \]
\[ V = \oplus \ker(\lambda_i - A) \]

\section*{Exercise 54}
\begin{ex}
  Let $A \in \mathbb K^{n \times n}$ be a matrix. For a given vector $v \in \mathbb K^n$ consider the sequence $v, Av, A^2 v, \dots$.
  \[ m \coloneqq \min\setdef{k}{\exists c_0, c_1, \dots, c_{k-1}: A^k v = c_0 v + c_1 Av + \dots + c_{k-1} A^{k-1} v} \]
  Show:
  \begin{enumerate}
    \item $v, Av, A^2 v, \dots, A^{m-1} v$ are linear independent.
    \item $U_v = \mathcal L\set{v, Av, \dots, A^{m-1} v}$ is the smallest $A$-invariant subspace containing $v$.
    \item Let $A^m v = \sum_{i=0}^{m-1} c_i A^i v$. Determine the matrix representation of restriction $C = \Phi_B^B(f_A|_{U_v})$ in regards of basis $B = (v, Av, A^2 v, \dots, A^{m-1} v)$.
  \end{enumerate}
\end{ex}

\subsection{Exercise 54a}
\[ c_0 v + c_1 Av + \dots + c_{m-1} A^{m-1} v = 0 \implies c_i = 0 \forall i = 0, \dots, n-1 \]
\[ k = \max\set{i: c_i \neq 0} \implies k \leq m - 1  \]
It holds that $c_0 v + c_1 Av + \dots + c_{k+1} A^{k-1} v = -c_k A^k v \implies m \leq k$.

$m \leq k$ contradicts with $k \leq m-1$.

\subsection{Exercise 54b}
\[ \forall w \in U_v: Aw \in U_v \]
Assume $\exists W: v \in W, W$ invariant.
\[ B = \text{ basis of } W \]
\[ \implies B = \set{v, b_2, \dots, b_m} = \set{v, Av, \dots} \]

\subsection{Exercise 54c}
\[ B = \set{w, Av, \dots, A^{m-1} v} \]
\[ A^n v = \sum_{i=0}^{n-1} c_i A^i v \]
\[ \Phi_B^B(f|_{U_v}) \]

\begin{table}
  \begin{center}
    \begin{tabular}{ccccc}
      $b_1$ & $b_2$ & \dots & $b_{n-1}$ & $b_{n-2}$ \\
    \hline
      $b_1$ & $0$ & $0$ & $\ddots$ & $c_0$ \\
      $b_2$ & $1$ & $0$ & $\ddots$ & $c_1$ \\
      $\vdots$ & $\vdots$ & & & $\vdots$ \\
      $b_n$ & $0$ & $0$ & $\ddots$ & $c_n$
    \end{tabular}
  \end{center}
\end{table}

\section*{Exercise 55}
\begin{ex}
  \begin{enumerate}
    \item Let $A \in \mathbb C^{n \times n}$ and $p(x), q(x) \in \mathbb C[x]$ polynomials with $p(A) q(A) = 0$ and $\operatorname{gcd}(p(x), q(x)) = 1$. Show that $\image{q(A)} = \ker{p(A)}$.
    \item Let $A$ be an idempotent matrix ($A^2 = A$). Show that $A$ is diagonalizable.
  \end{enumerate}
\end{ex}

\subsection{Exercise 55a}

\[ A \in \mathbb C^{n \times n} \qquad p(x) q(x) \in \mathcal C[x] \qquad p(A) q(A) = 0 \qquad \operatorname{gcd}(p,q) = 1 \]
\begin{enumerate}
  \item $\forall v \in V: p(A) q(A) v = 0 \implies \image(q(A)) \subseteq \ker(p(A))$
  \item By exercise 46, $\operatorname{gcd}(p,q) = 1 \iff \exists a, b \in \mathbb C[x]: p(x) a(x) + q(x) b(x) = 1$
    \[ \implies \forall v \in V: p(A) a(A) v + q(A) b(A) v = v \implies V = \image{p(A)} + \image{q(A)} \]
    \[ \implies \dim\image{p(A)} + \dim\image{q(A)} \geq n \qquad n = \dim(V) \]
    \[ \dim{\image{p(A)}} + \dim{\ker{p(A)}} = n \]
    \[ \implies \dim\image{q(A)} \geq \dim\ker{p(A)} \iff \image(q(A)) \subseteq \ker(p(A)) \]
\end{enumerate}

\subsection{Exercise 55b}
\[ \implies \lambda_i = \set{0, 1} \]
\[ A^2 v = A \lambda_i v_i = \lambda_i^2 v_i = \lambda_i v_i \]

\section*{Exercise 56}
\begin{ex}
  Determine all invariant subspaces of matrices (over $\mathbb C$)
  \[
    (a) \quad A = \begin{bmatrix} 1 & & & \\ & -1 & & \\ & & 1 & \\ & & & 0 \end{bmatrix} \qquad
    (b) \quad B = \begin{bmatrix} 1 & & \\ & 1 & 1 \\ & & 1 \end{bmatrix}
  \]
\end{ex}

\[ \chi_A(\lambda) = (\lambda + 1) (\lambda - 1)^2 \lambda \]

Consider $\lambda = 0$.
\[ \ker(A) = \begin{pmatrix} -1 & & & 0 \\ & 1 & & \\ & & -1 & \\ & 0 & & 0 \end{pmatrix} \implies v_1 = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \end{pmatrix} \qquad U_3 = \mathcal L\set{\begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}} \]

Consider $\lambda = 1$.
\[ v_2 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} \qquad a_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix} \implies \mathcal L\set{\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}} = U_4 \]

Consider $\lambda = -1$.
\[ v_4 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} \qquad \mathcal L\set{\begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}} = U_5 \]
\[ \image(A) = \set{\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}} = U_6 \]

Is this set complete?
Difficult to prove.


Alternative approach (a constructive approach):
\[ W \subseteq \mathbb C^4, \text{ invariant in regards of } A \]
$W$ is of structure on the left side.

\[ v = \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \end{pmatrix} \]
$\mathcal L(v)$ is invariant.

\[ \begin{pmatrix} a \\ b \\ c \\ d \end{pmatrix} \in W \]
\[
  \begin{pmatrix} 0 \\ 0 \\ 0 \\ d \end{pmatrix}
  = \begin{pmatrix} a \\ b \\ c \\ d \end{pmatrix} - \begin{pmatrix} a \\ b \\ c \\ 0 \end{pmatrix} \in W
\]
\[ A \begin{pmatrix} a \\ b \\ c \\ d \end{pmatrix} = \begin{pmatrix} a \\ -b \\ c \\ 0 \end{pmatrix} \]
\[ A^2 \begin{pmatrix} a \\ b \\ c \\ d \end{pmatrix} = \begin{pmatrix} a \\ -b \\ c \\ 0 \end{pmatrix} \]

If $d = 0 \implies \underbrace{W}_{= W^{-1}} \subset \mathbb C^3 \times \set{0}$.
If $d \neq 0 \implies e_k \in W \implies W = W^{-1} \oplus \mathcal L(e_4)$ with $W^{-1} \subseteq \mathbb C^3$.

\[ \begin{pmatrix} a \\ b \\ c \\ 0 \end{pmatrix} \in W^{-1} \]
\[ A \begin{pmatrix} a \\ b \\ c \\ 0 \end{pmatrix} = \begin{pmatrix} a \\ -b \\ c \\ 0 \end{pmatrix} \in W^{-1} \]
\[ \begin{pmatrix} a \\ b \\ c \\ 0 \end{pmatrix} - \begin{pmatrix} a \\ -b \\ c \\ 0 \end{pmatrix} \in W^{(-1)} \]
\[ b = 0 \implies W^{-1} \in \mathcal L(e_1, e_3) \]
\[ b \neq 0 \implies e_2 \in W^{-1} \subseteq W \]
\[ W = W^{-2} \oplus \mathcal L(e_2, e_4) \]

\[ \underbrace{\begin{pmatrix} a \\ b \\ c \\ 0 \end{pmatrix} - \begin{pmatrix} a \\ -b \\ c \\ 0 \end{pmatrix}}_{\begin{pmatrix} 0 \\ b \\ 0 \\ 0 \end{pmatrix}} \in W^{(-1)}  \]
\[ A \begin{pmatrix} a \\ b \\ c \\ 0 \end{pmatrix} = \begin{pmatrix} a \\ -b \\ c \\ 0 \end{pmatrix} \in W^{-1} \]
\[ A \begin{pmatrix} a \\ 0 \\ c \\ 0 \end{pmatrix} = \begin{pmatrix} a \\ 0 \\ c \\ 0 \end{pmatrix} \]


\section*{Exercise 57}
\begin{ex}
  We call $J_k(\lambda)$ the Jordan block of length $k$ of eigenvalue $\lambda$, hence
  \[ J_k(\lambda) = \begin{bmatrix} \lambda & 1 & & & \\ & \lambda & 1 & & \\ & & \ddots & \ddots & \\ & & & \lambda & 1 \\ & & & & \lambda \end{bmatrix} \]
  Given a block diagonal matrix with the following Jordan blocks $J_k(\lambda)$:
  \[
    A = \begin{bmatrix}
      J_2(0) & & & & & & & & \\
      & J_3(0) & & & & & & & \\
      & & J_3(0) & & & & & & \\
      & & & J_1(1) & & & & & \\
      & & & & J_1(1) & & & & \\
      & & & & & J_2(1) & & & \\
      & & & & & & J_3(1) & & \\
      & & & & & & & J_5(1) &
    \end{bmatrix}
  \]
  Determine $\dim\ker(\lambda I - A)^k$ for $\lambda \in \set{0,1}$ and $0 \leq k \leq 20$ and bases of all eigenspaces and main spaces.
\end{ex}

$(e_1, e_3, e_6)$.

Let $k = 2$. $(e_1, e_2, e_3, e_4, e_6, e_7)$.

\begin{tabular}{ccc}
  k \textbackslash $\lambda$ & 0 & 1 \\
\hline
  1 & 3 & 5 \\
  2 & 6 & 8 \\
  3 & 8 & 10 \\
  4 & 8 & 11 \\
  5 & 8 & 12 \\
  6 & 8 & 12 \\
  \vdots & \vdots & \vdots
\end{tabular}

\[ \dim\ker(\lambda \mathbf 1 - A)^2 \]
\[ (e_9 e_{10} e_{11} e_{13} e_{16}) + (e_{12} e_{14} e_{12}) + (e_{15} e_{18}) + (e_{19}) \]

\section*{Exercise 58}
\begin{ex}
  For a matrix $A \in \mathbb C^{20 \times 20}$ the following kernel dimensions are known:

  \begin{center}
    \begin{tabular}{c|ccccccc}
      $k$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
    \hline
      $\ker(A - 2I)^k$ & 1 & 2 & 3 & 4 & 5 & 6 & 6 \\
      $\ker(A - I)^k$  & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
      $\ker(A)^k$      & 3 & 4 & 5 & 6 & 7 & 7 & 7 \\
      $\ker(A + I)^k$  & 3 & 6 & 6 & 6 & 6 & 6 & 6 \\
      $\ker(A + 2I)^k$ & 0 & 1 & 1 & 1 & 1 & 1 & 1
    \end{tabular}
  \end{center}

  \begin{enumerate}
    \item Two numbers in this table are wrong. Find and fix them.
    \item Determine a Jordan normal form and the minimal polynomial of $A$.
  \end{enumerate}
\end{ex}

$0$ in the last row is wrong. If $\ker(A + 2I) = \set{0}$, then $(A + 2I)$ is regular. The product of regular matrices is regular. Hence the kernel must be trivial ($= \set{0}$).

\[ \lambda = -1 \qquad k = 7 \qquad \text{ not 7, but 6} \]
\[ \lambda = -2 \qquad k = 1 \qquad \text{ not 0, but 1} \]

\[ J = \operatorname{diag}(J_6(2), J_5(0), J_1(0), J_2(-1), J_2(-1), J_2(-1), J_1(-2)) \]
\[ a_S(\lambda) = 2a_J - a_{J-1} - a_{J+1} \]
\[ (\lambda - 2)^6 \lambda^5 (\lambda + 1)^2 (\lambda + 2) \]

\[
  \begin{pmatrix}
    0 & 0 & 0 & 0 \\
    2 & 2 & 2 & 0 \\
    1 & 1 & 1 & 0 \\
    4 & 3 & 2 & 1
  \end{pmatrix}
\]

\section*{Exercise 61}
\begin{ex}
  Determine and interpret the evaluation of the exponential function of the cross product:
  \[ e^{\vec \varphi x}] \vec v = \vec v + \vec \varphi \times \vec v + \frac1{2!} \vec\varphi \times (\vec \varphi \times \vec v) + \frac1{3!} \vec\varphi \times (\vec \varphi (\vec \varphi \times \vec v)) + \dots \]
  where $\vec\varphi \coloneqq (q, 0, 0)^T$. Hint: matrix representation of linear map $\vec\varphi \times: \vec x \mapsto \vec \varphi \times \vec x$.
\end{ex}

\[
  \vec\varphi = \begin{pmatrix} \varphi \\ 0 \\ 0 \end{pmatrix} \qquad
  \vec v = \begin{pmatrix} v_1 \\ v_2 \\ v_3 \end{pmatrix} \qquad
  \varphi
\]
\[ = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & 1 & 0 \end{pmatrix} \]

\[ \left(\sum_{k=0}^\infty \frac{A^k}{k!}\right) \cdot \vec v = \sum \]

\section*{Exercise 59}
\begin{ex}
  The matrix $A$ has the characteristic polynomial
  \[
    A = \begin{bmatrix}
      -5 & -1 & -5 & -7 & -7 & -4 \\
      1 & -3 & 0 & -1 & -1 & 0 \\
      7 & 5 & 8 & 12 & 12 & 6 \\
      3 & -3 & 2 & 2 & 1 & 1 \\
      -8 & 6 & -6 & -6 & -5 & -4 \\
      7 & -10 & 4 & 1 & 1 & 3
    \end{bmatrix}
  \]
  \begin{enumerate}
    \item Determine for every main space $\ker(\lambda_i - A)^{r_i}$ a basis ($u_1^{(i)}, u_2^{(i)}, \dots, u_{n_i}^{(i)}$) in such a way that every ($u_1^{(i)}, u_2^{(i)}, \dots, u_{m_{i,k}}^{(i)}$) is a basis of $\operatorname{ker}(\lambda_i - A)^k$.
    \item Determine a Jordan normal form $J$ and the minimal polynomial of $A$ and a regular matrix $B$ such that $B^{-1}AB = J$.
  \end{enumerate}
\end{ex}

\[ \chi_A = (x - 1)^3 (x + 1)^3 \]
\[ \ker(A - 1) = \set{x_1 \begin{pmatrix} 1 \\ 0 \\ -1 \\ 1 \\ 0 \\ -2 \end{pmatrix} + x_3 \begin{pmatrix} 0 \\ 0 \\ 0 \\-1 \\ 1 \\ 0 \end{pmatrix}, x_1, x_3 \in \mathbb R} \]
\[ \ker(A + 1) = \set{x_4 \cdot \begin{pmatrix} 1 \\ 1 \\ -2 \\ 1 \\ -2 \\ 3 \end{pmatrix}, x_4 \in \mathbb R} \]
\[ \dim\ker(A - 1) = 2 \qquad \dim\ker(A + 1) = 1 \]
\[
  J = \begin{pmatrix}
    1 &   &   &    &    & \\
      & 1 & 1 &    &    & \\
      &   & 1 &    &    & \\
      &   &   & -1 & 1  & \\
      &   &   &    & -1 & 1 \\
      &   &   &    &    & 1
  \end{pmatrix}
\] \[
  B: B^{-1} AB = J
\] \[ \implies AB = BJ \]
\[ B = (b_1, b_2, \dots, b_6) \]
where $b_i$ are column vectors.
\[ AB = \begin{pmatrix} b_1 & b_2 & b_2+b_3 & -b_4 & b_4-b_5 & b_5-b_6 \end{pmatrix}  \]

\[ (A - 1) b_1 = 0 \qquad (A + 1) b_4 = 0 \]
\[ (A - 1) b_2 = 0 \qquad (A + 1) b_5 = b_4 \]
\[ (A - 1) b_3 = b_2 \qquad (A + 1) b_0 = b_5 \]

\[
  B = \begin{pmatrix}
    0 & 1 & -1 & 1 & 1 & -1 \\
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & -1 & 0 & -2 & -1 & 2 \\
    -1 & -1 & -1 & 1 & 0 & 0 \\
    1 & 2 & 0 & -2 & 0 & -1 \\
    0 & -2 & 3 & 3& 0 & 0
  \end{pmatrix}
\]

\section*{Exercise 63}
\begin{ex}
  Show that a matrix is nilpotent if and only if $0$ is the only eigenvalue.
\end{ex}

$A$ is nilpotent $\iff \exists k \in \mathbb N: A^k = 0$.
We assume an algebraically closed field, because otherwise a counterexample can be found.

Direction $\implies$.

Assume there exists a eigenvalue $\lambda \neq 0$: $A^k = 0 \iff \ker(0 \cdot I - A)^k = V$.
\[ A^k x = \lambda^k x \]
This gives a contradiction.
If the field is algebraically closed, then $0$ is the only eigenvalue.

Direction $\impliedby$.

Let $A \in \mathbb K^{n \times n} \implies \chi_A(\lambda) = \lambda^n$.
\[ \chi_A(A) = 0 \xRightarrow{\text{Cayleigh-Hamilton}} A^r = 0 \implies \exists k \in \mathbb N: A^k = 0 \]

\section*{Exercise 64}
\begin{ex}
  Determine a unitary matrix $U$, that diagonalizes the matrix
  \[
    \begin{pmatrix}
      i & 1 & i & -1 \\
      -1 & i & 1 & i \\
      i & -1 & i & 1 \\
      1 & i & -1 & i
    \end{pmatrix}
  \]
\end{ex}

\[
  U = \begin{pmatrix}
    -i/\sqrt{2} & 1/\sqrt{6}  & i/\sqrt{12}  & -i/2 \\
    1/\sqrt{2}  & -i/\sqrt{6} & 1/\sqrt{12}  & -1/2 \\
    0           & 2/\sqrt{6}  & -i/\sqrt{12} & i/2 \\
    0           & 0           & 3/\sqrt{12}  & 1/2
  \end{pmatrix}
\]

\section*{Exercise 65}
\begin{ex}
  Let $A \in \mathbb C^{n \times n}$ be a normal matrix with eigenvalues $\lambda_1, \lambda_2, \dots, \lambda_n$.
  Show that for an arbitrary vector $x \in \mathbb C^n$ it holds that
  \[ \norm{Ax} \leq \max_{1 \leq i \leq n} \card{\lambda_i} \norm{x} \]
\end{ex}

$A \in \mathbb C^{n \times n}$ is normal and $\lambda_1, \dots, \lambda_n$ are eigenvalues.
$x \in \mathbb C^n$. Show that $\norm{Ax} \leq \max_{1 \leq i \leq n} \card{\lambda_i} \norm{x}$.
$B = \set{u_1, \dots, u_n} \subseteq \mathbb C^n \implies \exists \text{ linear combination}: x = \sum_i \mu_i u_i$.
\begin{align*}
  \norm{Ax} &= \norm{A \cdot \sum_{i=1}^n \mu_i u_i} \\
    &= \norm{\sum_{j=1}^n \mu_i \cdot \lambda_i \cdot u_i} \\
    &= \sqrt{\angel{\sum_{i=1}^n \mu_i \lambda_i u_i}} \\
    &= \sqrt{\sum_{i=1}^n \angel{\mu_i \lambda_i u_i, \mu_i \lambda_i u_i}} \\
    &= \sqrt{\sum_{i=1}^n \card{\lambda_i}^2 \underbrace{\angel{\mu_i u_i, \mu_i u_i}}_{>0}} \\
    &\leq \max_{1 \leq j \leq n} \sqrt{\sum_{i=1}^n \angel{\mu_i u_i, \mu_i u_i}} \\
    &= \max_{1 \leq j \leq n} \card{\lambda_j} \norm{\sum_{i=1}^n \mu_i u_i} \\
    &= \max_{1 \leq j \leq n} \card{\lambda_j} \norm{x}
\end{align*}

\section*{Exercise 66}
\begin{ex}
  Determine the Schur normal form of matrix
  \[ \begin{bmatrix} 0 & -1 & 0 \\ 1 & 2 & 0 \\ -1 & -3 & -1 \end{bmatrix} \]
\end{ex}

Determine the eigenvalues:
\[ \det(A - \lambda I) = 0 \qquad \chi_A(\lambda) = (\lambda + 1)(\lambda - 1)^2 \]

Determine the eigenvectors:
\[ \lambda = -1 \implies \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \]

\[ W_1 = \begin{pmatrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \end{pmatrix} \qquad W_1^* = W_1 \]
\[ W^* A W = \begin{pmatrix} -1 & -3 & -1 \\ 0 & 2 & 1 \\ 0 & -1 & 0 \end{pmatrix} \]
Consider the bottom-right $2\times 2$ matrix as $A_2$.

\[ A_2 = \begin{pmatrix} 2 & 1 \\ -1 & 0 \end{pmatrix} \qquad \lambda_{2_1} = 1 \quad \lambda_{2_2} = 1 \]
\[ v_1 = \frac{1}{\sqrt2} \begin{pmatrix} 1 \\ -1 \end{pmatrix} \qquad v_2 = \frac{1}{\sqrt2} \begin{pmatrix} 1 \\ 1 \end{pmatrix} \]
\[
  w_2 = \begin{pmatrix}
    1 & 0 & 0 \\
    0 & \frac1{\sqrt2} & \frac1{\sqrt{2}} \\
    0 & -\frac1{\sqrt2} & \frac1{\sqrt2}
  \end{pmatrix}
\] \[
  W^*_2 \cdot W_1^* \cdot A \cdot W_1 \cdot W_2 = \begin{pmatrix}
    -1 & -\sqrt{2} & -2 \sqrt2 \\
    0 & 1 & 2 \\
    0 & 0 & 1
  \end{pmatrix}
\]
The diagonal elements are the eigenvalues and it is an upper triangular matrix.

\section*{Exercise 67}
\begin{ex}
  Let $A \in \mathbb C^{n \times n}$ be a normal matrix.
  Show that for an arbitrary matrix $B \in \mathbb C^{n \times n}$:
  \[ AB = BA \implies A^* B = BA^* \]
\end{ex}

$A \in \mathbb C^{n \times n}$ is normal with eigenvalues $\lambda_1, \dots, \lambda_n$ and $B \in \mathbb C^{n \times n}$ arbitrary.
Let $k$ be the number of different eigenvalues. $\Lambda_j \coloneqq \lambda_{n_j} \cdot I$.

$\exists U \in U_n(\mathbb C): U^* AU = D = \operatorname{diag}(\lambda_1, \dots, \lambda_n) = \operatorname{diag}(\Lambda_1, \dots, \Lambda_k)$.
\[ AB = BA \iff U^* AU U^* BU = U^* B UU^* AU \]
$C \coloneqq U^* B U$.
\[ \iff DC = CD \iff \sum_{\gamma=1}^n d_{i\gamma} c_{\gamma j} \iff \lambda_i \cdot c_{ij} = c_{ij} \cdot \lambda_j \iff c_{ij} = 0 \text{ if } \lambda_i \neq \lambda_j \]
$C = \operatorname{diag}(C_1, \dots, C_k)$ with $\dim{C_i} = \dim{\Lambda_i}$.
$D^* = \overline{D} = \operatorname{diag}(\overline{\Lambda_1}, \overline{\Lambda_k})$.
\[ D^* C = \operatorname{diag}(\overline\Lambda_1 C_1, \dots, \overline\Lambda_k C_k) = \operatorname{diag}(\overline \lambda_{n_1} C_1, \dots, \overline{\lambda}_{n_k} C_k) = \operatorname{diag}(C_1 \overline\Lambda_1, \dots, C_k \overline\Lambda_k) \]
\[ = CD^* \implies D^* C = CD^* \iff (U^* AU)^* \cdot U^* BU = U^* BU \cdot (U^* AU)^* \]
\[ \iff U^* A^* U U^* B U = U^* BUU^* A^* U \iff A^* B = BA^* \]

Also, $Av = \lambda v$.
\[ ABv = BAv = \lambda Bv \]
\[ B(E_j) \subseteq E_\lambda \]
\[ \operatorname{eigenspace}(A, \lambda) = \operatorname{eigenspace}(A^*, \overline\lambda) \]

\section*{Exercise 68}
\begin{ex}
  Determine the translation and a rotation, that transforms the quadric $Q$ into normal form.
  \[ Q = \setdef{x}{16 x_1^2 - 24 x_1 x_2 + 9 x_2^2 + 30x_1 + 40x_2 + 50 = 0} \subseteq \mathbb R^2 \]
\end{ex}

\[ x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} \qquad x^T Ax + b^T x + \gamma = 0 \]
\[ \implies A = \begin{pmatrix} 16 & -12 \\ -12 & 9 \end{pmatrix} \implies b = \begin{pmatrix} 30 \\ 40 \end{pmatrix} \qquad \gamma = 50 \]

Task 1: rotation.

\[ A = QDQ^* \]
\[ \chi_A(\lambda) = (\lambda - 16)(\lambda - 9) - 144 = \lambda (\lambda - 25) \]
\[ \implies \lambda_1 = 0 \qquad \lambda_2 = 25 \]
\[ D = \begin{pmatrix} 0 & 0 \\ 0 & 25 \end{pmatrix} \]

\[ \ker(0 - A) = \ker\begin{pmatrix} -16 & 12 \\ 12 & -9 \end{pmatrix} = \mathcal L\begin{pmatrix} 3 \\ 4 \\ 1 \end{pmatrix} \implies u_1 = \frac15 \begin{pmatrix} 3 \\ 4 \end{pmatrix} \]
\[ \ker(25 - 1) = \mathcal L\begin{pmatrix} 1 \\ -3 \\ 4 \end{pmatrix} \implies u_2 = \frac15 \begin{pmatrix} -4 \\ 3 \end{pmatrix} \]
\[ \implies Q = \frac15 \begin{pmatrix} 3 & -4 \\ 4 & 3 \end{pmatrix} \qquad \text{\enquote{rotation matrix}} \]
\[ \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = Q \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} \]
\[ (Qy)^T A (Qy) + b^T (Qy) + \gamma = 0 \]
\[ y^T \cdot \underbrace{Q^T A Q}_{D} \cdot y + b^T Q y + \gamma = 0 \]

Insert: $25y_2^2 + \xi D y_1 + \xi 0 = 0$.

\[ \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} = \begin{pmatrix} z_1 \\ z_2 \end{pmatrix} + \begin{pmatrix} t_1 \\ t_2 \end{pmatrix} \]

\[ y_2^2 + 2y_1 + 2 = 0 \]
\[ (z_2 + t_2)^2 + 2 (z_1 + t_1) + 2 = 0 \]
\[ z_2^2 + 2z_2 t_2 + t_2^2 + 2z_1 + 2t_1 + 20 \]

\[ 2t_2 \overset!= 0 \implies t_2 = 0 \]
\[ 2t_2 + t_2^2 +2 \overset!= 0 \implies t_1 = -1 \]


\[ t = \begin{pmatrix} -1 \\ 0 \end{pmatrix} \]
\[ z_2^2 + 2z_1 = 0 \]
\[ b^T \cdot Q = \frac13 \begin{pmatrix} 30 & 40 \end{pmatrix} \begin{pmatrix} 3 & -4 \\ 4 & 3 \end{pmatrix} = \begin{pmatrix} 50 & 0 \end{pmatrix} \]

Translation is not a linear map. Thus, it is described in vector multiplication, not as a matrix.

(rotation matrix $\implies$ determinant is one)

\section{Exercise 71}
\[ \ker{A} \cap \ker{B} = \set{0} \qquad AB = BA \]

\subsection{Exercise 71a}
\[ \ker{A^2} \cap \ker{B} = \set{0} \]
Let $x \in \ker{A^2} \cap \ker{B}: A^2 x = 0 \implies Ax \in \ker{A}$.
$Bx = 0$. $BAx = ABx = 0 \implies Ax \in \ker{B}$.

Thus, $Ax \in \ker{A} \cap \ker{B} = \set{0} \implies Ax = 0 \implies x \in \ker{A}$. By assumption $x \in \ker{B}$. Thus, $x \in \ker{A} \cap \ker{B} = \set{0} \implies x = 0$.

\subsection{Exercise 71b}
\[ \ker{A^2} \cap \ker{B^2} \overset!= 0 \]
\[ A' = B \qquad B' = A^2 \]
\[ \ker{A'} \cap \ker{B'} = \set{0} \]
\[ A' B' = B' A' \]

\[ BA^2 = BAA = ABA = AAB = A^2 B \]

We apply (a) to $A'$ and $B'$:
\[ \underbrace{\ker(A')^2 \cap \ker(B')}_{= \ker{B^2} \cap \ker{A^2}} = \set{0} \]

\subsection{Exercise 71c}
Inductive:
\[ A^{(2^k)} \cdot B^{(2^k)} = B^{(2^k)} \cdot A^{2^k} \]
Induction hypothesis: $\ker{A^{2^k}} \cap \ker{B^{2^k}} = \set{0}$.

We apply (b) to $A^{2^k}$ and $B^{2^k}$.
\[ \ker(A^{2^k})^2 \cap \ker(B^{2^k})^2 = \set{0} \]

Recall that $(A^{2^k})^2 = A^{2^k} \cdot A^{2^k} = A^{2^k} + A^{2^k} = A^{2 \cdo 2^k} = A^{2^{k+1}}$.

\subsection{Exercise 71d}
\[ \ker{A^r} \cap \ker{B^s} = \set{0} \]
choose $k$ such that $2^k \geq \max(r, s)$.

\[ \ker{A^r} \leq \ker{A^{2^k}} \land \ker{B^s} \leq \ker{B^{2^k}} \implies \ker{A^r} \cap \ker{B^s} \subseteq \ker{A^{2^k}} \cap \ker{B^{2^k}} = \set{0} \]

Main spaces $\lambda - A$ and $\mu - A$
\begin{enumerate}
  \item commute
  \item $\ker(\lambda - A) \cap \ker(\mu - A) = \set{0}$
\end{enumerate}
\[ \implies \ker(\lambda - A)^r \cap \ker(\mu - A)^s = \set{0} \]

\subsection{Exercise 72}
\begin{enumerate}
  \item Determine eigenvalues.
  \item Determine eigenvectors.
  \item Determine eigenspaces and \emph{main} spaces.

    For eigenvalue $8$, we get:
    \[ \mathcal L\left(\begin{pmatrix} 1 \\ 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}\right)  = \ker(8 - A)^k \qquad \forall k \]
    Eigenspace = main space, thus no further computations are required.
    \[
      B = \begin{bmatrix}
        1 & \dots \\
        0 & \dots \\
        0 & \dots \\
        1 & \dots \\
        0 & \dots \\
      \end{bmatrix}
      \qquad
      J = \begin{bmatrix}
        8 & \dots \\
        \vdots & \ddots
      \end{bmatrix}
    \]

    For eigenvalue $0$, we get:
    \[ \ker{A} = \mathcal L\left(\begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 2 \end{pmatrix}\right) \]
    \[ \ker{A^2} = \mathcal L \left(\begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 2 \end{pmatrix}, \begin{pmatrix} 3 \\ 2 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} -1 \\ 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}\right) \eqqcolon \set{u_1, u_2, u_3, u_4} \]
    $\dim = 4 \implies$ this is the main space.

    \[ v_1^{(2)} - v_3 = \begin{pmatrix} 3 \\ 2 \\ 0 \\ 0 \\ 0 \end{pmatrix} \in \ker{A^2} \]
    \[ \implies A \cdot u_3 \in \ker{A} \]
    are linear independent. $A u_4 \in \ker{A}$.
    \[
      A = \begin{pmatrix}
        4 & -2 & -4 & 4 & -2 \\
        0 & 0 & 0 & 0 & 0 \\
        2 & 1 & -2 & -2 & -1 \\
        4 & -6 & -4 & 4 & -2 \\
        -4 & 6 & 4 & 4 & 2
      \end{pmatrix}
    \]
    \[ v_1^{(1)} = A v_1^{(2)} = \begin{pmatrix} 8 \\ 0 \\ 8 \\ 0 \\ 0 \end{pmatrix} = 8 u_1 \]
    \[ v_2^{(1)} = A v_2^{(2)} = A \cdot \begin{pmatrix} -1 \\ 0 \\ 0 \\ 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ -4 \\ 0 \\ 8 \end{pmatrix} = 4 \cdot u_2 - 4 \cdot u_1 \]
    \[ \mathcal L(u_1, u_2) = \mathcal L(v_1^{(1)}, v_2^{(1)}) \]

    \[ v_1^{(1)} \quad v_2^{(1)} \quad | \quad v_1^{(2)} \quad v_2^{(2)} \]
    \[ \text{order: } v_1^{(1)} \to v_1^{(2)} \to v_2^{(1)} \to v_2^{(2)} \]

    \[
      B = \begin{bmatrix}
        1 & 8 & 3 & 0 & -1 \\
        0 & 0 & 2 & 0 & 0 \\
        0 & 8 & 0 & -4 & 0 \\
        1 & 0 & 0 & 0 & 1 \\
        0 & 0 & 0 & 8 & 0 \\
      \end{bmatrix}
      \qquad
      J = \begin{bmatrix}
        8 &   &   &   & \\
          & 0 & 1 &   & \\
          &   & 0 &   & \\
          &   &   & 0 & 1 \\
          &   &   &   & 0
      \end{bmatrix}
    \]
    where the second column is $v_1^{(1)}$, the third column is $v_1^{(2)}$, the third column is $v_2^{(1)}$ and the fourth column is $v_2^{(2)}$.
\end{enumerate}

\[ (A - \lambda I) v_i^{(k)} = v_i^{(k-1)} \implies A \cdot v_i^{(k)} = \lambda v_i^{(k)} + v_i^{(k-1)} \]

\section{Exercise 73}
\subsection{Exercise 73a}
\[ \operatorname{JNF}(A) = \operatorname{JNF}(A^T) \]
Eigenvalues of $A$ and $A^T$ are the same.
\[ \dim\ker(\lambda - A) = \dim\ker(\lambda - A^T) \]
\[ n-\text{rank}(\lambda - A)^k = n-\text{rank}(\lambda - A^T)^k \]
with $\dim\ker(\lambda - A) = n-\text{rank}(\lambda - A)^k$ and $\dim\ker(\lambda - A^T) = n-\text{rank}(\lambda - A^T)^k$.

This defines the size of the blocks uniquely.

\subsection{Exercise 73b}
\[ A = TJT^{-1} \qquad A^T = (T^t)^{-t} \cdot J^t \cdot T^t \]
\[ J^t = \begin{bmatrix}
    -2 &    &    &    & \\
    1  & -2 &    &    & \\
       &    & -2 &    & \\
       &    &  1 & -2 & \\
       &    &    &  1 & -2
  \end{bmatrix}
\]
Find $V$ such that
\[ V^{-1} J^T V = J \]
\[
  \begin{bmatrix} & 1 \\ 1 & \end{bmatrix}
  \begin{bmatrix} -2 &   \\ 1 & -2 \end{bmatrix}
  \begin{bmatrix} & 1 \\ 1 & \end{bmatrix}
  = \begin{bmatrix} -2 & 1 \\ 0 & -2 \end{bmatrix}
\]

\[
  \begin{bmatrix} & & 1 \\ & 1 & \\ 1 & & \end{bmatrix}
  \begin{bmatrix} -2 & & \\ 1 & -2 & \\ & 1 & -2 \end{bmatrix}
  \begin{bmatrix} & & 1 \\ & 1 & \\ 1 & & \end{bmatrix}
  =
  \begin{bmatrix} 0 & 1 & -2 \\ 1 & -2 & 0 \\ -2 & 0 & 0 \end{bmatrix}
  \begin{bmatrix} & & 1 \\ & 1 & \\ 1 & & \end{bmatrix}
  =
  \begin{bmatrix} -2 & 1 & 0 \\ 0 & -2 & 1 \\ 0 & 0 & -2 \end{bmatrix}
\] \[
  VJ^TV = J \implies J^T = VJV
\] \[
  A^T = (T^T)^1 J^T T^T = (T^T)^{-1} VJVT^t = UJU^{-1}
\] \[
  U = (T^t)^{-1} V
\]

\section{Exercise 74}

Given $x_1, \dots, x_n \in \mathbb C$ and $y_1, \dots, y_n \in \mathbb C$.
Then there exists $g(x) \in \mathbb C[x]_n$ such that $p(x_i) = y_i$.

Direction $\impliedby$.

Immediate. $A^* = p(A) \implies AA^* = Ap(A) = (x p(x))(A) = (p(x)x)(A) = p(A) A = A^* A$.

Direction $\implies$.

\[ AA^* = A^* A \implies A = U \begin{bmatrix} \lambda_1 & & \\ & \ddots & \\ & & \lambda_n \end{bmatrix} U^* \]
\[ A^* = U \begin{bmatrix} \overline{\lambda}_1 & & \\ & \ddots & \\ & & \overline{\lambda}_n \end{bmatrix} U^* \]
\[ p(A) = U \cdot \begin{bmatrix} p(\lambda_1) & & \\ & \ddots & \\ & & p(\lambda_n) \end{bmatrix} \cdot U^* \]

$p(x)$ is polynomial of degree $\leq n$ such that $p(\lambda_i) = \overline{\lambda_i} \implies p(A) = A^*$.

\section{Exercise 75}

$A$ is normal $\implies \exists$ ONB: $u_1, \dots, u_n$ of eigenvectors.

$x \in \mathbb C^n$ with $\norm{x} = 1$.
\[ x = \sum_1^n \alpha_i u_i \]
\[ \norm{x}^2 = \sum \card{\alpha_i}^2 = 1 \]
\[ \beta_i = \card{\alpha_i}^2 \implies W(A) = \set{\sum \lambda_i \beta_i}{\sum \beta_i = 1} \]

\[ \angel{Ax, x} = \angel{A \sum \alpha_i u_i, \sum \alpha_j u_j} = \angel{\sum \alpha_i \lambda_i u_i, \sum \alpha_j u_j} = \sum_{i,j\gamma} \alpha_i \lambda_i \overline\alpha_j \underbrace{\angel{u_i, u_j}}_{\delta_{ij}} = \sum \card{\alpha_i}^2 \lambda_i \]



\end{document}