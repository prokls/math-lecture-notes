\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{baskervald}
\usepackage{bbold}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{faktor}
\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red]{hyperref}
\usepackage{imakeidx} % before hyperref
\usepackage{mathalfa}
\usepackage{mathtools}
\usepackage{mdframed}
\usepackage[bigdelims,vvarbb]{newtxmath}
\usepackage{rotating}
\usepackage{stmaryrd}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{xcolor}

\renewcommand*\oldstylenums[1]{\textosf{#1}}

\theoremstyle{definition}
\newmdtheoremenv[%
  backgroundcolor=white,
  linecolor=white!60!black,
  linewidth=3pt]{ex}{Exercise}

\DeclareMathOperator\kernel{kernel}
\DeclareMathOperator\image{image}
\DeclareMathOperator\sign{sign}
\DeclareMathOperator\Hom{Hom}

\title{Linear Algebra 2 -- Practicals}
\author{Lukas Prokop}
\date{summer term 2016}

\newcommand\meta[3]{This #1 took place on #2 (#3).\par}
\newcommand\abs[1]{|\,#1\,|}
\newcommand\set[1]{\left\{#1\right\}}
\newcommand\setdef[2]{\left\{#1\,\middle|\,#2\right\}}
\newcommand\card[1]{\left|\,#1\,\right|}
\newcommand\divides[2]{#1\,\mid\,#2}
\newcommand\mathspace{\hspace{20pt}}
\newcommand\fun[1]{\left\langle{#1}\right\rangle}
\newcommand\Q{\mathbb{Q}}
\newcommand\nope{\lightning}
\newcommand\vecfour[4]{\begin{pmatrix} #1 \\ #2 \\ #3 \\ #4 \end{pmatrix}}
\newcommand{\textgreek}[1]{\begingroup\fontencoding{LGR}\selectfont#1\endgroup}

\parindent0pt
\parskip7pt
\setcounter{tocdepth}{1}

\begin{document}
\maketitle
\tableofcontents

\clearpage
Exercise I did on the board: 3, 7.

\section{Exercise 1}
\begin{ex}
  Determine the matrix representation of the linear map
  \[ f: \mathbb R_1[x] \to \mathbb R_2[x] \]
  \[ p(x) \mapsto (x-1) \cdot p(x) \]
  in regards of bases $B = \set{1-x, 1+x} \subseteq \mathbb R_1[x]$ and $C = \set{1, 1 + x, 1 + x + x^2} \subseteq \mathbb R^2[x]$.
\end{ex}

\[
  f: \mathbb R_1[x] \to \mathbb R_2[x]
\] \[
  f: p(x) \mapsto (x-1) p(x)
\] \[
  B = \set{1-x, 1+x} \eqqcolon \set{b_1, b_2}
\] \[
  C = \set{1, 1+x, 1+x+x^2} \eqqcolon \set{c_1, c_2, c_3}
\]

Find $A \in \mathbb K^{3\times 2} \eqqcolon M_C^B(f)$.

\[ \forall v \in \mathbb R_1: f(v) = w : \Phi_C(w) = A \Phi_B(v) \]

\[ f(b_1) = (1-x)(x-1) = -x^2 + 2x - 1 \]
\[ f(b_2) = (x-1)(x+1) = x^2 - 1 \]

\[ \Phi_C(f(b_1)) \]

Coefficient comparison:
\begin{align*}
  -x^2 + 2x - 1 &= \lambda_1 \cdot 1 + \lambda_2 (1 + x) + \lambda_3 (1 + x + x^2) \\
  x^2: & \lambda_3 = -1 \\
  x^1: & 2 = \lambda_2 + \lambda_3 \Rightarrow \lambda_2 = 3 \\
  x^0: & -1 = \lambda_1 + \lambda_2 + \lambda_3 \Rightarrow \lambda_1 = -3
\end{align*}

\[ \Phi_C(f(b_1)) = \begin{pmatrix} 3 \\ 3 \\ 1 \end{pmatrix} \]
\[ \Phi_C(f(b_2)): x^2 = 1 = \lambda_1 \cdot 1 + \lambda_2 (1 + x) + \lambda_3 (1 + x + x^2) \]
\begin{align*}
  x^2: & \lambda_3 = 1 \\
  x^1: & \lambda_2 + \lambda_3 = 0 \Rightarrow \lambda_2 = -1 \\
  x^0: & -1 = \lambda_1 + \lambda_2 + \lambda_3 \\
       & -1 = \lambda_1 - 1 + 1 \\
       & -1 = \lambda_1
\end{align*}

\[ \Phi_C(f(b_2)) = \begin{pmatrix} -1 \\ -1 \\ 1 \end{pmatrix} \]
\[ A = \begin{pmatrix} -3 & -1 \\ 3 & -1 \\ 1 & 1 \end{pmatrix} \]


\section{Exercise 3}
\begin{ex}
  Let $A_1, A_2, \ldots, A_k$ be quadratic $n\times n$ matrices over the field $\mathbb K$.
  Show that the product $A_1 A_2 \ldots A_k$ is invertible if and only if all $A_i$ are invertible.
\end{ex}

All $A_i$ are invertible, then $\prod A_i$ is invertible.

$A, B$ invertible, then $AB$ is invertible and $(AB)^{-1} = B^{-1} A^{-1}$.
Generalize by induction.

If $\prod A_i$ is invertible, then all $A_i$ are invertible.

Sidenote: We know that $\operatorname{rank}(A) = n - \dim{\kernel(A)}$.

\begin{description}
  \item[$k=1$] trivial
  \item[$k=2$] $A_1 A_2$ is invertible. Let $C = (A_1 A_2)^{-1}$. Then $C A_1 A_2 = I_n$.
    Let $x \in \kernel(A_2) \Rightarrow A_2 x = 0 \Rightarrow \underbrace{C A_1}_{I_n} A_2 x = C A_1 0 = 0$.
    \[ \kernel(A_2) = 0 \Rightarrow \operatorname{rank}(A_2) = n - 0: n \Rightarrow A_2 \text{ invertible} \]
    \[ A_1 = \underbrace{A_1 A_2}_{\text{invertible}} \cdot \underbrace{A_2^{-1}}_{\text{invertible}} \]
  \item[$k \to k+1$]
    Let $A_1 \ldots A_{k+1}$ is invertible $\Rightarrow (A_1, \ldots, A_k) A_{k+1}$ is invertible $\xRightarrow{k=2} A_1, \ldots, A_k$ is invertible, $A_{k+1}$ invertible $\xRightarrow{\text{induction base}}$ $A_1, \ldots, A_k, A_{k+1}$ is invertible.
\end{description}

Remark:
$A,B \in \mathbb K^{n\times n}$. $B$ is inverse of $A$
\[ \Leftrightarrow AB = I = BA \Leftrightarrow AB = I \Leftrightarrow BA = I \]

\section{Exercise 2}
%
\begin{ex}
  Let $V$ be a vector space and $f: V \to \mathbb V$ is a nilpotent linear map,
  hence there exists some $k \in \mathbb N$ such that $f^k = 0$.
\end{ex}

\subsection{Part a}
\begin{ex}
  Show that $\text{id}_V - f$ is invertible with $(\text{id}_V - f)^{-1} = \text{id}_V + f + f^2 + \ldots + f^{k-1}$.
\end{ex}

Show that: $(\text{id}_v - f)^{-1} = \sum_{i=0}^{k-1} f^i$.
\[ (\text{id}_V - f) \circ \left(\sum_{i=0}^{k-1} f^{i}\right) = \text{id}_V \circ \sum_{i=0}^{k-1} f^i - f \circ \sum_{i=0}^{k-1} f^i - \sum_{i=0}^{k-1} f^{i+1} = f^0 + \sum_{i=1}^{k-1} f^i - \sum_{i=1}^{k-1} f^i - f^k = \text{id}_V - 0 = \text{id}_V \]
and $\left(\sum_{i=0}^{k-1} f^i\right) \circ \left(\text{id}_V - f\right)$ analogously.

\subsection{Part b}
\begin{ex}
  Use part a) to determine the inverse of the matrix
  \[
    \begin{pmatrix}
      1 & 2 & 3 & 4 \\
      0 & 1 & 2 & 3 \\
      0 & 0 & 1 & 2 \\
      0 & 0 & 0 & 1
    \end{pmatrix}
  \]
\end{ex}
\[
  \begin{pmatrix}
    1 & 2 & 3 & 4 \\
    0 & 1 & 2 & 3 \\
    0 & 0 & 1 & 2 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \eqqcolon A
  = \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  - f_A
\] \[
  f_A = I_n - A =
  \begin{pmatrix}
    0 & -2 & -3 & -4 \\
    0 & 0 & -2 & -3 \\
    0 & 0 & 0 & -2 \\
    0 & 0 & 0 & 0
  \end{pmatrix}
\] \[
  f^2_A = f \cdot f = \begin{pmatrix} 0 & 0 & 4 & 12 \\ 0 & 0 & 0 & 4 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  f^3 = f^2 \cdot f = \begin{pmatrix} 0 & 0 & 0 & -8 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  f^4 = f^3 \cdot f = \begin{pmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\]
$\Rightarrow$ f nilpotent.

\[ A^{-1} = (\operatorname{id}_v - f)^{-1} = \operatorname{id}_v + f + f^2 + f^3 \]
\[
  = \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  +
  \begin{pmatrix}
    0 & -2 & -3 & -4 \\
    0 & 0 & -2 & -3 \\
    0 & 0 & 0 & -2 \\
    0 & 0 & 0 & 0
  \end{pmatrix}
  +
  \begin{pmatrix} 0 & 0 & 4 & 12 \\ 0 & 0 & 0 & 4 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
  +
  \begin{pmatrix} 0 & 0 & 0 & -8 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  = \begin{pmatrix} 1 & -2 & 1 & 0 \\ 0 & 1 & -2 & 1 \\ 0 & 0 & 1 & -2 \\ 0 & 0 & 0 & 1 \end{pmatrix}
\] \[
  A \cdot A' =
  \begin{pmatrix} 1 & 2 & 3 & 4 \\ 0 & 1 & 2 & 3 \\ 0 & 0 & 1 & 2 \\ 0 & 0 & 0 & 1 \end{pmatrix} \cdot
  \begin{pmatrix} 1 & -2 & 1 & 0 \\ 0 & 1 & -2 & 1 \\ 0 & 0 & 1 & -2 \\ 0 & 0 & 0 & 1 \end{pmatrix}
  = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}
\]

\section{Exercise 4}
\subsection{Part a}
\begin{ex}
  Let $A$ be an invertible $n\times n$ matrix over a field $\mathbb K$ and $u,v$ are
  column vectors (hence $n\times 1$ matrices), such that $\sigma  1 + v^t A^{-1} u \neq 0$.
  Show that $(A + uv^t)$ is invertible and that
  \[ (A + uv^t)^{-1} = A^{-1} - \frac1{\sigma} A^{-1} uv^t A^{-1} \]
\end{ex}

\subsection{Part b}
\begin{ex}
  Apply this formula to determine the inverse of the matrix
  \[
    A = \begin{pmatrix}
      5 & 3 & 0 & 1 \\
      3 & 2 & 0 & 0 \\
      0 & 0 & 2 & 3 \\
      0 & 0 & 3 & 5
    \end{pmatrix}
  \]
\end{ex}

\[
  B = A + S
\] \[
  B = \begin{pmatrix} 5 & 3 & 0 & 0 \\ 3 & 2 & 0 & 0 \\ 0 & 0 & 2 & 3 \\ 0 & 0 & 3 & 5 \end{pmatrix}
  + \begin{pmatrix} 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  \begin{pmatrix} 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
    = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} \cdot \begin{pmatrix} 0 & 0 & 0 & 1 \end{pmatrix}
\]

$A$ is invertible, because it is a block matrix\footnote{That's why chose $A$ and $S$ that way}.

\[
  A^{-1} = \begin{pmatrix}
    2 & -3 & 0 & 0 \\
    -3 & 5 & 0 & 0 \\
    0 & 0 & 5 & -3 \\
    0 & 0 & -3 & 2
  \end{pmatrix}
\] \[
  \sigma = 1 + \begin{pmatrix} 0 & 0 & 0 & 1 \end{pmatrix} A^{-1} \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} = 1 + 0 \neq 0
\]

\[ \Rightarrow B^{-1} = A^{-1} - A^{-1} \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} \cdot \begin{pmatrix} 0 & 0 & 0 & 1 \end{pmatrix} A^{-1}
  = \begin{pmatrix}
    2 & -3 & 6 & -4  \\
    -3 & 5 & -9 & 6 \\
    0 & 0 & 5 & -3 \\
    0 & 0 & -3 & 2
  \end{pmatrix}
\]

\section{Exercise 5}
\begin{ex}
  Show that the linear maps $f,g,h: \mathbb R^2 \to \mathbb R^2$ defined as
  \[
    f: (x_1, x_2) \mapsto (x_1 + x_2, x_1 - x_2) \quad
    g: (x_1, x_2) \mapsto (x_1 + x_2, x_1 + x_2) \quad
    h: (x_1, x_2) \mapsto (x_2, x_1)
  \]
  are linear independent, if they are considered as elements of the vector space
  $\Hom(\mathbb R^2, \mathbb R^2)$ of all maps from $\mathbb R^2$ to $\mathbb R^2$.
\end{ex}

Let $\lambda_1, \lambda_2, \lambda_3 \in \mathbb R$.
Show that
\[ \lambda_1 f + \lambda_2 g + \lambda_3 h = 0 \stackrel!{=} \lambda_1 = \lambda_2 = \lambda_3 = 0 \]

\[ f: x \mapsto Ax \qquad A_f = \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} \qquad A_g = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} \qquad A_n = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \]

Is an isomorphism, $\Hom(\mathbb R^2, \mathbb R^2) \to \mathbb R^{2 \times 2}$ with $f \mapsto A_f$.

\[ \lambda_1 \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} + \lambda_2 \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} + \lambda_3 \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix} \]

\[
  \begin{pmatrix}
    1 & 1 & 0 \\
    1 & 1 & 1 \\
    -1 & 1 & 0
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 1 & 0 \\
    0 & 0 & 1 \\
    0 & 2 & 0
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1 \\
  \end{pmatrix}
\]
\[ \Rightarrow \lambda_i = 0 \forall i \in \set{1,2,3} \]

\section{Exercise 6}
\begin{ex}
  Let $V$ be a vector space with $\dim{V} = n < \infty$ and $U \subseteq V$ is a
  subspace with $\dim{U} = m$.
  \begin{enumerate}
    \item Show that
      \[ U^\bot = \setdef{v^* \in V^*}{U \subseteq \kernel(v^*)} \]
      is a subspace of $V^*$.
    \item Determine $\dim{U^\bot}$.
    \item Is $\setdef{v^* \in V^*}{U = \kernel{v^*}}$ also a subspace?
  \end{enumerate}
\end{ex}

$U^\bot$ is called orthogonal space or annihilation of $U$.

\begin{enumerate}
  \item
    \[ U^\bot = \setdef{v^* \in V^*}{U \subseteq \kernel(v^*)} \]
    $v^* \in \Hom(V,\mathbb K)$.
    \[ \kernel(v^*) = \setdef{x \in V}{v^*(x) = 0} \supseteq U \Leftrightarrow \forall x \in U: v^*(x) = 0 \]

    \begin{description}
      \item[$\mathbf{U^\bot}$ is nonempty] \hfill{} \\
        The constant zero-function $u: V \to \mathbb K$ with $x \mapsto 0 \in U^\bot$ exists.
        Hence $U^\bot \neq \emptyset$.
      \item[Additivity: $\mathbf{\bigwedge_{u_1,u_2 \in U^\bot} u_1 + u_2 \in U^\bot}$] \hfill{} \\
        Let $u_1,u_2 \in U^\bot$ be linear. Let $x \in U$.
        \[ (u_1 + u_2)(x) = \underbrace{u_1(x)}_{\in U^\bot} + \underbrace{u_2(x)}_{\in U^\bot} = 0 + 0 = 0 \]
      \item[Multiplication: $\mathbf{\bigwedge_{\lambda \in \mathbb K} \bigwedge_{u \in U^\bot} \lambda \cdot u \in U^\bot}$] \hfill{} \\
        Let $\lambda \in \mathbb K$, $u \in U^\bot$ and $x \in U$.
        \[ (\lambda \cdot u)(x) = \lambda \cdot \underbrace{u(x)}_{\in U^\bot} \Rightarrow \lambda \cdot 0 = 0 \]
    \end{description}

  \item
    \[ \dim{V} = n \qquad \dim{V^*} = n \qquad \dim{U} = m \]
    $U$ is subspace of $V$, so $m \leq n$.
    \[ k \coloneqq \dim{U^\bot} \leq n = \dim{V^*} \]
    Let $(u_1, \ldots, u_m)$ be basis of $U$.

    We apply the \emph{basis extension theorem}:
    Let $(u_1, \ldots, u_m, u_{m+1}, \ldots, u_n)$ be a basis of $V$.

    Let $(v_1^*, \ldots, v_n^*)$ the dual basis to $(v_1, \ldots, v_n)$ to $V^*$.
    Hence
    \[ v_1^*(v_j) = \delta_{ij} = \begin{cases} 1 & i=j \\ 0 & i \neq j \end{cases} \]

    Claim: $U^\bot = L(\set{v^*_{m+1}, \ldots, v_n^*}) \Rightarrow (v^*_{m+1}, \ldots, v^*_n)$
    is basis of $U^\bot \Rightarrow \dim{U^\bot} = n - m$.

    Let $v \in V^*$ be arbitrary, $v = \lambda_1 v_1^* + \ldots + \lambda_n v_n^*$.

    \[ v \in U^\bot \Leftrightarrow \forall x \in U: v(x) = 0 \Leftrightarrow v|_{U} = 0 \xLeftrightarrow{(u_1,\ldots, u_m) \text{ is basis of } U} v(u_i) = 0 \quad i = 1, \ldots, m \]
    \begin{align*}
        &\Leftrightarrow \forall i \in \set{1, \ldots, m} (\lambda_1 v^*_1 + \ldots + \lambda_n v^*_n)(v_i) = 0 \\
        &\Leftrightarrow \forall i \in \set{1, \ldots, m} v_1 v^*_1(v_i) + \ldots + \lambda_n v_n^*(v_i) = 0 \\
        &\Leftrightarrow v^k \in L(v^*_{m+1}, \ldots, v^*_n) \\
        &\Leftrightarrow \forall i \in \set{1, \ldots, m} \lambda_i = 0
    \end{align*}

    \[ \pi: V \to \faktor{V}{U} \]
    \[ x \mapsto v + U \]
    \[ \pi^t: (\faktor{V}{U})^* \to V^* \]
    \[ w \to w \circ \pi \]

    $\pi$ surjective, then $\pi^t$ is injective and
    \[ \operatorname{image}(\pi^t) = U^t \Rightarrow \faktor{V}{U}^k \to U^\bot \]

  \item
    Is $\setdef{v^* \in V^*}{U = \kernel{v^*}}$ also a subspace?

    Counterexample:
    Let $u = \set{0}$ and $V \neq \set{0}$.
    \[ \kernel(v^*) = \setdef{x \in V}{x^*(x) = 0} = \set{0} = U \]

    If it is a subspace, then the constant null function (which is the zero element of this set) must be contained.
    This is a contradiction to \enquote{only $x=0$ maps to $0$}.
\end{enumerate}

\section{Exercise 8}
\begin{ex}
  Let $\mathbb R[x]$ be the vector space of real polynomials.
  Show that the dimension of the dual space $\mathbb R[x]^*$ is overcountable.

  \emph{Hint:} Show that linear functionals $(\delta_t)_{t \in \mathbb R}$ defined
  as $\fun{\delta_t, p(x)} = p(t)$ (function application) is linear independent.
\end{ex}

\begin{quote}
  \enquote{In welchem Vektorraum leben wir?} (Florian Kainrath)
\end{quote}

$\delta_t$ are linear maps.

\begin{align*}
  \forall p \in \mathbb R[x]: \sum_{i=1}^n \lambda_t \delta_{t_i}(p(x))
    &= 0 \Rightarrow \lambda_i = 0 \forall i \in \set{1, \ldots, n} \\
  \forall p \in \mathbb R[x]: \sum_{i=1}^n \lambda_t p(t_i) = 0
    &\Rightarrow \lambda_i = 0
\end{align*}

Consider the polynomial $(x - t_1)(x - t_2) \ldots (x - \hat{t}_j)(x - t_{j+1}) \ldots (x - t_n) = p(x)$.
\[ \Rightarrow \sum_{i=1}^n \lambda_i p_j(t_i) = 0 \Leftrightarrow \lambda_j p_j(t_j) = 0 = \lambda_j = 0 \]

\section{Exercise 9}
\begin{ex}
  Let $f \in \Hom(V, W)$ be a linear map between two finite-fimensional vector spaces
  with bases $B \subseteq V$ and $C \subseteq W$. Show that the matrix representation
  of the transposed map
  \[ f^t: W^* \to V^* \]
  \[ w^* \mapsto w^* \circ f \]
  in regards of the dual basis $C^*$ and $B^*$ has the matrix representation
  \[ \Phi_{B^*}^{C^*}(f^t) = \Phi_C^B(f)^t \]
\end{ex}

Show that $f \in \Hom(V, W)$ and $B = (b_1, \ldots, b_m)$ is basis of $V$ with dual basis $B^* = (b_1^*, \ldots, b_m^*)$.
$C = (c_1, \ldots, c_n)$ is basis of $W$ with dual basis $C^* = (c_1^*, \ldots, c_n^*)$.
\[ \Phi_{B^*}^{C^*}(f^t) = \Phi_C^B(f)^t \]
\[ A \coloneqq \Phi_C^B(f) \]

$\Phi_{B^*}^{C^*}(f^t) = P = A^t \forall i \in \set{1, \ldots, n} j \in \set{1, \ldots, m}$ and $a_{ij} = p_{ji}$.
$A \in \mathbb K^{n \times m}$ and $P \in \mathbb K^{m\times n}$.

\[ (a_{ij}) = A = \Phi_C^B(f) \Leftrightarrow  \forall j \in \set{1, \ldots, m} \]
\[ \Phi_C(f(b_j)) = A \Phi_B(b_j) = \begin{pmatrix} a_{1j} \\ \vdots \\ a_{nj} \end{pmatrix} \Leftrightarrow A = \begin{pmatrix} a_{1j} \\ \vdots \\ a_{nj} \end{pmatrix}  \Phi_C^{-1} \]
\[ f(b_j) = \sum_{i=1}^n a_{ij} c_i \qquad \forall j \in \set{1, \ldots, m} \]
\[ (p_{ij}) = p = \Phi_{B^*}^{C^*}(f^t) \Leftrightarrow f^t(c_j^*) = \sum_{i=1}^m p_{ij} b_i^* \forall j \in \set{1,\ldots,n} \]
\[ \Leftrightarrow f^t(c_j^*) \text{ with }j \in \set{1,\ldots, n} = \sum_{i=1}^m p_{ij} b^*_i \xLeftrightarrow{w} c_i \circ f = \sum_{i=1}^m p_{ij} b_i^* \forall j \in \set{1,\ldots,n} \]

Show that $a_{kj} = p_{ik}$ with $k \in \set{1, \ldots, n}$, $j \in \set{1, \ldots, m}$.

\[ a_{kj} = C_k^*\left(\sum_{i=1}^n a_{ij} c_i\right) = c_k^*\left(f(b_j)\right) = \left(f^t(c_k^*)(b_j)\right)
  = \left(\sum_{i=1}^m p_{ik} b_i^*\right)(b_i) = p_{jk} \]

\section{Exercise 10}
\begin{ex}
  \begin{itemize}
    \item Determine the dual basis of $(\mathbb R^4)^*$ to the basis.
      \[
        B = \left\{
          \begin{bmatrix} 1 \\ 2 \\ 1 \\ 0 \end{bmatrix},
          \begin{bmatrix} 1 \\ 0 \\ -1 \\ 1 \end{bmatrix},
          \begin{bmatrix} -1 \\ -2 \\ 2 \\ -1 \end{bmatrix}
          \begin{bmatrix} 2 \\ -1 \\ 1 \\ 1 \end{bmatrix}
        \right\}
      \]
    \item
      Determine the matrix of the unique (why?) projection map
      $\varphi: \mathbb R^4 \to \mathbb R^4$ with $\image(\varphi) = \mathcal L\set{(1,2,1,0)^t, (1,0,-1,1)^t}$
      and $\kernel(\varphi) = \mathcal L\set{(-1, -2, 2, -1)^t, (2, -1, 1, 1)^t}$.
  \end{itemize}
\end{ex}

\subsection{Exercise 10.a}

\[
  \begin{pmatrix}
    1 & 1 & -1 & 2  & 1 & 0 & 0 & 0 \\
    2 & 0 & -2 & -1 & 0 & 1 & 0 & 0 \\
    1 & -1 & 2 & 1  & 0 & 0 & 1 & 0 \\
    0 & 1 & -1 & 1  & 0 & 0 & 0 & 1
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 0 & 0 & 0 & -3 & 1 & 2 & 5 \\
    0 & 1 & 0 & 0 & -9 & 2 & 5 & 15 \\
    0 & 0 & 1 & 0 & -5 & 1 & 3 & 8 \\
    0 & 0 & 0 & 1 & 4 & -1 & -2 & -6
  \end{pmatrix}
\]

So
\[
  b_1^* = \begin{pmatrix} -3 \\ 1 \\ 2 \\ 5 \end{pmatrix} \quad
  b_2^* = \begin{pmatrix} -9 \\ 2 \\ 5 \\ 15 \end{pmatrix} \quad
  b_3^* = \begin{pmatrix} -5 \\ 1 \\ 3 \\ 8 \end{pmatrix} \quad
  b_4^* = \begin{pmatrix} 4 \\ -1 \\ -2 \\ -6 \end{pmatrix}
\]

\[
  B^* = \begin{pmatrix}
    -3 & 1 & 2 & 5 \\
    -9 & 2 & 5 & 15 \\
    -5 & 1 & 3 & 8 \\
    4 & -1 & -2 & -6
  \end{pmatrix}
\]

\[ (\mathbb R^n)^* \cong \mathbb R^{1 \times 4} \]
\[ b_i^*(b_j) = \delta_{ij} \]

\subsection{Exercise 10.b}

Find a projective map $\varphi: \mathbb R^4 \to \mathbb R^4$ such that $U_1 = \varphi(\mathbb R^4)$.
So $\image(\varphi) = \mathcal L(U_1)$ and $\kernel(\varphi) = U_2$.

\[ U_1 = \mathcal L\set{(1, 2, 1, 0)^t, (1, 0, -1, 1)^t} \]
\[ U_2 = \mathcal L\set{(-1, -2, 2, -1)^t, (2, -1, 1, 1)^t} \]

Why do we get a unique map?

$\varphi$ is a projection map iff $\varphi$ is linear and $\varphi \circ \varphi = \varphi$.
Consider $b_1 \in U_1 = \varphi(\mathbb R^4)$ and $b_1 = \varphi(x) \quad x \in \mathbb R^4$.
$\varphi(b_1) = \varphi(\varphi(x)) = \varphi(x) = b_1$. This isomorphism ensures that
the solution is unique.

Because $\varphi: \mathbb R^4 \to \mathbb R^4$, the linear map will be represented by a $4 \times 4$ matrix.

\[
  \begin{pmatrix}
    1 & 2 & 1 & 0 & 1 & 2 & 1 & 0 \\
    1 & 0 & -1 & 1 & 1 & 0 & -1 & 1 \\
    -1 & -2 & 2 & -1 & 0 & 0 & 0 & 0 \\
    2 & -1 & 1 & 1 & 0 & 0 & 0 & 0
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 0 & 0 & 0 & -12 & -6 & 6 & -9 \\
    0 & 1 & 0 & 0 & 3 & 2 & -1 & 2 \\
    0 & 0 & 1 & 0 & 7 & 4 & -3 & 5 \\
    0 & 0 & 0 & 1 & 20 & 10 & -10 & 15
  \end{pmatrix}
\] \[
  \begin{pmatrix}
    -12 & 3 & 7 & 20 \\
    -6 & 2 & 4 & 10 \\
    6 & -1 & -3 & -10 \\
    9 & 2 & 5 & 15
  \end{pmatrix}
\]

\section{Exercise 11}
\begin{ex}
  Given the permutation
  \[ \pi = \left(\begin{pmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ 2 & 5 & 1 & 6 & 3 & 7 & 4 \end{pmatrix}\right) \]
  \begin{itemize}
    \item Determine $\pi^{-1}$ and $\pi^k$ for some $k \in \mathbb N$.
    \item Determine all inversions of $\pi$ and determine $\sign(\pi)$.
    \item Decompose $\pi$ in a product of transpositions.
  \end{itemize}
\end{ex}

\subsection{Exercise 11.a}

\[ \pi = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ 2 & 5 & 1 & 6 & 3 & 7 & 4 \end{pmatrix} \]
\[ \pi^{-1} = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ 3 & 1 & 5 & 7 & 2 & 4 & 6 \end{pmatrix} \]

We give a recursive definition:
\[
  \pi_{(i)}^k = \begin{cases}
    \pi_{(i)}^{k \bmod{4}} & i \in \set{1,2,3,5} \\
    \pi_{(i)}^{k \bmod{3}} & i \in \set{4, 6, 7}
  \end{cases}
\]

\subsection{Exercise 11.b}
%
Inversions are:
\[ f_\pi = \setdef{(i,j)}{i < j \land \pi(i) > \pi(j)} \]
\[ F_\pi = \set{(1,3), (2,3), (2,5), (2,7), (4,5), (4,7), (6,7)} \]

\[ \sign(\pi) = (-1)^f_\pi = -1 \]

\subsection{Exercise 11.c}
%
\[ \pi \circ \tau_{1,3} = (1\ 5\ 2\ 6\ 3\ 7\ 4) \]
\[ \pi \circ \tau_{1,3} \circ \tau_{2,3} \circ \tau_{3,5} \circ \tau_{4,7} \circ \tau_{6,7} = \text{ id} \]
\[ \pi = \tau_{6,7} \circ \tau_{4,7} \circ \tau_{3,5} \circ \tau_{2,3} \circ \tau_{1,3} \]

In terms of notation, remember:
\[
  \begin{pmatrix}
    1 & 2 & \ldots & n \\
    \pi(1) & \pi(2) & \ldots & \pi(n)
  \end{pmatrix}
  \circ
  \tau_{i,j}
  = \begin{pmatrix}
    1 & i & j & n \\
      & \pi(j) & \pi(i) &
  \end{pmatrix}
\]

\section{Exercise 12}
\begin{ex}
  A permutation $\pi \in \mathfrak S_n$ is called cyclic, if there exists
  some $k \geq 1$ and a sequence $i_1, i_2, \ldots, i_k$ such that
  $\pi(i_j) = i_{j+1}$ for $1 \leq j \leq k-1$, $\pi(i_k) = i_1$
  and $\pi(i) = i$ for $i \not\in \set{i_1, i_2, \ldots, i_k}$, hence
  \[ i_1 \to i_2 \to \ldots \to i_k \to i_1 \]
  and all other $i$ are fixed. Common notation: $\pi = (i_1, i_2, \ldots, i_k)$.
  \begin{itemize}
    \item Show that two cyclic permutations $\pi = (i_1, i_2, \ldots, i_k)$
      and $\rho = (j_1, j_2, \ldots, j_l)$ commute ($\pi \circ \rho = \rho \circ \pi$)
      if $\set{i_1, \ldots, i_k} \cap \set{j_1, \ldots, j_l} = \emptyset$.
    \item
      Decompose the cycle into a product of transpositions and show that
      for a cyclic permutation it holds that $\sign(\pi) = (-1)^{k-1}$.
  \end{itemize}
\end{ex}

\subsection{Exercise 12.a}

\begin{description}
  \item[Case 1: $m \in \set{i_1, i_2, \ldots, i_k}$]
    \[ \pi \circ \rho(m) = \pi(\rho(m)) = \pi(m) \]
    \[ \rho \circ \pi(m) = \rho(\pi(m)) = \pi(m) \]
  \item[Case 2: $m \in \set{j_1, j_2, \ldots, j_l}$]
    \[ \pi \circ \rho(m) = \pi(\rho(m)) = \rho(m) \]
    \[ \rho \circ \pi(m) = \rho(\pi(m)) = \rho(m) \]
  \item[Case 3: $m \not\in \set{i_1, \ldots, i_k} \cup \set{j_1, \ldots, j_l}$]
    \[ \pi \circ \rho(m) = \pi(\rho(m)) = m \]
    \[ \rho \circ \pi(m) = \rho(\pi(m)) = m \]
\end{description}

\subsection{Exercise 12.b}
%
\[
  \pi = \begin{pmatrix}
    1 & 2 & \ldots & i_1 & i_2 \ldots & i_k & \ldots & n \\
    1 & 2 & \ldots & i_2 & i_3 \ldots & i_1 & \ldots & n
  \end{pmatrix}
\] \[
  \pi \circ \tau_{i_{1},i_k} = \begin{pmatrix}
    1 & 2 & \ldots & i_1 & i_2 \ldots & i_k & \ldots & n \\
    1 & 2 & \ldots & i_1 & i_3 \ldots & i_2 & \ldots & n
  \end{pmatrix}
\] \[
  \pi \circ \tau_{i_{1},i_k} \circ \tau_{i_2,i_k} = \begin{pmatrix}
    1 & 2 & \ldots & i_1 & i_2 & i_3 & \ldots & i_k & \ldots & n \\
    1 & 2 & \ldots & i_1 & i_2 & i_4 & \ldots & i_3 & \ldots & n
  \end{pmatrix}
\] \[
  \tau \circ \tau_{i_1,i_k} \circ \tau_{i_2,i_k} \circ \ldots \circ \tau_{i_{k-1},i_k} = \text{id}
\] \[
  \pi = \tau_{i_{k-1},i_k} \circ \ldots \circ \tau_{i_l,i_{l+1}} \circ \ldots \circ \tau_{i_1,i_k}
\]

\subsection{Exercise 13}
\begin{ex}
  Let $\pi \in \mathfrak S_n$ be a permutation and $i \in \set{1,2,\ldots,n}$.
  \begin{itemize}
    \item Show that the sequence $i$, $\pi(i)$, $\pi^2(i)$, \ldots is periodic and the first number
      which occurs twice is $i$.
    \item The sequence $(i, \pi(i), \pi^2(i), \ldots, \pi^{k-1}(i))$ where $k$ is the smallest exponent
      such that $\pi^k(i) = i$, is called cycle of $i$. Show that the relation,
      $i \sim j: \Leftrightarrow j$ is in cycle of $i$, is a equivalence relation in $\set{1,2,\ldots,n}$.
    \item Show that every permutation can be represented as product of commutative cycles.
    \item Apply this decomposition for the permutation $\pi$ from exercise~11.
  \end{itemize}
\end{ex}

\subsection{Exercise 13.a}

\begin{itemize}
  \item $i$, $\pi(i)$, \ldots, $\pi^k(i)$ is periodic.
  \item the first element which occurs twice is $i$
  \item
    \[ \setdef{\pi^k(i)}{k \in \set{1, \ldots, n+1}} \]
    at least one elemtn must have occured twice.
  \item
    \[ \pi^k(i) = \pi^l(i) \]
    wlog. $k > l$
    \[ \pi^{k-l}(i) = i \qquad k-l < k \]
\end{itemize}

\[ \pi^{k-l}(i) = (\pi^l)^{-1} \left(\pi^k (\tau)\right) = \left(\pi^e\right)^{-1} \left(\pi^e(i)\right) \]

\subsection{Exercise 13.b}

\begin{description}
  \item[reflexive]
    \[ i \sim i \quad\Leftrightarrow\quad \exists k: \pi^k(i) = i \]
  \item[symmetrical]
    \[
      i \sim j \Rightarrow j \sim i
      \qquad
      \exists l: \pi^l(i) = j \quad
      \pi^k(i) = i \quad
      \pi^{k-l}(i) = i
    \]
  \item[transitive]
    \[
      i \sim j \land j \sim m \Rightarrow i \sim m
      \qquad
      (\exists l_1: \pi^{l_1}(i) = j) \land (\exists l_2: \pi^{l_2}(j) = m)
    \]
    \[ \Rightarrow \exists l_3 = l_1 + l_2: \pi^{l_3}(i) = m \]
\end{description}

\subsection{Exercise 13.c}

Lengthy and therefore skipped.

\subsection{Exercise 13.d}
%
\[
  \pi = \begin{pmatrix}
    1 & 2 & 3 & 4 & 5 & 6 & 7 \\
    2 & 5 & 1 & 6 & 3 & 7 & 4
  \end{pmatrix}
\] \[
  \pi = (1\ 2\ 5\ 3) (4\ 6\ 7)
\]

\section{Exercise 14}
\begin{ex}
  Determine the determinant of the following matrix using three different methods
  (Leibniz, Laplace, Gau\ss-Jordan).
  \[
    \begin{bmatrix}
      1 & 2 & 3 \\
      1 & 1 & 2 \\
      2 & -1 & 2
    \end{bmatrix}
  \]
\end{ex}

Using Leibniz' definition:
\[
  \det(A) = 1 \cdot (-1)^{1+1} \begin{vmatrix} 1 & 2 \\ -1 & 2 \end{vmatrix}
    + (-1)^{2+1} \begin{vmatrix} 2 & 3 \\ -1 & 2 \end{vmatrix}
    + 2 (-1)^4 \begin{vmatrix} 2 & 3 \\ 1 & 2 \end{vmatrix}
\]

Using Gau\ss' definition:
\[
  \det{
  \begin{pmatrix}
    1 & 2 & 3  \\
    1 & 1 & 2 \\
    2 & -1 & 2
  \end{pmatrix}
  } = \det{
  \begin{pmatrix}
    1 & 2 & 3 \\
    0 & -1 & -1 \\
    0 & -5 & -4
  \end{pmatrix}
  } = \det{
  \begin{pmatrix}
    1 & 2 & 3 \\
    0 & -1 & -1 \\
    0 & 0 & 1
  \end{pmatrix}
  } = -1
\]

Using Leibniz' definition:
\[
  \begin{vmatrix}
    1 & 2 & 3 \\
    1 & 1 & 2 \\
    2 & -1 & 2
  \end{vmatrix}
  = 1 \cdot 1 \cdot 2 + 2 \cdot 2 \cdot 2 + 3 \cdot 1 \cdot (-1)
  - 2 \cdot 1 \cdot 3 - (-1) \cdot 2 \cdot 1 - 2 \cdot 1 \cdot 2 = -1
\]

\section{Exercise 15}
\begin{ex}
  The numbers $18984$, $10962$, $40026$, $17976$ and $14994$ are divisible by $42$.
  Show that the determinant of $A$ is divisible by $42$ without explicitly computing it.
  \[
    A = \begin{pmatrix}
      1 & 8 & 9 & 8 & 4 \\
      1 & 0 & 9 & 6 & 2 \\
      4 & 0 & 0 & 2 & 6 \\
      1 & 7 & 9 & 7 & 6 \\
      1 & 4 & 9 & 9 & 4
    \end{pmatrix}
  \]
\end{ex}

\[
  \begin{vmatrix}
    1 & 8 & 9 & 8 & 4 \\
    1 & 0 & 9 & 6 & 2 \\
    4 & 0 & 0 & 2 & 6 \\
    1 & 7 & 9 & 7 & 6 \\
    1 & 4 & 9 & 9 & 4
  \end{vmatrix}
  =
  \begin{vmatrix}
    1 & 8 & 9 & 8 & 18984 \\
    1 & 0 & 9 & 6 & 10962 \\
    4 & 0 & 0 & 2 & 40026 \\
    1 & 7 & 9 & 7 & 17976 \\
    1 & 4 & 9 & 9 & 14994
  \end{vmatrix}
  = 42 \cdot B
\]
where $B$ is some matrix with modified 5-th column.

Why does this work?
Well, this can be proven using Leibniz' definition of the determinant.
\[
  \det((a_{ij}))
  = \sum_{\sigma \in S_n}
    \operatorname{sgn}(\sigma) a_1  \ldots
\]

\section{Exercise 16}
\begin{ex}
  Compute the $n\times n$-determinants:
  \begin{enumerate}
    \item \[
        \begin{pmatrix}
          1 & 2 & 3 & 4 & \ldots & n-1 & n \\
          -1 & 0 & 3 & 4 & \ldots & n-1 & n \\
          -1 & -2 & 0 & 4 & \ldots & n-1 & n \\
          \ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
          -1 & -2 & -3 & -4 & \ldots & 0 & n \\
          -1 & -2 & -3 & -4 & \ldots & -n+1 & 0
        \end{pmatrix}
      \]
    \item \[
        \begin{pmatrix}
          0 & 0 & \ldots & 0 & a_n \\
          0 & 0 & \ldots & a_{n-1} & * \\
          \vdots & & \vdots & \vdots & \vdots \\
          0 & a_2 & * & \ldots & * \\
          a_1 & * & \ldots &  & *
        \end{pmatrix}
      \]
  \end{enumerate}
\end{ex}

\[
  \begin{pmatrix}
    1 & 2 & 3 & 4 & \ldots & n-1 & n \\
    -1 & 0 & 3 & 4 & \ldots & n-1 & n \\
    -1 & -2 & 0 & 4 & \ldots & n-1 & n \\
    \ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
    -1 & -2 & -3 & -4 & \ldots & 0 & n \\
    -1 & -2 & -3 & -4 & \ldots & -n+1 & 0
  \end{pmatrix}
  =
  \begin{pmatrix}
    1 & 2 & 3 & 4 & \ldots & n-1 & n \\
    0 & 2 & * & * & \ldots & n-1 & n \\
    0 & 0 & 3 & * & \ldots & n-1 & n \\
    \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
    0 & 0 & 0 & 0 & \ldots & 0 & n
  \end{pmatrix}
  = 1 \cdot 2 \cdot 3 \cdot \ldots \cdot n = n!
\]

\[
  \begin{vmatrix}
    0 & 0 & \ldots & 0 & a_n \\
    0 & 0 & \ldots & a_{n-1} & * \\
    \vdots & & \vdots & \vdots & * \\
    0 & a_2 & * & \ldots & * \\
    a_1 & * & \ldots &  & *
  \end{vmatrix}
  =
  (-1)^k
  \begin{vmatrix}
    a_1 & *   & \ldots & *       & a_n \\
    0   & a_2 & \ldots & \ddots  & * \\
    \vdots    &        & \vdots  & \ddots & \vdots \\
    0   & 0   &        & a_{n-1} & * \\
    0   & 0   & \ldots & 0       & a_n \\
  \end{vmatrix}
  =
  \left(\prod_{k=1}^n a_k\right) (-1)^k
\]
where $k = \frac n2$ is $n$ is even or $k = \frac{n-1}2$ is odd.

\section{Exercise 17}
\begin{ex}
  Let $A \in \mathbb K_{m\times m}$, $B \in \mathbb K_{m\times n}$, $D \in \mathbb K_{n\times n}$ matrices.
  Show that,
  \[
    \det{\begin{pmatrix}
      A & B \\
      0 & D
    \end{pmatrix}}
    = \det{A} \cdot \det{D}
  \]
\end{ex}

Let $T = \begin{pmatrix}
  A & B \\
  0 & D
\end{pmatrix}$

If $A$ is singular, the rows are linear dependent. So $\det{T} = 0$.
The same applies to $D$.

We apply row operations to $A$ to retrieve an upper triangular matrix $A_1$.
If we do the same operations on $T$, we get $B_1$.
We apply row oeprations to $D$ to retrieve an upper triangular matrix $D_1$.

\[
  \hat T = \begin{pmatrix}
    A_1 & B_1 \\
    0 & D_1
  \end{pmatrix}
\]

Let $a$ be the product of diagonal elements of $A_1$.
Let $d$ be the product of diagonal elements of $D_1$.

So $a \cdot d$ is the product of diagonal elements of $\hat T$.

Let $p$ be the number of swaps in $A_1$. Let $q$ be the number of swaps in $A_2$.
\[ p + q = \hat{T} \]

Then
\[ \det{A} = (-1)^p a \qquad \det{D} = (-1)^q b \]
\[ \det{T} = (-1)^{p+q} a \cdot b \]

\section{Exercise 18}
\begin{ex}
  Compute the entry $(A^{-1})_{4,3}$ of the inverse matrix
  \[
    A = \begin{bmatrix}
      1 & 0 & 0 & 0 & -2 \\
      0 & 0 & -1 & 0 & 0 \\
      0 & 2 & 2 & -1 & -2 \\
      0 & 1 & 2 & 0 & -2 \\
      0 & 0 & 0 & 0 & -1
    \end{bmatrix}
  \]
\end{ex}

We compute the inverse matrix $A^{-1}$.

\[
  \left(\begin{bmatrix}
    1 & 0 & 0 & 0 & -2 \\
    0 & 0 & -1 & 0 & 0 \\
    0 & 2 & 2 & -1 & -2 \\
    0 & 1 & 2 & 0 & -2 \\
    0 & 0 & 0 & 0 & -1
  \end{bmatrix}\right)^{-1}
  =
  \begin{bmatrix}
    1 & 0 & 0 & 0 & 2 \\
    0 & 2 & 0 & 1 & -2 \\
    0 & -1 & 0 & 0 & 0 \\
    0 & 2 & -1 & 2 & -2 \\
    0 & 0 & 0 & 0 & -1
  \end{bmatrix}
\]

But we can also use the Theorem from the lecture.

Use the adjoint matrix $\hat{A}$ of $A$ where $\hat{a}_{kl} = (-1)^{k+l} \det{A_{lk}}$.
Then $A^{-1} = \frac{1}{\det{A}} \cdot \hat{A}$.

\[ A^{-1} = \frac{1}{\det{A}} \cdot \hat{A} \]
\[ A^{-1}_{43} = \frac{1}{\det{A}} (-1)^{3+4} \det{A_{3,4}} = -1 \]

But we can also determine it more easily.
$(A^{-1})_{4,3}$ is the element in the 4th row and 3rd column.
It is also the element in the $4$-th row of $A^{-1} e_3$.

So
\[ A_{e_4} = -e_3 \]
So $-1$.




\end{document}
