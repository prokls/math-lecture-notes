\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{baskervald}
\usepackage{bbold}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{faktor}
\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red]{hyperref}
\usepackage{imakeidx} % before hyperref
\usepackage{mathalfa}
\usepackage{mathtools}
\usepackage{mdframed}
\usepackage[bigdelims,vvarbb]{newtxmath}
\usepackage{rotating}
\usepackage{stmaryrd}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{xcolor}

\renewcommand*\oldstylenums[1]{\textosf{#1}}

\theoremstyle{definition}
\newmdtheoremenv[%
  backgroundcolor=white,
  linecolor=white!60!black,
  linewidth=3pt]{ex}{Exercise}

\DeclareMathOperator\kernel{kernel}
\DeclareMathOperator\Hom{Hom}

\title{Linear Algebra 2 -- Practicals}
\author{Lukas Prokop}
\date{summer term 2016}

\newcommand\meta[3]{This #1 took place on #2 (#3).\par}
\newcommand\abs[1]{|\,#1\,|}
\newcommand\set[1]{\left\{#1\right\}}
\newcommand\setdef[2]{\left\{#1\,\middle|\,#2\right\}}
\newcommand\card[1]{\left|\,#1\,\right|}
\newcommand\divides[2]{#1\,\mid\,#2}
\newcommand\mathspace{\hspace{20pt}}
\newcommand\fun[1]{\left\langle{#1}\right\rangle}
\newcommand\Q{\mathbb{Q}}
\newcommand\nope{\lightning}
\newcommand\vecfour[4]{\begin{pmatrix} #1 \\ #2 \\ #3 \\ #4 \end{pmatrix}}
\newcommand{\textgreek}[1]{\begingroup\fontencoding{LGR}\selectfont#1\endgroup}

\parindent0pt
\parskip7pt
\setcounter{tocdepth}{1}

\begin{document}
\maketitle
\tableofcontents

\clearpage
Exercise I did on the board: 3, 7.

\section{Exercise 1}
\begin{ex}
  Determine the matrix representation of the linear map
  \[ f: \mathbb R_1[x] \to \mathbb R_2[x] \]
  \[ p(x) \mapsto (x-1) \cdot p(x) \]
  in regards of bases $B = \set{1-x, 1+x} \subseteq \mathbb R_1[x]$ and $C = \set{1, 1 + x, 1 + x + x^2} \subseteq \mathbb R^2[x]$.
\end{ex}

\[
  f: \mathbb R_1[x] \to \mathbb R_2[x]
\] \[
  f: p(x) \mapsto (x-1) p(x)
\] \[
  B = \set{1-x, 1+x} \eqqcolon \set{b_1, b_2}
\] \[
  C = \set{1, 1+x, 1+x+x^2} \eqqcolon \set{c_1, c_2, c_3}
\]

Find $A \in \mathbb K^{3\times 2} \eqqcolon M_C^B(f)$.

\[ \forall v \in \mathbb R_1: f(v) = w : \Phi_C(w) = A \Phi_B(v) \]

\[ f(b_1) = (1-x)(x-1) = -x^2 + 2x - 1 \]
\[ f(b_2) = (x-1)(x+1) = x^2 - 1 \]

\[ \Phi_C(f(b_1)) \]

Coefficient comparison:
\begin{align*}
  -x^2 + 2x - 1 &= \lambda_1 \cdot 1 + \lambda_2 (1 + x) + \lambda_3 (1 + x + x^2) \\
  x^2: & \lambda_3 = -1 \\
  x^1: & 2 = \lambda_2 + \lambda_3 \Rightarrow \lambda_2 = 3 \\
  x^0: & -1 = \lambda_1 + \lambda_2 + \lambda_3 \Rightarrow \lambda_1 = -3
\end{align*}

\[ \Phi_C(f(b_1)) = \begin{pmatrix} 3 \\ 3 \\ 1 \end{pmatrix} \]
\[ \Phi_C(f(b_2)): x^2 = 1 = \lambda_1 \cdot 1 + \lambda_2 (1 + x) + \lambda_3 (1 + x + x^2) \]
\begin{align*}
  x^2: & \lambda_3 = 1 \\
  x^1: & \lambda_2 + \lambda_3 = 0 \Rightarrow \lambda_2 = -1 \\
  x^0: & -1 = \lambda_1 + \lambda_2 + \lambda_3 \\
       & -1 = \lambda_1 - 1 + 1 \\
       & -1 = \lambda_1
\end{align*}

\[ \Phi_C(f(b_2)) = \begin{pmatrix} -1 \\ -1 \\ 1 \end{pmatrix} \]
\[ A = \begin{pmatrix} -3 & -1 \\ 3 & -1 \\ 1 & 1 \end{pmatrix} \]


\section{Exercise 3}
\begin{ex}
  Let $A_1, A_2, \ldots, A_k$ be quadratic $n\times n$ matrices over the field $\mathbb K$.
  Show that the product $A_1 A_2 \ldots A_k$ is invertible if and only if all $A_i$ are invertible.
\end{ex}

All $A_i$ are invertible, then $\prod A_i$ is invertible.

$A, B$ invertible, then $AB$ is invertible and $(AB)^{-1} = B^{-1} A^{-1}$.
Generalize by induction.

If $\prod A_i$ is invertible, then all $A_i$ are invertible.

Sidenote: We know that $\operatorname{rank}(A) = n - \dim{\kernel(A)}$.

\begin{description}
  \item[$k=1$] trivial
  \item[$k=2$] $A_1 A_2$ is invertible. Let $C = (A_1 A_2)^{-1}$. Then $C A_1 A_2 = I_n$.
    Let $x \in \kernel(A_2) \Rightarrow A_2 x = 0 \Rightarrow \underbrace{C A_1}_{I_n} A_2 x = C A_1 0 = 0$.
    \[ \kernel(A_2) = 0 \Rightarrow \operatorname{rank}(A_2) = n - 0: n \Rightarrow A_2 \text{ invertible} \]
    \[ A_1 = \underbrace{A_1 A_2}_{\text{invertible}} \cdot \underbrace{A_2^{-1}}_{\text{invertible}} \]
  \item[$k \to k+1$]
    Let $A_1 \ldots A_{k+1}$ is invertible $\Rightarrow (A_1, \ldots, A_k) A_{k+1}$ is invertible $\xRightarrow{k=2} A_1, \ldots, A_k$ is invertible, $A_{k+1}$ invertible $\xRightarrow{\text{induction base}}$ $A_1, \ldots, A_k, A_{k+1}$ is invertible.
\end{description}

Remark:
$A,B \in \mathbb K^{n\times n}$. $B$ is inverse of $A$
\[ \Leftrightarrow AB = I = BA \Leftrightarrow AB = I \Leftrightarrow BA = I \]

\section{Exercise 2}
%
\begin{ex}
  Let $V$ be a vector space and $f: V \to \mathbb V$ is a nilpotent linear map,
  hence there exists some $k \in \mathbb N$ such that $f^k = 0$.
\end{ex}

\subsection{Part a}
\begin{ex}
  Show that $\text{id}_V - f$ is invertible with $(\text{id}_V - f)^{-1} = \text{id}_V + f + f^2 + \ldots + f^{k-1}$.
\end{ex}

Show that: $(\text{id}_v - f)^{-1} = \sum_{i=0}^{k-1} f^i$.
\[ (\text{id}_V - f) \circ \left(\sum_{i=0}^{k-1} f^{i}\right) = \text{id}_V \circ \sum_{i=0}^{k-1} f^i - f \circ \sum_{i=0}^{k-1} f^i - \sum_{i=0}^{k-1} f^{i+1} = f^0 + \sum_{i=1}^{k-1} f^i - \sum_{i=1}^{k-1} f^i - f^k = \text{id}_V - 0 = \text{id}_V \]
and $\left(\sum_{i=0}^{k-1} f^i\right) \circ \left(\text{id}_V - f\right)$ analogously.

\subsection{Part b}
\begin{ex}
  Use part a) to determine the inverse of the matrix
  \[
    \begin{pmatrix}
      1 & 2 & 3 & 4 \\
      0 & 1 & 2 & 3 \\
      0 & 0 & 1 & 2 \\
      0 & 0 & 0 & 1
    \end{pmatrix}
  \]
\end{ex}
\[
  \begin{pmatrix}
    1 & 2 & 3 & 4 \\
    0 & 1 & 2 & 3 \\
    0 & 0 & 1 & 2 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \eqqcolon A
  = \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  - f_A
\] \[
  f_A = I_n - A =
  \begin{pmatrix}
    0 & -2 & -3 & -4 \\
    0 & 0 & -2 & -3 \\
    0 & 0 & 0 & -2 \\
    0 & 0 & 0 & 0
  \end{pmatrix}
\] \[
  f^2_A = f \cdot f = \begin{pmatrix} 0 & 0 & 4 & 12 \\ 0 & 0 & 0 & 4 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  f^3 = f^2 \cdot f = \begin{pmatrix} 0 & 0 & 0 & -8 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  f^4 = f^3 \cdot f = \begin{pmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\]
$\Rightarrow$ f nilpotent.

\[ A^{-1} = (\operatorname{id}_v - f)^{-1} = \operatorname{id}_v + f + f^2 + f^3 \]
\[
  = \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  +
  \begin{pmatrix}
    0 & -2 & -3 & -4 \\
    0 & 0 & -2 & -3 \\
    0 & 0 & 0 & -2 \\
    0 & 0 & 0 & 0
  \end{pmatrix}
  +
  \begin{pmatrix} 0 & 0 & 4 & 12 \\ 0 & 0 & 0 & 4 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
  +
  \begin{pmatrix} 0 & 0 & 0 & -8 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  = \begin{pmatrix} 1 & -2 & 1 & 0 \\ 0 & 1 & -2 & 1 \\ 0 & 0 & 1 & -2 \\ 0 & 0 & 0 & 1 \end{pmatrix}
\] \[
  A \cdot A' =
  \begin{pmatrix} 1 & 2 & 3 & 4 \\ 0 & 1 & 2 & 3 \\ 0 & 0 & 1 & 2 \\ 0 & 0 & 0 & 1 \end{pmatrix} \cdot
  \begin{pmatrix} 1 & -2 & 1 & 0 \\ 0 & 1 & -2 & 1 \\ 0 & 0 & 1 & -2 \\ 0 & 0 & 0 & 1 \end{pmatrix}
  = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}
\]

\section{Exercise 4}
\subsection{Part a}
\begin{ex}
  Let $A$ be an invertible $n\times n$ matrix over a field $\mathbb K$ and $u,v$ are
  column vectors (hence $n\times 1$ matrices), such that $\sigma  1 + v^t A^{-1} u \neq 0$.
  Show that $(A + uv^t)$ is invertible and that
  \[ (A + uv^t)^{-1} = A^{-1} - \frac1{\sigma} A^{-1} uv^t A^{-1} \]
\end{ex}

\subsection{Part b}
\begin{ex}
  Apply this formula to determine the inverse of the matrix
  \[
    A = \begin{pmatrix}
      5 & 3 & 0 & 1 \\
      3 & 2 & 0 & 0 \\
      0 & 0 & 2 & 3 \\
      0 & 0 & 3 & 5
    \end{pmatrix}
  \]
\end{ex}

\[
  B = A + S
\] \[
  B = \begin{pmatrix} 5 & 3 & 0 & 0 \\ 3 & 2 & 0 & 0 \\ 0 & 0 & 2 & 3 \\ 0 & 0 & 3 & 5 \end{pmatrix}
  + \begin{pmatrix} 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\] \[
  \begin{pmatrix} 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix}
    = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} \cdot \begin{pmatrix} 0 & 0 & 0 & 1 \end{pmatrix}
\]

$A$ is invertible, because it is a block matrix\footnote{That's why chose $A$ and $S$ that way}.

\[
  A^{-1} = \begin{pmatrix}
    2 & -3 & 0 & 0 \\
    -3 & 5 & 0 & 0 \\
    0 & 0 & 5 & -3 \\
    0 & 0 & -3 & 2
  \end{pmatrix}
\] \[
  \sigma = 1 + \begin{pmatrix} 0 & 0 & 0 & 1 \end{pmatrix} A^{-1} \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} = 1 + 0 \neq 0
\]

\[ \Rightarrow B^{-1} = A^{-1} - A^{-1} \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} \cdot \begin{pmatrix} 0 & 0 & 0 & 1 \end{pmatrix} A^{-1}
  = \begin{pmatrix}
    2 & -3 & 6 & -4  \\
    -3 & 5 & -9 & 6 \\
    0 & 0 & 5 & -3 \\
    0 & 0 & -3 & 2
  \end{pmatrix}
\]

\section{Exercise 5}
\begin{ex}
  Show that the linear maps $f,g,h: \mathbb R^2 \to \mathbb R^2$ defined as
  \[
    f: (x_1, x_2) \mapsto (x_1 + x_2, x_1 - x_2) \quad
    g: (x_1, x_2) \mapsto (x_1 + x_2, x_1 + x_2) \quad
    h: (x_1, x_2) \mapsto (x_2, x_1)
  \]
  are linear independent, if they are considered as elements of the vector space
  $\Hom(\mathbb R^2, \mathbb R^2)$ of all maps from $\mathbb R^2$ to $\mathbb R^2$.
\end{ex}

Let $\lambda_1, \lambda_2, \lambda_3 \in \mathbb R$.
Show that
\[ \lambda_1 f + \lambda_2 g + \lambda_3 h = 0 \stackrel!{=} \lambda_1 = \lambda_2 = \lambda_3 = 0 \]

\[ f: x \mapsto Ax \qquad A_f = \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} \qquad A_g = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} \qquad A_n = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \]

Is an isomorphism, $\Hom(\mathbb R^2, \mathbb R^2) \to \mathbb R^{2 \times 2}$ with $f \mapsto A_f$.

\[ \lambda_1 \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} + \lambda_2 \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} + \lambda_3 \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix} \]

\[
  \begin{pmatrix}
    1 & 1 & 0 \\
    1 & 1 & 1 \\
    -1 & 1 & 0
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 1 & 0 \\
    0 & 0 & 1 \\
    0 & 2 & 0
  \end{pmatrix}
  \leadsto
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1 \\
  \end{pmatrix}
\]
\[ \Rightarrow \lambda_i = 0 \forall i \in \set{1,2,3} \]

\section{Exercise 6}
\begin{ex}
  Let $V$ be a vector space with $\dim{V} = n < \infty$ and $U \subseteq V$ is a
  subspace with $\dim{U} = m$.
  \begin{enumerate}
    \item Show that
      \[ U^\bot = \setdef{v^* \in V^*}{U \subseteq \kernel(v^*)} \]
      is a subspace of $V^*$.
    \item Determine $\dim{U^\bot}$.
    \item Is $\setdef{v^* \in V^*}{U = \kernel{v^*}}$ also a subspace?
  \end{enumerate}
\end{ex}

$U^\bot$ is called orthogonal space or annihilation of $U$.

\begin{enumerate}
  \item
    \[ U^\bot = \setdef{v^* \in V^*}{U \subseteq \kernel(v^*)} \]
    $v^* \in \Hom(V,\mathbb K)$.
    \[ \kernel(v^*) = \setdef{x \in V}{v^*(x) = 0} \supseteq U \Leftrightarrow \forall x \in U: v^*(x) = 0 \]

    \begin{description}
      \item[$\mathbf{U^\bot}$ is nonempty] \hfill{} \\
        The constant zero-function $u: V \to \mathbb K$ with $x \mapsto 0 \in U^\bot$ exists.
        Hence $U^\bot \neq \emptyset$.
      \item[Additivity: $\mathbf{\bigwedge_{u_1,u_2 \in U^\bot} u_1 + u_2 \in U^\bot}$] \hfill{} \\
        Let $u_1,u_2 \in U^\bot$ be linear. Let $x \in U$.
        \[ (u_1 + u_2)(x) = \underbrace{u_1(x)}_{\in U^\bot} + \underbrace{u_2(x)}_{\in U^\bot} = 0 + 0 = 0 \]
      \item[Multiplication: $\mathbf{\bigwedge_{\lambda \in \mathbb K} \bigwedge_{u \in U^\bot} \lambda \cdot u \in U^\bot}$] \hfill{} \\
        Let $\lambda \in \mathbb K$, $u \in U^\bot$ and $x \in U$.
        \[ (\lambda \cdot u)(x) = \lambda \cdot \underbrace{u(x)}_{\in U^\bot} \Rightarrow \lambda \cdot 0 = 0 \]
    \end{description}

  \item
    \[ \dim{V} = n \qquad \dim{V^*} = n \qquad \dim{U} = m \]
    $U$ is subspace of $V$, so $m \leq n$.
    \[ k \coloneqq \dim{U^\bot} \leq n = \dim{V^*} \]
    Let $(u_1, \ldots, u_m)$ be basis of $U$.

    We apply the \emph{basis extension theorem}:
    Let $(u_1, \ldots, u_m, u_{m+1}, \ldots, u_n)$ be a basis of $V$.

    Let $(v_1^*, \ldots, v_n^*)$ the dual basis to $(v_1, \ldots, v_n)$ to $V^*$.
    Hence
    \[ v_1^*(v_j) = \delta_{ij} = \begin{cases} 1 & i=j \\ 0 & i \neq j \end{cases} \]

    Claim: $U^\bot = L(\set{v^*_{m+1}, \ldots, v_n^*}) \Rightarrow (v^*_{m+1}, \ldots, v^*_n)$
    is basis of $U^\bot \Rightarrow \dim{U^\bot} = n - m$.

    Let $v \in V^*$ be arbitrary, $v = \lambda_1 v_1^* + \ldots + \lambda_n v_n^*$.

    \[ v \in U^\bot \Leftrightarrow \forall x \in U: v(x) = 0 \Leftrightarrow v|_{U} = 0 \xLeftrightarrow{(u_1,\ldots, u_m) \text{ is basis of } U} v(u_i) = 0 \quad i = 1, \ldots, m \]
    \begin{align*}
        &\Leftrightarrow \forall i \in \set{1, \ldots, m} (\lambda_1 v^*_1 + \ldots + \lambda_n v^*_n)(v_i) = 0 \\
        &\Leftrightarrow \forall i \in \set{1, \ldots, m} v_1 v^*_1(v_i) + \ldots + \lambda_n v_n^*(v_i) = 0 \\
        &\Leftrightarrow v^k \in L(v^*_{m+1}, \ldots, v^*_n) \\
        &\Leftrightarrow \forall i \in \set{1, \ldots, m} \lambda_i = 0
    \end{align*}

    \[ \pi: V \to \faktor{V}{U} \]
    \[ x \mapsto v + U \]
    \[ \pi^t: (\faktor{V}{U})^* \to V^* \]
    \[ w \to w \circ \pi \]

    $\pi$ surjective, then $\pi^t$ is injective and
    \[ \operatorname{image}(\pi^t) = U^t \Rightarrow \faktor{V}{U}^k \to U^\bot \]

  \item
    Is $\setdef{v^* \in V^*}{U = \kernel{v^*}}$ also a subspace?

    Counterexample:
    Let $u = \set{0}$ and $V \neq \set{0}$.
    \[ \kernel(v^*) = \setdef{x \in V}{x^*(x) = 0} = \set{0} = U \]

    If it is a subspace, then the constant null function (which is the zero element of this set) must be contained.
    This is a contradiction to \enquote{only $x=0$ maps to $0$}.
\end{enumerate}

\section{Exercise 8}
\begin{ex}
  Let $\mathbb R[x]$ be the vector space of real polynomials.
  Show that the dimension of the dual space $\mathbb R[x]^*$ is overcountable.

  \emph{Hint:} Show that linear functionals $(\delta_t)_{t \in \mathbb R}$ defined
  as $\fun{\delta_t, p(x)} = p(t)$ (function application) is linear independent.
\end{ex}

\begin{quote}
  \enquote{In welchem Vektorraum leben wir?} (Florian Kainrath)
\end{quote}

$\delta_t$ are linear maps.

\begin{align*}
  \forall p \in \mathbb R[x]: \sum_{i=1}^n \lambda_t \delta_{t_i}(p(x))
    &= 0 \Rightarrow \lambda_i = 0 \forall i \in \set{1, \ldots, n} \\
  \forall p \in \mathbb R[x]: \sum_{i=1}^n \lambda_t p(t_i) = 0
    &\Rightarrow \lambda_i = 0
\end{align*}

Consider the polynomial $(x - t_1)(x - t_2) \ldots (x - \hat{t}_j)(x - t_{j+1}) \ldots (x - t_n) = p(x)$.
\[ \Rightarrow \sum_{i=1}^n \lambda_i p_j(t_i) = 0 \Leftrightarrow \lambda_j p_j(t_j) = 0 = \lambda_j = 0 \]

\section{Exercise 9}
\begin{ex}
  Let $f \in \Hom(V, W)$ be a linear map between two finite-fimensional vector spaces
  with bases $B \subseteq V$ and $C \subseteq W$. Show that the matrix representation
  of the transposed map
  \[ f^t: W^* \to V^* \]
  \[ w^* \mapsto w^* \circ f \]
  in regards of the dual basis $C^*$ and $B^*$ has the matrix representation
  \[ \Phi_{B^*}^{C^*}(f^t) = \Phi_C^B(f)^t \]
\end{ex}

Show that $f \in \Hom(V, W)$ and $B = (b_1, \ldots, b_m)$ is basis of $V$ with dual basis $B^* = (b_1^*, \ldots, b_m^*)$.
$C = (c_1, \ldots, c_n)$ is basis of $W$ with dual basis $C^* = (c_1^*, \ldots, c_n^*)$.
\[ \Phi_{B^*}^{C^*}(f^t) = \Phi_C^B(f)^t \]
\[ A \coloneqq \Phi_C^B(f) \]

$\Phi_{B^*}^{C^*}(f^t) = P = A^t \forall i \in \set{1, \ldots, n} j \in \set{1, \ldots, m}$ and $a_{ij} = p_{ji}$.
$A \in \mathbb K^{n \times m}$ and $P \in \mathbb K^{m\times n}$.

\[ (a_{ij}) = A = \Phi_C^B(f) \Leftrightarrow  \forall j \in \set{1, \ldots, m} \]
\[ \Phi_C(f(b_j)) = A \Phi_B(b_j) = \begin{pmatrix} a_{1j} \\ \vdots \\ a_{nj} \end{pmatrix} \Leftrightarrow A = \begin{pmatrix} a_{1j} \\ \vdots \\ a_{nj} \end{pmatrix}  \Phi_C^{-1} \]
\[ f(b_j) = \sum_{i=1}^n a_{ij} c_i \qquad \forall j \in \set{1, \ldots, m} \]
\[ (p_{ij}) = p = \Phi_{B^*}^{C^*}(f^t) \Leftrightarrow f^t(c_j^*) = \sum_{i=1}^m p_{ij} b_i^* \forall j \in \set{1,\ldots,n} \]
\[ \Leftrightarrow f^t(c_j^*) \text{ with }j \in \set{1,\ldots, n} = \sum_{i=1}^m p_{ij} b^*_i \xLeftrightarrow{w} c_i \circ f = \sum_{i=1}^m p_{ij} b_i^* \forall j \in \set{1,\ldots,n} \]

Show that $a_{kj} = p_{ik}$ with $k \in \set{1, \ldots, n}$, $j \in \set{1, \ldots, m}$.

\[ a_{kj} = C_k^*\left(\sum_{i=1}^n a_{ij} c_i\right) = c_k^*\left(f(b_j)\right) = \left(f^t(c_k^*)(b_j)\right)
  = \left(\sum_{i=1}^m p_{ik} b_i^*\right)(b_i) = p_{jk} \]

\end{document}
